{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb270d6a",
   "metadata": {},
   "source": [
    "## 1. Setup - Colab Kontrol√º ve Proje Kurulumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Colab kontrol√º\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"‚úÖ Google Colab ortamƒ± tespit edildi\")\n",
    "    \n",
    "    # GPU kontrol√º\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GPU bulunamadƒ±! Runtime > Change runtime type > GPU se√ßin\")\n",
    "    \n",
    "    # GitHub'dan projeyi klonla\n",
    "    print(\"\\nüì• Proje indiriliyor...\")\n",
    "    !git clone https://github.com/Aliekinozcetin/Mitre_Attack_TTP_Mapping.git\n",
    "    \n",
    "    # Proje dizinine ge√ß\n",
    "    os.chdir('Mitre_Attack_TTP_Mapping')\n",
    "    print(f\"‚úÖ √áalƒ±≈üma dizini: {os.getcwd()}\")\n",
    "    \n",
    "    # Gerekli paketleri y√ºkle\n",
    "    print(\"\\nüì¶ Paketler y√ºkleniyor...\")\n",
    "    !pip install -q -r requirements.txt\n",
    "    print(\"‚úÖ T√ºm paketler y√ºklendi\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Yerel ortamda √ßalƒ±≈üƒ±yorsunuz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ca280",
   "metadata": {},
   "source": [
    "## 2. Import Mod√ºller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from src.data_loader import prepare_data\n",
    "from src.model import load_model\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model\n",
    "\n",
    "print(\"‚úÖ Mod√ºller y√ºklendi\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6279ff",
   "metadata": {},
   "source": [
    "## 3. Konfig√ºrasyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parametreleri\n",
    "CONFIG = {\n",
    "    'model_name': 'bert-base-uncased',  # veya 'jackaduma/SecBERT', 'distilbert-base-uncased'\n",
    "    'max_length': 512,\n",
    "    'batch_size': 16,  # GPU varsa 32'ye √ßƒ±karabilirsin\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_epochs': 3,\n",
    "    'warmup_steps': 500,\n",
    "    'threshold': 0.5,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'output_dir': './outputs'\n",
    "}\n",
    "\n",
    "# Konfig√ºrasyonu yazdƒ±r\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4715c",
   "metadata": {},
   "source": [
    "## 4. Veri Y√ºkleme ve Hazƒ±rlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ace414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: DATA PREPARATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "data = prepare_data(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "\n",
    "train_dataset = data['train_dataset']\n",
    "test_dataset = data['test_dataset']\n",
    "label_list = data['label_list']\n",
    "num_labels = data['num_labels']\n",
    "\n",
    "print(f\"\\n‚úÖ Veri hazƒ±rlama tamamlandƒ±!\")\n",
    "print(f\"   Train samples: {len(train_dataset)}\")\n",
    "print(f\"   Test samples: {len(test_dataset)}\")\n",
    "print(f\"   Number of labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9a687",
   "metadata": {},
   "source": [
    "## 5. Model Y√ºkleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f12260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: MODEL INITIALIZATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "model = load_model(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    num_labels=num_labels,\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model y√ºklendi ve {CONFIG['device']} cihazƒ±na ta≈üƒ±ndƒ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fec12",
   "metadata": {},
   "source": [
    "## 6. Model Eƒüitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730aed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: MODEL TRAINING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Output dizini olu≈ütur\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_name = f\"{CONFIG['model_name'].replace('/', '_')}_{timestamp}\"\n",
    "output_dir = os.path.join(CONFIG['output_dir'], run_name)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Label listesini kaydet\n",
    "label_file = os.path.join(output_dir, \"labels.json\")\n",
    "with open(label_file, 'w') as f:\n",
    "    json.dump(label_list, f, indent=2)\n",
    "\n",
    "# Eƒüitimi ba≈ülat\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=output_dir,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "# Training ge√ßmi≈üini kaydet\n",
    "history_file = os.path.join(output_dir, \"training_history.json\")\n",
    "with open(history_file, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Eƒüitim tamamlandƒ±!\")\n",
    "print(f\"   Final loss: {history['train_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bbb0e",
   "metadata": {},
   "source": [
    "## 7. Model Deƒüerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ae708",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: MODEL EVALUATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "metrics = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    device=CONFIG['device'],\n",
    "    threshold=CONFIG['threshold'],\n",
    "    label_list=label_list\n",
    ")\n",
    "\n",
    "# Metrikleri kaydet\n",
    "metrics_to_save = {k: float(v) if isinstance(v, (float, int)) else v \n",
    "                   for k, v in metrics.items() \n",
    "                   if k not in ['predictions', 'labels']}\n",
    "metrics_file = os.path.join(output_dir, \"evaluation_metrics.json\")\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics_to_save, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Deƒüerlendirme tamamlandƒ±!\")\n",
    "print(f\"\\nKey Metrics:\")\n",
    "print(f\"  Micro F1:    {metrics['micro_f1']:.4f}\")\n",
    "print(f\"  Macro F1:    {metrics['macro_f1']:.4f}\")\n",
    "print(f\"  Samples F1:  {metrics['samples_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc1197",
   "metadata": {},
   "source": [
    "## 8. Sonu√ßlarƒ± Kaydet ve ƒ∞ndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √ñzet dosyasƒ± olu≈ütur\n",
    "summary = {\n",
    "    'model': CONFIG['model_name'],\n",
    "    'timestamp': timestamp,\n",
    "    'configuration': CONFIG,\n",
    "    'data': {\n",
    "        'num_labels': num_labels,\n",
    "        'train_samples': len(train_dataset),\n",
    "        'test_samples': len(test_dataset)\n",
    "    },\n",
    "    'training': {\n",
    "        'final_loss': history['train_loss'][-1]\n",
    "    },\n",
    "    'evaluation': metrics_to_save\n",
    "}\n",
    "\n",
    "summary_file = os.path.join(output_dir, \"summary.json\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSonu√ßlar kaydedildi: {output_dir}\")\n",
    "print(\"\\nDosyalar:\")\n",
    "print(f\"  - labels.json\")\n",
    "print(f\"  - training_history.json\")\n",
    "print(f\"  - evaluation_metrics.json\")\n",
    "print(f\"  - summary.json\")\n",
    "print(f\"  - final_model.pt\")\n",
    "print(f\"  - checkpoint_epoch_*.pt\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335ef4f",
   "metadata": {},
   "source": [
    "## 9. Colab'da Sonu√ßlarƒ± ƒ∞ndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c90d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "    from google.colab import files\n",
    "    \n",
    "    # Sonu√ßlarƒ± ZIP'le\n",
    "    zip_name = f\"{run_name}.zip\"\n",
    "    shutil.make_archive(run_name, 'zip', output_dir)\n",
    "    \n",
    "    print(f\"\\nüì¶ Sonu√ßlar sƒ±kƒ±≈ütƒ±rƒ±lƒ±yor: {zip_name}\")\n",
    "    print(f\"   Boyut: {os.path.getsize(zip_name) / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # ƒ∞ndir\n",
    "    print(\"\\n‚¨áÔ∏è  ƒ∞ndirme ba≈ülatƒ±lƒ±yor...\")\n",
    "    files.download(zip_name)\n",
    "    print(\"‚úÖ ƒ∞ndirme tamamlandƒ±!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Yerel ortamdasƒ±nƒ±z, sonu√ßlar zaten bilgisayarƒ±nƒ±zda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7989e",
   "metadata": {},
   "source": [
    "## 10. (Opsiyonel) Farklƒ± Modelleri Dene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SecBERT modelini denemek i√ßin bu h√ºcreyi √ßalƒ±≈ütƒ±r\n",
    "# CONFIG['model_name'] = 'jackaduma/SecBERT'\n",
    "\n",
    "# DistilBERT modelini denemek i√ßin bu h√ºcreyi √ßalƒ±≈ütƒ±r  \n",
    "# CONFIG['model_name'] = 'distilbert-base-uncased'\n",
    "# CONFIG['batch_size'] = 32  # DistilBERT daha k√º√ß√ºk, batch size artƒ±rƒ±labilir\n",
    "\n",
    "# Sonra yukarƒ±daki h√ºcreleri tekrar √ßalƒ±≈ütƒ±r"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
