{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb270d6a",
      "metadata": {
        "id": "bb270d6a"
      },
      "source": [
        "## 1. Setup - Colab KontrolÃ¼ ve Proje Kurulumu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89af471e",
      "metadata": {
        "id": "89af471e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Colab kontrolÃ¼\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"âœ… Google Colab ortamÄ± tespit edildi\")\n",
        "\n",
        "    # GPU kontrolÃ¼\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    else:\n",
        "        print(\"âš ï¸  GPU bulunamadÄ±! Runtime > Change runtime type > GPU seÃ§in\")\n",
        "\n",
        "    # GitHub'dan projeyi klonla\n",
        "    print(\"\\nğŸ“¥ Proje indiriliyor...\")\n",
        "    !git clone https://github.com/Aliekinozcetin/Mitre_Attack_TTP_Mapping.git\n",
        "\n",
        "    # Proje dizinine geÃ§\n",
        "    os.chdir('Mitre_Attack_TTP_Mapping')\n",
        "    print(f\"âœ… Ã‡alÄ±ÅŸma dizini: {os.getcwd()}\")\n",
        "\n",
        "    # Gerekli paketleri yÃ¼kle (sadece temel ML paketleri, Jupyter paketleri hariÃ§)\n",
        "    print(\"\\nğŸ“¦ Paketler yÃ¼kleniyor...\")\n",
        "    !pip install -q torch transformers datasets scikit-learn pandas tqdm wandb matplotlib seaborn\n",
        "    print(\"âœ… TÃ¼m paketler yÃ¼klendi\")\n",
        "else:\n",
        "    print(\"â„¹ï¸  Yerel ortamda Ã§alÄ±ÅŸÄ±yorsunuz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e6ca280",
      "metadata": {
        "id": "9e6ca280"
      },
      "source": [
        "## 2. Import ModÃ¼ller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cf6a18",
      "metadata": {
        "id": "d9cf6a18"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from src.data_loader import prepare_data\n",
        "from src.model import load_model\n",
        "from src.train import train_model\n",
        "from src.evaluate import evaluate_model\n",
        "\n",
        "print(\"âœ… ModÃ¼ller yÃ¼klendi\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f6279ff",
      "metadata": {
        "id": "2f6279ff"
      },
      "source": [
        "## 3. KonfigÃ¼rasyon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4943e1b9",
      "metadata": {
        "id": "4943e1b9"
      },
      "outputs": [],
      "source": [
        "# Training parametreleri\n",
        "CONFIG = {\n",
        "    'model_name': 'bert-base-uncased',  # veya 'jackaduma/SecBERT', 'distilbert-base-uncased'\n",
        "    'max_length': 512,\n",
        "    'batch_size': 16,  # GPU varsa 32'ye Ã§Ä±karabilirsin\n",
        "    'learning_rate': 2e-5,\n",
        "    'num_epochs': 3,\n",
        "    'warmup_steps': 500,\n",
        "    'threshold': 0.5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'output_dir': './outputs'\n",
        "}\n",
        "\n",
        "# KonfigÃ¼rasyonu yazdÄ±r\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key:20s}: {value}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a4715c",
      "metadata": {
        "id": "16a4715c"
      },
      "source": [
        "## 4. Veri YÃ¼kleme ve HazÄ±rlama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ace414",
      "metadata": {
        "id": "10ace414"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: DATA PREPARATION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "data = prepare_data(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    max_length=CONFIG['max_length']\n",
        ")\n",
        "\n",
        "train_dataset = data['train_dataset']\n",
        "test_dataset = data['test_dataset']\n",
        "label_list = data['label_list']\n",
        "num_labels = data['num_labels']\n",
        "\n",
        "print(f\"\\nâœ… Veri hazÄ±rlama tamamlandÄ±!\")\n",
        "print(f\"   Train samples: {len(train_dataset)}\")\n",
        "print(f\"   Test samples: {len(test_dataset)}\")\n",
        "print(f\"   Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c9a687",
      "metadata": {
        "id": "f0c9a687"
      },
      "source": [
        "## 5. Model YÃ¼kleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f12260",
      "metadata": {
        "id": "78f12260"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 2: MODEL INITIALIZATION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "model = load_model(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    num_labels=num_labels,\n",
        "    device=CONFIG['device']\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Model yÃ¼klendi ve {CONFIG['device']} cihazÄ±na taÅŸÄ±ndÄ±!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d65fec12",
      "metadata": {
        "id": "d65fec12"
      },
      "source": [
        "## 6. Model EÄŸitimi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730aed8b",
      "metadata": {
        "id": "730aed8b"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 3: MODEL TRAINING\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Output dizini oluÅŸtur\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_name = f\"{CONFIG['model_name'].replace('/', '_')}_{timestamp}\"\n",
        "output_dir = os.path.join(CONFIG['output_dir'], run_name)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Label listesini kaydet\n",
        "label_file = os.path.join(output_dir, \"labels.json\")\n",
        "with open(label_file, 'w') as f:\n",
        "    json.dump(label_list, f, indent=2)\n",
        "\n",
        "# EÄŸitimi baÅŸlat\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    test_dataset=test_dataset,\n",
        "    output_dir=output_dir,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    learning_rate=CONFIG['learning_rate'],\n",
        "    num_epochs=CONFIG['num_epochs'],\n",
        "    warmup_steps=CONFIG['warmup_steps'],\n",
        "    device=CONFIG['device']\n",
        ")\n",
        "\n",
        "# Training geÃ§miÅŸini kaydet\n",
        "history_file = os.path.join(output_dir, \"training_history.json\")\n",
        "with open(history_file, 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… EÄŸitim tamamlandÄ±!\")\n",
        "print(f\"   Final train loss: {history['train_loss'][-1]:.4f}\")\n",
        "if 'val_loss' in history:\n",
        "    print(f\"   Final val loss: {history['val_loss'][-1]:.4f}\")\n",
        "\n",
        "# Loss grafiÄŸi\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "if 'val_loss' in history:\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training History')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(output_dir, 'training_loss.png'))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nğŸ“Š Loss grafiÄŸi kaydedildi: training_loss.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e9bbb0e",
      "metadata": {
        "id": "3e9bbb0e"
      },
      "source": [
        "## 7. Model DeÄŸerlendirme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2ae708",
      "metadata": {
        "id": "6d2ae708"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 4: MODEL EVALUATION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Ã–nce model Ã§Ä±ktÄ±larÄ±nÄ± kontrol et\n",
        "print(\"ğŸ” Model Ã§Ä±ktÄ±larÄ±nÄ± kontrol ediyorum...\")\n",
        "model.eval()\n",
        "sample_batch = next(iter(torch.utils.data.DataLoader(test_dataset, batch_size=16)))\n",
        "with torch.no_grad():\n",
        "    sample_out = model(\n",
        "        input_ids=sample_batch['input_ids'].to(CONFIG['device']),\n",
        "        attention_mask=sample_batch['attention_mask'].to(CONFIG['device'])\n",
        "    )\n",
        "    sample_probs = torch.sigmoid(sample_out['logits'])\n",
        "\n",
        "print(f\"\\nSample sigmoid outputs:\")\n",
        "print(f\"  Min: {sample_probs.min().item():.6f}\")\n",
        "print(f\"  Max: {sample_probs.max().item():.6f}\")\n",
        "print(f\"  Mean: {sample_probs.mean().item():.6f}\")\n",
        "print(f\"  Median: {sample_probs.median().item():.6f}\")\n",
        "\n",
        "# Otomatik threshold belirleme\n",
        "optimal_threshold = float(sample_probs.median().item())\n",
        "print(f\"\\nğŸ’¡ Ã–nerilen threshold: {optimal_threshold:.4f}\")\n",
        "\n",
        "# FarklÄ± threshold deÄŸerleri ile deÄŸerlendir\n",
        "thresholds_to_test = [0.1, 0.2, 0.3, optimal_threshold, 0.5]\n",
        "print(f\"\\nğŸ“Š FarklÄ± threshold deÄŸerleri test ediliyor...\")\n",
        "\n",
        "best_f1 = 0\n",
        "best_threshold = 0.5\n",
        "best_metrics = None\n",
        "\n",
        "for thresh in thresholds_to_test:\n",
        "    metrics = evaluate_model(\n",
        "        model=model,\n",
        "        test_dataset=test_dataset,\n",
        "        batch_size=CONFIG['batch_size'],\n",
        "        device=CONFIG['device'],\n",
        "        threshold=thresh,\n",
        "        label_list=label_list\n",
        "    )\n",
        "\n",
        "    if metrics['micro_f1'] > best_f1:\n",
        "        best_f1 = metrics['micro_f1']\n",
        "        best_threshold = thresh\n",
        "        best_metrics = metrics\n",
        "\n",
        "print(f\"\\nğŸ† En iyi threshold: {best_threshold:.4f}\")\n",
        "print(f\"   Micro F1: {best_f1:.4f}\")\n",
        "\n",
        "# En iyi metrikleri kaydet\n",
        "metrics_to_save = {k: float(v) if isinstance(v, (float, int)) else v\n",
        "                   for k, v in best_metrics.items()\n",
        "                   if k not in ['predictions', 'labels']}\n",
        "metrics_to_save['best_threshold'] = best_threshold\n",
        "\n",
        "metrics_file = os.path.join(output_dir, \"evaluation_metrics.json\")\n",
        "with open(metrics_file, 'w') as f:\n",
        "    json.dump(metrics_to_save, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… DeÄŸerlendirme tamamlandÄ±!\")\n",
        "print(f\"\\nFinal Metrics (threshold={best_threshold:.4f}):\")\n",
        "print(f\"  Micro F1:    {best_metrics['micro_f1']:.4f}\")\n",
        "print(f\"  Macro F1:    {best_metrics['macro_f1']:.4f}\")\n",
        "print(f\"  Samples F1:  {best_metrics['samples_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4cc1197",
      "metadata": {
        "id": "c4cc1197"
      },
      "source": [
        "## 8. SonuÃ§larÄ± Kaydet ve Ä°ndir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "226f7494",
      "metadata": {
        "id": "226f7494"
      },
      "outputs": [],
      "source": [
        "# Ã–zet dosyasÄ± oluÅŸtur\n",
        "summary = {\n",
        "    'model': CONFIG['model_name'],\n",
        "    'timestamp': timestamp,\n",
        "    'configuration': CONFIG,\n",
        "    'data': {\n",
        "        'num_labels': num_labels,\n",
        "        'train_samples': len(train_dataset),\n",
        "        'test_samples': len(test_dataset)\n",
        "    },\n",
        "    'training': {\n",
        "        'final_loss': history['train_loss'][-1]\n",
        "    },\n",
        "    'evaluation': metrics_to_save\n",
        "}\n",
        "\n",
        "summary_file = os.path.join(output_dir, \"summary.json\")\n",
        "with open(summary_file, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PIPELINE COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nSonuÃ§lar kaydedildi: {output_dir}\")\n",
        "print(\"\\nDosyalar:\")\n",
        "print(f\"  - labels.json\")\n",
        "print(f\"  - training_history.json\")\n",
        "print(f\"  - evaluation_metrics.json\")\n",
        "print(f\"  - summary.json\")\n",
        "print(f\"  - final_model.pt\")\n",
        "print(f\"  - checkpoint_epoch_*.pt\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b335ef4f",
      "metadata": {
        "id": "b335ef4f"
      },
      "source": [
        "## 9. Colab'da SonuÃ§larÄ± Ä°ndir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c90d65",
      "metadata": {
        "id": "44c90d65"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    import shutil\n",
        "    from google.colab import files\n",
        "\n",
        "    # SonuÃ§larÄ± ZIP'le\n",
        "    zip_name = f\"{run_name}.zip\"\n",
        "    shutil.make_archive(run_name, 'zip', output_dir)\n",
        "\n",
        "    print(f\"\\nğŸ“¦ SonuÃ§lar sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±yor: {zip_name}\")\n",
        "    print(f\"   Boyut: {os.path.getsize(zip_name) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    # Ä°ndir\n",
        "    print(\"\\nâ¬‡ï¸  Ä°ndirme baÅŸlatÄ±lÄ±yor...\")\n",
        "    files.download(zip_name)\n",
        "    print(\"âœ… Ä°ndirme tamamlandÄ±!\")\n",
        "else:\n",
        "    print(\"â„¹ï¸  Yerel ortamdasÄ±nÄ±z, sonuÃ§lar zaten bilgisayarÄ±nÄ±zda.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e7989e",
      "metadata": {
        "id": "48e7989e"
      },
      "source": [
        "## 10. (Opsiyonel) FarklÄ± Modelleri Dene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d018e9fb",
      "metadata": {
        "id": "d018e9fb"
      },
      "outputs": [],
      "source": [
        "# SecBERT modelini denemek iÃ§in bu hÃ¼creyi Ã§alÄ±ÅŸtÄ±r\n",
        "# CONFIG['model_name'] = 'jackaduma/SecBERT'\n",
        "\n",
        "# DistilBERT modelini denemek iÃ§in bu hÃ¼creyi Ã§alÄ±ÅŸtÄ±r\n",
        "# CONFIG['model_name'] = 'distilbert-base-uncased'\n",
        "# CONFIG['batch_size'] = 32  # DistilBERT daha kÃ¼Ã§Ã¼k, batch size artÄ±rÄ±labilir\n",
        "\n",
        "# Sonra yukarÄ±daki hÃ¼creleri tekrar Ã§alÄ±ÅŸtÄ±r"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}