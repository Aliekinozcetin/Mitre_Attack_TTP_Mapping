{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe9927e",
   "metadata": {},
   "source": [
    "# \ud83d\udee1\ufe0f CTI - MITRE ATT&CK TTP MAPPING PROJECT\n",
    "\n",
    "> **Ama\u00e7:** Siber tehdit istihbarat\u0131 (CTI) metinlerini otomatik olarak MITRE ATT&CK tekniklerine e\u015fle\u015ftirmek i\u00e7in derin \u00f6\u011frenme tabanl\u0131 multi-label s\u0131n\u0131fland\u0131rma sistemi.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83e\udd16 Model: CTI-BERT (IBM Research)\n",
    "\n",
    "| \u00d6zellik | De\u011fer |\n",
    "|---------|-------|\n",
    "| **Model** | `ibm-research/CTI-BERT` |\n",
    "| **Tip** | Domain-specific BERT |\n",
    "| **Avantaj** | G\u00fcvenlik ve CTI metinlerinde genel BERT'ten daha iyi performans |\n",
    "| **Embedding** | 768-dimensional |\n",
    "\n",
    "\ud83d\udcce [Hugging Face Model Card](https://huggingface.co/ibm-research/CTI-BERT)\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcca Dataset: Security-TTP-Mapping\n",
    "\n",
    "| \u00d6zellik | De\u011fer |\n",
    "|---------|-------|\n",
    "| **Kaynak** | `tumeteor/Security-TTP-Mapping` |\n",
    "| **Train** | 14.9k \u00f6rnek |\n",
    "| **Test** | 2.6k \u00f6rnek |\n",
    "| **Labels** | 499 MITRE ATT&CK tekni\u011fi |\n",
    "\n",
    "\ud83d\udcce [Hugging Face Dataset](https://huggingface.co/datasets/tumeteor/Security-TTP-Mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6204197",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udd27 SETUP \n",
    "> Colab ortam\u0131nda proje kurulumu ve ba\u011f\u0131ml\u0131l\u0131klar\u0131n y\u00fcklenmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4016e0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: /content/Mitre_Attack_TTP_Mapping\n",
      "\n",
      "\u26a1 OPTIMIZATION APPLIED:\n",
      "   - ExtraTreesClassifier: 50 trees (was 100)\n",
      "   - RandomForestClassifier: 50 trees (was 100)\n",
      "   - max_features='sqrt' (~28 features per split instead of 768)\n",
      "   - min_samples_split=20 (faster splits)\n",
      "   - Expected speedup: ~4x faster training!\n",
      "\n",
      "   If training was stuck, Runtime > Interrupt execution, then re-run from Strategy cell\n",
      "\n",
      "\u2139\ufe0f  Yerel ortamda \u00e7al\u0131\u015f\u0131yorsunuz\n"
     ]
    }
   ],
   "source": [
    "# Update repository to latest version (get optimized tree classifiers)\n",
    "!cd /content/Mitre_Attack_TTP_Mapping && git pull origin main\n",
    "\n",
    "print(\"\\n\u26a1 OPTIMIZATION APPLIED:\")\n",
    "print(\"   - ExtraTreesClassifier: 50 trees (was 100)\")\n",
    "print(\"   - RandomForestClassifier: 50 trees (was 100)\")\n",
    "print(\"   - max_features='sqrt' (~28 features per split instead of 768)\")\n",
    "print(\"   - min_samples_split=20 (faster splits)\")\n",
    "print(\"   - Expected speedup: ~4x faster training!\")\n",
    "print(\"\\n   If training was stuck, Runtime > Interrupt execution, then re-run from Strategy cell\\n\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\u2705 Google Colab ortam\u0131 tespit edildi\")\n",
    "    \n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\u2705 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  GPU bulunamad\u0131! Runtime > Change runtime type > GPU se\u00e7in\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udce5 Proje indiriliyor...\")\n",
    "    !rm -rf Mitre_Attack_TTP_Mapping\n",
    "    !git clone https://github.com/Aliekinozcetin/Mitre_Attack_TTP_Mapping.git\n",
    "    os.chdir('Mitre_Attack_TTP_Mapping')\n",
    "    print(f\"\u2705 \u00c7al\u0131\u015fma dizini: {os.getcwd()}\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udce6 Paketler y\u00fckleniyor...\")\n",
    "    !pip install -q torch transformers datasets scikit-learn pandas tqdm matplotlib seaborn\n",
    "    print(\"\u2705 T\u00fcm paketler y\u00fcklendi\")\n",
    "    \n",
    "    # HuggingFace ba\u011flant\u0131 optimizasyonu\n",
    "    print(\"\\n\ud83d\udd27 HuggingFace cache ayarlar\u0131...\")\n",
    "    \n",
    "    # Create cache directory\n",
    "    cache_dir = '/content/hf_cache'\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    # Set environment variables\n",
    "    os.environ['HF_HOME'] = cache_dir\n",
    "    os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "    os.environ['HF_DATASETS_CACHE'] = cache_dir\n",
    "    os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '600'  # 10 minutes\n",
    "    os.environ['CURL_CA_BUNDLE'] = ''\n",
    "    os.environ['HF_ENDPOINT'] = 'https://huggingface.co'\n",
    "    os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'  # Faster downloads\n",
    "    \n",
    "    print(f\"\u2705 Cache dizini olu\u015fturuldu: {cache_dir}\")\n",
    "    print(f\"   Timeout: 10 dakika\")\n",
    "    \n",
    "    # Test HuggingFace connection\n",
    "    try:\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        print(\"\\n\ud83d\udce1 HuggingFace ba\u011flant\u0131 testi...\")\n",
    "        info = api.model_info(\"ibm-research/CTI-BERT\", timeout=30)\n",
    "        print(f\"\u2705 Model eri\u015filebilir: {info.modelId}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Ba\u011flant\u0131 uyar\u0131s\u0131: {str(e)[:100]}\")\n",
    "        print(\"   Model indirme denemeye devam edilecek...\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f  Yerel ortamda \u00e7al\u0131\u015f\u0131yorsunuz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044287e",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udce6 Import Modules\n",
    "> Gerekli k\u00fct\u00fcphaneleri ve proje mod\u00fcllerini y\u00fckle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4696cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc.strategies\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc.strategies\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import project modules\n",
    "from src.data_loader import prepare_data, load_datasets_and_prepare_dataloaders\n",
    "from src.model import load_model\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model\n",
    "from src.strategies import get_strategy_config\n",
    "from src.augmentation import replace_iocs, back_translate, augment_tail_samples\n",
    "\n",
    "print(\"\u2705 Mod\u00fcller y\u00fcklendi\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82a7c4",
   "metadata": {},
   "source": [
    "---\n",
    "## \u2699\ufe0f Configuration\n",
    "> E\u011fitim parametrelerini ve \u00e7\u0131kt\u0131 dizinini ayarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aaecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base training configuration\n",
    "BASE_CONFIG = {\n",
    "    'model_name': 'ibm-research/CTI-BERT',  # CTI domain-specific BERT\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_epochs': 5,\n",
    "    'max_length': 128,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Store results from all strategies\n",
    "all_test_results = {}\n",
    "\n",
    "print(\"\u2705 Konfig\u00fcrasyon ayarland\u0131\")\n",
    "print(f\"Model: {BASE_CONFIG['model_name']}\")\n",
    "print(f\"Device: {BASE_CONFIG['device']}\")\n",
    "print(f\"Output: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c082e5",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udce5 Data Loading\n",
    "> Dataset'i y\u00fckle ve DataLoader'lar\u0131 olu\u015ftur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\udce5 Veri y\u00fckleniyor...\")\n",
    "print(\"\ud83d\udce6 Dataset: tumeteor/Security-TTP-Mapping (Single Source)\")\n",
    "print(f\"\ud83e\udd16 Model: {BASE_CONFIG['model_name']}\")\n",
    "print(\"\")\n",
    "\n",
    "# Use single dataset: tumeteor only\n",
    "train_dataloader, val_dataloader, test_dataset, label_names = load_datasets_and_prepare_dataloaders(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    max_length=BASE_CONFIG['max_length'],\n",
    "    dataset_name=\"tumeteor/Security-TTP-Mapping\"\n",
    ")\n",
    "\n",
    "# Get train_dataset from dataloader for strategies\n",
    "train_dataset = train_dataloader.dataset\n",
    "\n",
    "# Create test dataloader\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_labels = len(label_names)\n",
    "\n",
    "# Create data dict for backward compatibility\n",
    "data = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'test_dataset': test_dataset,\n",
    "    'label_list': label_names,\n",
    "    'num_labels': num_labels\n",
    "}\n",
    "\n",
    "print(f\"\u2705 Veri y\u00fcklendi\")\n",
    "print(f\"   Train batches: {len(train_dataloader)}\")\n",
    "print(f\"   Test batches: {len(test_dataloader)}\")\n",
    "print(f\"   Toplam label say\u0131s\u0131: {num_labels}\")\n",
    "print(f\"   \u0130lk 5 label: {label_names[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de26a69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcca EXPERIMENT STRUCTURE\n",
    "\n",
    "> \u00dc\u00e7 a\u015famal\u0131 deneysel \u00e7al\u0131\u015fma ile optimal TTP mapping stratejisini bulma.\n",
    "\n",
    "| B\u00f6l\u00fcm | A\u00e7\u0131klama | Strateji Say\u0131s\u0131 | Tahmini S\u00fcre |\n",
    "|-------|----------|-----------------|--------------|\n",
    "| **PART A** | Data Augmentation | 5 strateji | ~4-5 saat |\n",
    "| **PART B** | Loss Functions + Capacity | 4 + 5 strateji | ~5-6 saat |\n",
    "| **PART C** | Hybrid (Loss \u00d7 Classification) | 10 strateji | ~7.5-10 saat |\n",
    "\n",
    "### \ud83c\udfaf \u00d6nerilen \u00c7al\u0131\u015ft\u0131rma S\u0131ras\u0131:\n",
    "1. **PART A** \u2192 En iyi augmentation y\u00f6ntemini bul\n",
    "2. **PART B** \u2192 En iyi loss function'\u0131 belirle  \n",
    "3. **PART C** \u2192 Optimal kombinasyonu ke\u015ffet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7ad4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udd04 PART A: DATA AUGMENTATION EXPERIMENTS\n",
    "\n",
    "> **Hedef:** Tail TTP'lerin (az g\u00f6r\u00fclen teknikler) performans\u0131n\u0131 art\u0131rmak i\u00e7in veri augmentation stratejilerini test et.\n",
    "\n",
    "\u26a0\ufe0f **\u00d6ncelik:** Bu b\u00f6l\u00fcm\u00fc PART B ve C'den \u00d6NCE \u00e7al\u0131\u015ft\u0131r\u0131n!\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udccb Augmentation Y\u00f6ntemleri\n",
    "\n",
    "| Y\u00f6ntem | A\u00e7\u0131klama | Etki |\n",
    "|--------|----------|------|\n",
    "| **IoC Replacement** | IP, domain, hash, file path de\u011fi\u015ftirme | Overfitting'i \u00f6nler |\n",
    "| **Back-translation** | EN \u2192 DE \u2192 EN paraphrasing | Semantic \u00e7e\u015fitlilik |\n",
    "| **Tail Oversampling** | Rare TTP'leri 3x-10x \u00e7o\u011faltma | Class balance |\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83e\uddea Test Stratejileri\n",
    "\n",
    "| Strateji | A\u00e7\u0131klama | S\u00fcre |\n",
    "|----------|----------|------|\n",
    "| **AUG-1** | Baseline (No Augmentation) | ~30-40 dk |\n",
    "| **AUG-2** | IoC Replacement Only | ~30-40 dk |\n",
    "| **AUG-3** | Back-translation Only | ~40-50 dk |\n",
    "| **AUG-4** | Oversampling Only | ~30-40 dk |\n",
    "| **AUG-5** | Combined (All 3 methods) | ~50-60 dk |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f4abc",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 AUG-1: Baseline (No Augmentation)\n",
    "> Referans performans i\u00e7in augmentation olmadan Weighted BCE.  \n",
    "> \u23f1\ufe0f ~30-40 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26356171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "strategy_name = \"aug_baseline\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea AUG-1: Baseline (No Augmentation)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "# Use weighted BCE (best performing strategy)\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "strategy_train_dataloader = DataLoader(\n",
    "    strategy_config['dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"\ud83d\udccb Konfig\u00fcrasyon:\")\n",
    "print(f\"   Strategy: Weighted BCE (Baseline for comparison)\")\n",
    "print(f\"   Augmentation: NONE\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "# Store results\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': 'Weighted BCE (No Augmentation)',\n",
    "    'description': 'Baseline for augmentation comparison',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 AUG-1 TAMAMLANDI: {strategy_name}\")\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca01e99",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 AUG-2: IoC Replacement Only\n",
    "> IP, domain, hash, file path de\u011fi\u015ftirme ile overfitting'i \u00f6nle.  \n",
    "> \u23f1\ufe0f ~30-40 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_ioc_replacement\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea AUG-2: IoC Replacement\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "# Load raw dataset for text augmentation\n",
    "print(\"\ud83d\udd04 Loading raw dataset for IoC replacement...\")\n",
    "from datasets import load_dataset\n",
    "import ast\n",
    "\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Find text column\n",
    "print(f\"Available columns: {train_df.columns.tolist()}\")\n",
    "possible_text_cols = ['text1', 'description', 'text', 'content', 'sentence']\n",
    "text_column = None\n",
    "for col in possible_text_cols:\n",
    "    if col in train_df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise ValueError(f\"No text column found! Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_column}\")\n",
    "\n",
    "# Apply IoC replacement to texts\n",
    "print(\"Replacing IoCs in training texts...\")\n",
    "augmented_train_texts = []\n",
    "for text in train_df[text_column].fillna('').tolist():\n",
    "    # Original + 2 IoC-replaced versions\n",
    "    augmented_train_texts.append(text)  # Original\n",
    "    augmented_train_texts.append(replace_iocs(text, seed=42))  # Aug 1\n",
    "    augmented_train_texts.append(replace_iocs(text, seed=123))  # Aug 2\n",
    "\n",
    "# Replicate labels accordingly\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "\n",
    "# Parse labels\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Expand labels to match augmented texts\n",
    "augmented_train_labels = []\n",
    "for labels in train_labels_raw:\n",
    "    augmented_train_labels.append(labels)  # Original\n",
    "    augmented_train_labels.append(labels)  # Aug 1\n",
    "    augmented_train_labels.append(labels)  # Aug 2\n",
    "\n",
    "print(f\"\u2705 Original samples: {len(train_df)}\")\n",
    "print(f\"\u2705 Augmented samples: {len(augmented_train_texts)} (3x augmentation)\")\n",
    "\n",
    "# Prepare augmented data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create custom dataset\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_train_texts,\n",
    "    augmented_train_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "# Store results\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': 'Weighted BCE + IoC Replacement (3x)',\n",
    "    'description': 'Training data augmented with IoC replacement only',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 AUG-2 TAMAMLANDI: {strategy_name}\")\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e4284",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 AUG-3: Back-translation Only\n",
    "> EN \u2192 DE \u2192 EN paraphrasing ile semantic \u00e7e\u015fitlilik.  \n",
    "> Tail TTP \u00f6rneklerinin %15'ine uygulan\u0131r.  \n",
    "> \u23f1\ufe0f ~40-50 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_back_translation\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea AUG-3: Back-translation\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "# Load raw data\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Parse labels\n",
    "import ast\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Calculate label frequencies\n",
    "from collections import Counter\n",
    "label_counter = Counter()\n",
    "for labels in train_labels_raw:\n",
    "    label_counter.update(labels)\n",
    "\n",
    "# Identify tail TTPs (frequency < 10)\n",
    "tail_threshold = 10\n",
    "tail_ttps = {label for label, count in label_counter.items() if count < tail_threshold}\n",
    "print(f\"\ud83d\udcca Tail TTPs detected: {len(tail_ttps)} (frequency < {tail_threshold})\")\n",
    "\n",
    "# Identify samples with tail TTPs\n",
    "tail_sample_indices = []\n",
    "for idx, labels in enumerate(train_labels_raw):\n",
    "    if any(label in tail_ttps for label in labels):\n",
    "        tail_sample_indices.append(idx)\n",
    "\n",
    "print(f\"\ud83d\udcca Samples with tail TTPs: {len(tail_sample_indices)} / {len(train_df)}\")\n",
    "\n",
    "# Apply back-translation to 15% of tail samples (faster)\n",
    "import random\n",
    "random.seed(42)\n",
    "num_to_augment = int(len(tail_sample_indices) * 0.15)\n",
    "samples_to_augment = random.sample(tail_sample_indices, num_to_augment)\n",
    "\n",
    "print(f\"\ud83d\udd04 Applying back-translation to {num_to_augment} samples...\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_train_texts = train_df[text_column].fillna('').tolist()\n",
    "augmented_train_labels = train_labels_raw.copy()\n",
    "\n",
    "# Load translation models (lazy loading)\n",
    "back_translate_cached = {}\n",
    "\n",
    "for idx in samples_to_augment:\n",
    "    original_text = train_df.iloc[idx][text_column]\n",
    "    if pd.isna(original_text) or len(original_text.strip()) < 10:\n",
    "        continue\n",
    "    \n",
    "    # Back-translate\n",
    "    try:\n",
    "        bt_text = back_translate(original_text, pivot_lang='de')\n",
    "        if bt_text and bt_text != original_text:\n",
    "            # Add augmented sample\n",
    "            augmented_train_texts.append(bt_text)\n",
    "            augmented_train_labels.append(train_labels_raw[idx])\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f Back-translation failed for sample {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Original samples: {len(train_df)}\")\n",
    "print(f\"Augmented samples: {len(augmented_train_texts)} (+{len(augmented_train_texts) - len(train_df)} from back-translation)\")\n",
    "\n",
    "# Create custom dataset\n",
    "from src.data_loader import prepare_data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_train_texts,\n",
    "    augmented_train_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "# Store results\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': 'Weighted BCE + Back-translation (30% tail)',\n",
    "    'description': 'Training data augmented with back-translation for tail TTPs',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 AUG-3 TAMAMLANDI: {strategy_name}\")\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee08d69",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 AUG-4: Oversampling Only\n",
    "> Tail TTP'leri 3x-10x \u00e7o\u011faltarak class balance sa\u011fla.  \n",
    "> En h\u0131zl\u0131 augmentation y\u00f6ntemi.  \n",
    "> \u23f1\ufe0f ~30-40 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_oversampling\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea AUG-4: Oversampling Only\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Load raw data\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Find text column\n",
    "possible_text_cols = ['text1', 'description', 'text', 'content', 'sentence']\n",
    "text_column = None\n",
    "for col in possible_text_cols:\n",
    "    if col in train_df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise ValueError(f\"No text column found! Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_column}\")\n",
    "\n",
    "# Parse labels\n",
    "import ast\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Calculate label frequencies\n",
    "from collections import Counter\n",
    "label_counter = Counter()\n",
    "for labels in train_labels_raw:\n",
    "    label_counter.update(labels)\n",
    "\n",
    "# Identify tail TTPs (frequency < 10)\n",
    "tail_threshold = 10\n",
    "tail_ttps = {label for label, count in label_counter.items() if count < tail_threshold}\n",
    "print(f\"\ud83d\udcca Tail TTPs detected: {len(tail_ttps)} (frequency < {tail_threshold})\")\n",
    "\n",
    "# Get training texts\n",
    "train_texts = train_df[text_column].fillna('').tolist()\n",
    "\n",
    "# Apply oversampling only\n",
    "augmented_texts = train_texts.copy()\n",
    "augmented_labels = train_labels_raw.copy()\n",
    "\n",
    "print(f\"\ud83d\udd04 Applying oversampling to tail TTPs...\")\n",
    "\n",
    "for idx, labels in enumerate(train_labels_raw):\n",
    "    # Check if sample has tail TTPs\n",
    "    if any(label in tail_ttps for label in labels):\n",
    "        # Calculate oversample factor based on min frequency\n",
    "        min_freq = min([label_counter[label] for label in labels if label in tail_ttps])\n",
    "        oversample_factor = max(3, min(10, 100 // min_freq))  # 3x-10x based on frequency\n",
    "        \n",
    "        # Oversample\n",
    "        for _ in range(oversample_factor - 1):  # -1 because original is already in list\n",
    "            augmented_texts.append(train_texts[idx])\n",
    "            augmented_labels.append(labels)\n",
    "\n",
    "print(f\"Original samples: {len(train_texts)}\")\n",
    "print(f\"Augmented samples: {len(augmented_texts)}\")\n",
    "print(f\"Augmentation ratio: {len(augmented_texts) / len(train_texts):.2f}x\")\n",
    "\n",
    "# Create custom dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_texts,\n",
    "    augmented_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': 'Weighted BCE + Oversampling Only',\n",
    "    'description': 'Training data augmented with tail TTP oversampling',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 AUG-4 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351506a",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 AUG-5: Combined (IoC + Back-translation + Oversampling)\n",
    "> T\u00fcm augmentation y\u00f6ntemlerinin birlikte uyguland\u0131\u011f\u0131 strateji.  \n",
    "> En kapsaml\u0131 veri zenginle\u015ftirme.  \n",
    "> \u23f1\ufe0f ~50-60 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_combined\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea AUG-5: Combined Augmentation (All Methods)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Load raw data\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Find text column\n",
    "possible_text_cols = ['text1', 'description', 'text', 'content', 'sentence']\n",
    "text_column = None\n",
    "for col in possible_text_cols:\n",
    "    if col in train_df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise ValueError(f\"No text column found! Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_column}\")\n",
    "\n",
    "# Parse labels\n",
    "import ast\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Calculate label frequencies\n",
    "from collections import Counter\n",
    "label_counter = Counter()\n",
    "for labels in train_labels_raw:\n",
    "    label_counter.update(labels)\n",
    "\n",
    "# Identify tail TTPs (frequency < 10)\n",
    "tail_threshold = 10\n",
    "tail_ttps = {label for label, count in label_counter.items() if count < tail_threshold}\n",
    "print(f\"\ud83d\udcca Tail TTPs detected: {len(tail_ttps)} (frequency < {tail_threshold})\")\n",
    "\n",
    "# Get training texts\n",
    "train_texts = train_df[text_column].fillna('').tolist()\n",
    "\n",
    "print(f\"\ud83d\udd04 Applying COMBINED augmentation...\")\n",
    "print(f\"   - IoC Replacement\")\n",
    "print(f\"   - Back-translation (15% probability)\")\n",
    "print(f\"   - Tail Oversampling (3x-10x)\")\n",
    "\n",
    "# Apply combined augmentation\n",
    "augmented_texts = train_texts.copy()\n",
    "augmented_labels = train_labels_raw.copy()\n",
    "\n",
    "for idx, labels in enumerate(train_labels_raw):\n",
    "    # Check if sample has tail TTPs\n",
    "    if any(label in tail_ttps for label in labels):\n",
    "        # Calculate oversample factor based on min frequency\n",
    "        min_freq = min([label_counter[label] for label in labels if label in tail_ttps])\n",
    "        oversample_factor = max(3, min(10, 100 // min_freq))  # 3x-10x based on frequency\n",
    "        \n",
    "        # Oversample with augmentation\n",
    "        for _ in range(oversample_factor - 1):  # -1 because original is already in list\n",
    "            augmented_text = train_texts[idx]\n",
    "            \n",
    "            # Apply IoC replacement\n",
    "            augmented_text = replace_iocs(augmented_text)\n",
    "            \n",
    "            # Apply back-translation with 15% probability\n",
    "            import random\n",
    "            if random.random() < 0.15:\n",
    "                augmented_text = back_translate(augmented_text, device=BASE_CONFIG['device'])\n",
    "            \n",
    "            augmented_texts.append(augmented_text)\n",
    "            augmented_labels.append(labels)\n",
    "\n",
    "print(f\"\\nOriginal samples: {len(train_texts)}\")\n",
    "print(f\"Augmented samples: {len(augmented_texts)}\")\n",
    "print(f\"Augmentation ratio: {len(augmented_texts) / len(train_texts):.2f}x\")\n",
    "\n",
    "# Create custom dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_texts,\n",
    "    augmented_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': 'Weighted BCE + Combined Augmentation',\n",
    "    'description': 'Training data augmented with IoC replacement, back-translation, and tail oversampling',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 AUG-5 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18e9a8",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcca Part A Results: Augmentation Comparison\n",
    "> T\u00fcm augmentation stratejilerini kar\u015f\u0131la\u015ft\u0131r ve en iyi performans\u0131 belirle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract augmentation results for comparison\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"\ud83d\udcca AUGMENTATION STRATEGIES COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Define the desired order of strategies for the x-axis (must match strategy_name in each cell)\n",
    "ordered_strategies = ['aug_baseline', 'aug_ioc_replacement', 'aug_back_translation', 'aug_oversampling', 'aug_combined']\n",
    "aug_comparison_data = []\n",
    "\n",
    "for strategy_name in ordered_strategies:\n",
    "    if strategy_name in all_test_results:\n",
    "        data = all_test_results[strategy_name]\n",
    "        results = data['results']\n",
    "        aug_comparison_data.append({\n",
    "            'Strategy': data['config'],\n",
    "            'Training_Time_min': data.get('training_time_min', 0),\n",
    "            'mAP': results.get('mean_average_precision', 0),\n",
    "            'Micro_F1': results.get('micro_f1', 0),\n",
    "            'Recall@5': results.get('recall_at_5', 0),\n",
    "            'Precision@5': results.get('precision_at_5', 0),\n",
    "            'Recall@10': results.get('recall_at_10', 0),\n",
    "            'Precision@10': results.get('precision_at_10', 0),\n",
    "            'Hamming_Loss': results.get('hamming_loss', 0),\n",
    "            'Micro_Precision': results.get('micro_precision', 0),\n",
    "            'Micro_Recall': results.get('micro_recall', 0)\n",
    "        })\n",
    "\n",
    "if len(aug_comparison_data) > 0:\n",
    "    df_aug_comparison = pd.DataFrame(aug_comparison_data)\n",
    "    \n",
    "    # Ensure the DataFrame is in the desired order\n",
    "    df_aug_comparison['Strategy'] = pd.Categorical(df_aug_comparison['Strategy'], categories=[all_test_results[s]['config'] for s in ordered_strategies if s in all_test_results], ordered=True)\n",
    "    df_aug_comparison = df_aug_comparison.sort_values('Strategy')\n",
    "    \n",
    "    # Export CSV (includes all metrics including @10)\n",
    "    import os\n",
    "    aug_csv_path = 'outputs/augmentation_comparison.csv'\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    df_aug_comparison.to_csv(aug_csv_path, index=False)\n",
    "    print(f\"\u2705 CSV exported to: {aug_csv_path}\\n\")\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(\"\\n\ud83d\udccb Augmentation Performance Comparison (Ordered by Implementation):\")\n",
    "    print(df_aug_comparison.to_string(index=False))\n",
    "    \n",
    "    # Find best strategies\n",
    "    print(\"\\n\ud83c\udfc6 Best Performers:\")\n",
    "    print(f\"   Best mAP: {df_aug_comparison.loc[df_aug_comparison['mAP'].idxmax(), 'Strategy']} ({df_aug_comparison['mAP'].max():.4f})\")\n",
    "    print(f\"   Best Micro F1: {df_aug_comparison.loc[df_aug_comparison['Micro_F1'].idxmax(), 'Strategy']} ({df_aug_comparison['Micro_F1'].max():.4f})\")\n",
    "    print(f\"   Best Recall@5: {df_aug_comparison.loc[df_aug_comparison['Recall@5'].idxmax(), 'Strategy']} ({df_aug_comparison['Recall@5'].max():.4f})\")\n",
    "    print(f\"   Best Precision@5: {df_aug_comparison.loc[df_aug_comparison['Precision@5'].idxmax(), 'Strategy']} ({df_aug_comparison['Precision@5'].max():.4f})\")\n",
    "    print(f\"   Lowest Hamming Loss: {df_aug_comparison.loc[df_aug_comparison['Hamming_Loss'].idxmin(), 'Strategy']} ({df_aug_comparison['Hamming_Loss'].min():.4f})\")\n",
    "    \n",
    "    # Create output directory for plots\n",
    "    aug_plots_dir = 'outputs/augmentation_plots'\n",
    "    os.makedirs(aug_plots_dir, exist_ok=True)\n",
    "    \n",
    "    strategies = df_aug_comparison['Strategy'].tolist()\n",
    "    x_pos = np.arange(len(strategies))\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca Creating LINE CHART visualizations...\")\n",
    "\n",
    "    # ========== 1. mAP LINE CHART ==========\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['mAP'].tolist()\n",
    "    ax1.plot(x_pos, values, marker='o', linewidth=2.5, markersize=10, color='#06A77D', label='mAP')\n",
    "    ax1.fill_between(x_pos, values, alpha=0.2, color='#06A77D')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Mean Average Precision (mAP)', fontsize=12)\n",
    "    ax1.set_title('Augmentation Strategies: mAP Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax1.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax1.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/map_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 mAP line chart saved\")\n",
    "    \n",
    "    # ========== 2. RECALL@5 LINE CHART ==========\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Recall@5'].tolist()\n",
    "    ax2.plot(x_pos, values, marker='s', linewidth=2.5, markersize=10, color='#F39C12', label='Recall@5')\n",
    "    ax2.fill_between(x_pos, values, alpha=0.2, color='#F39C12')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Recall@5', fontsize=12)\n",
    "    ax2.set_title('Augmentation Strategies: Recall@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax2.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax2.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/recall_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Recall@5 line chart saved\")\n",
    "    \n",
    "    # ========== 3. PRECISION@5 LINE CHART ==========\n",
    "    fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Precision@5'].tolist()\n",
    "    ax3.plot(x_pos, values, marker='D', linewidth=2.5, markersize=10, color='#17A589', label='Precision@5')\n",
    "    ax3.fill_between(x_pos, values, alpha=0.2, color='#17A589')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Precision@5', fontsize=12)\n",
    "    ax3.set_title('Augmentation Strategies: Precision@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax3.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax3.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/precision_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Precision@5 line chart saved\")\n",
    "    \n",
    "    # ========== 4. MICRO F1 LINE CHART ==========\n",
    "    fig4, ax4 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Micro_F1'].tolist()\n",
    "    ax4.plot(x_pos, values, marker='p', linewidth=2.5, markersize=10, color='#8E44AD', label='Micro F1')\n",
    "    ax4.fill_between(x_pos, values, alpha=0.2, color='#8E44AD')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax4.set_ylabel('Micro F1 Score', fontsize=12)\n",
    "    ax4.set_title('Augmentation Strategies: Micro F1 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax4.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax4.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/micro_f1_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Micro F1 line chart saved\")\n",
    "    \n",
    "    # ========== 5. HAMMING LOSS LINE CHART ==========\n",
    "    fig5, ax5 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Hamming_Loss'].tolist()\n",
    "    ax5.plot(x_pos, values, marker='^', linewidth=2.5, markersize=10, color='#E74C3C', label='Hamming Loss')\n",
    "    ax5.fill_between(x_pos, values, alpha=0.2, color='#E74C3C')\n",
    "    ax5.set_xticks(x_pos)\n",
    "    ax5.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax5.set_ylabel('Hamming Loss', fontsize=12)\n",
    "    ax5.set_title('Augmentation Strategies: Hamming Loss Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax5.set_ylim([min(values)*0.9, max(values)*1.1])\n",
    "    for i, val in enumerate(values):\n",
    "        ax5.text(i, val + (max(values) - min(values))*0.02, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/hamming_loss_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Hamming Loss line chart saved\")\n",
    "    \n",
    "    # ========== 6. TRAINING TIME LINE CHART ==========\n",
    "    fig6, ax6 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Training_Time_min'].tolist()\n",
    "    ax6.plot(x_pos, values, marker='h', linewidth=2.5, markersize=10, color='#34495E', label='Training Time (min)')\n",
    "    ax6.fill_between(x_pos, values, alpha=0.2, color='#34495E')\n",
    "    ax6.set_xticks(x_pos)\n",
    "    ax6.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax6.set_ylabel('Training Time (minutes)', fontsize=12)\n",
    "    ax6.set_title('Augmentation Strategies: Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "    ax6.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax6.set_ylim([0, max(values)*1.15])\n",
    "    for i, val in enumerate(values):\n",
    "        ax6.text(i, val + 5, f'{val:.1f}', ha='center', fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/training_time_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Training Time line chart saved\")\n",
    "    \n",
    "    print(f\"\\n\u2705 All line charts saved to: {aug_plots_dir}/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\ud83d\udcc1 EXPORTED FILES:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  \u2022 CSV: {aug_csv_path} (includes @10 metrics)\")\n",
    "    print(f\"  \u2022 Line Charts: {aug_plots_dir}/\")\n",
    "    print(\"    - map_comparison.png\")\n",
    "    print(\"    - recall_5_comparison.png\")\n",
    "    print(\"    - precision_5_comparison.png\")\n",
    "    print(\"    - micro_f1_comparison.png\")\n",
    "    print(\"    - hamming_loss_comparison.png\")\n",
    "    print(\"    - training_time_comparison.png\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No augmentation results found. Please run strategies A-1 to A-4 first.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f52529",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udd04 PART B: LOSS FUNCTION STRATEGIES\n",
    "\n",
    "> **Hedef:** Farkl\u0131 loss fonksiyonlar\u0131n\u0131n multi-label s\u0131n\u0131fland\u0131rma performans\u0131na etkisini test et.\n",
    "\n",
    "\ud83d\udca1 **Not:** Bu stratejileri PART A'dan sonra, en iyi augmentation y\u00f6ntemi ile \u00e7al\u0131\u015ft\u0131r\u0131n.\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83e\uddea Test Stratejileri\n",
    "\n",
    "| Strateji | Loss Function | \u00d6zellik | S\u00fcre |\n",
    "|----------|---------------|---------|------|\n",
    "| **B-1** | Baseline BCE | Standart loss, referans | ~30-45 dk |\n",
    "| **B-2** | Weighted BCE | Frekans bazl\u0131 a\u011f\u0131rl\u0131klar | ~30-45 dk |\n",
    "| **B-3** | Focal Loss (\u03b3=2) | Moderate hard example focusing | ~30-45 dk |\n",
    "| **B-4** | Focal Loss (\u03b3=5) | Strong hard example focusing | ~30-45 dk |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c7ec3",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 B-1: Baseline (Standard BCE Loss)\n",
    "> Standart Binary Cross-Entropy loss. Referans performans i\u00e7in baseline.  \n",
    "> \u23f1\ufe0f ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"baseline\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea STRATEGY 1: Baseline BCE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"\ud83d\udccb Konfig\u00fcrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['pos_weight'] is not None:\n",
    "    print(f\"   Pos weight: min={strategy_config['pos_weight'].min():.2f}, max={strategy_config['pos_weight'].max():.2f}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 STRATEGY 1 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd655b",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 B-2: Weighted BCE Loss\n",
    "> Frekans bazl\u0131 a\u011f\u0131rl\u0131klar (pos_weight) ile class imbalance'\u0131 \u00e7\u00f6z.  \n",
    "> En etkili baseline y\u00f6ntem.  \n",
    "> \u23f1\ufe0f ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a054e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"weighted\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea STRATEGY 2: Weighted BCE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"\ud83d\udccb Konfig\u00fcrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['pos_weight'] is not None:\n",
    "    print(f\"   Pos weight: min={strategy_config['pos_weight'].min():.2f}, max={strategy_config['pos_weight'].max():.2f}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 STRATEGY 2 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028aa98",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 B-3: Focal Loss (\u03b3=2)\n",
    "> Moderate hard example focusing. Yanl\u0131\u015f s\u0131n\u0131fland\u0131r\u0131lan \u00f6rneklere odaklan.  \n",
    "> \u23f1\ufe0f ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"focal_weak\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea STRATEGY 3: Focal Loss (\u03b3=2)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"\ud83d\udccb Konfig\u00fcrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['use_focal_loss']:\n",
    "    print(f\"   Focal alpha: {strategy_config.get('focal_alpha')}\")\n",
    "    print(f\"   Focal gamma: {strategy_config.get('focal_gamma')}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 STRATEGY 3 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b7263",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 B-4: Focal Loss (\u03b3=5)\n",
    "> Strong hard example focusing. Tail TTP'ler i\u00e7in potansiyel iyile\u015ftirme.  \n",
    "> \u23f1\ufe0f ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"focal_strong\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea STRATEGY 4: Focal Loss (\u03b3=5)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"\ud83d\udccb Konfig\u00fcrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['use_focal_loss']:\n",
    "    print(f\"   Focal alpha: {strategy_config.get('focal_alpha')}\")\n",
    "    print(f\"   Focal gamma: {strategy_config.get('focal_gamma')}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n\ud83d\udd27 Model y\u00fckleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\ud83d\ude80 E\u011fitim ba\u015fl\u0131yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\ud83d\udcca Test seti de\u011ferlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2705 STRATEGY 4 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24503a",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcca Part B-1 Results: Loss Function Comparison\n",
    "> 4 loss function stratejisini (B-1 \u2192 B-4) kar\u015f\u0131la\u015ft\u0131r ve en iyi performans\u0131 belirle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for plots\n",
    "    loss_plots_dir = 'outputs/loss_function_plots'\n",
    "    os.makedirs(loss_plots_dir, exist_ok=True)\n",
    "    \n",
    "    strategies = df_loss_comparison['Strategy'].tolist()\n",
    "    x_pos = np.arange(len(strategies))\n",
    "    \n",
    "    # ========== 1. mAP LINE CHART ==========\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['mAP'].tolist()\n",
    "    ax1.plot(x_pos, values, marker='o', linewidth=2.5, markersize=10, color='#06A77D', label='mAP')\n",
    "    ax1.fill_between(x_pos, values, alpha=0.2, color='#06A77D')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Mean Average Precision (mAP)', fontsize=12)\n",
    "    ax1.set_title('Loss Functions: mAP Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax1.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax1.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/map_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 mAP line chart saved\")\n",
    "    \n",
    "    # ========== 2. RECALL@5 LINE CHART ==========\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['Recall@5'].tolist()\n",
    "    ax2.plot(x_pos, values, marker='s', linewidth=2.5, markersize=10, color='#F39C12', label='Recall@5')\n",
    "    ax2.fill_between(x_pos, values, alpha=0.2, color='#F39C12')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Recall@5', fontsize=12)\n",
    "    ax2.set_title('Loss Functions: Recall@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax2.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax2.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/recall_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Recall@5 line chart saved\")\n",
    "    \n",
    "    # ========== 3. PRECISION@5 LINE CHART ==========\n",
    "    fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['Precision@5'].tolist()\n",
    "    ax3.plot(x_pos, values, marker='D', linewidth=2.5, markersize=10, color='#17A589', label='Precision@5')\n",
    "    ax3.fill_between(x_pos, values, alpha=0.2, color='#17A589')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Precision@5', fontsize=12)\n",
    "    ax3.set_title('Loss Functions: Precision@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax3.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax3.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/precision_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Precision@5 line chart saved\")\n",
    "    \n",
    "    # ========== 4. HAMMING LOSS LINE CHART ==========\n",
    "    fig4, ax4 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['Hamming_Loss'].tolist()\n",
    "    ax4.plot(x_pos, values, marker='^', linewidth=2.5, markersize=10, color='#E74C3C', label='Hamming Loss')\n",
    "    ax4.fill_between(x_pos, values, alpha=0.2, color='#E74C3C')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax4.set_ylabel('Hamming Loss', fontsize=12)\n",
    "    ax4.set_title('Loss Functions: Hamming Loss Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax4.set_ylim([min(values)*0.9, max(values)*1.1])\n",
    "    for i, val in enumerate(values):\n",
    "        ax4.text(i, val + (max(values) - min(values))*0.02, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/hamming_loss_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \u2713 Hamming Loss line chart saved\")\n",
    "    \n",
    "    print(f\"\\n\u2705 All line charts saved to: {loss_plots_dir}/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\ud83d\udcc1 EXPORTED FILES:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  \u2022 CSV: {loss_csv_path} (includes @10 metrics)\")\n",
    "    print(f\"  \u2022 Line Charts: {loss_plots_dir}/\")\n",
    "    print(\"    - map_comparison.png\")\n",
    "    print(\"    - recall_5_comparison.png\")\n",
    "    print(\"    - precision_5_comparison.png\")\n",
    "    print(\"    - hamming_loss_comparison.png\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No loss function results found. Please run strategies B-1 to B-4 first.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40a253",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udd2c PART B Section 2: Capacity Testing (Top-K Analysis)\n",
    "\n",
    "> **Hedef:** Farkl\u0131 label subset boyutlar\u0131yla model kapasitesini test et ve \u00f6\u011frenme davran\u0131\u015f\u0131n\u0131 anla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af275ab",
   "metadata": {},
   "source": [
    "### \ud83d\udd39 Strategy B-5: Top-K Label Analysis\n",
    "\n",
    "> Model'in farkl\u0131 label say\u0131lar\u0131ndaki performans\u0131n\u0131 test et.\n",
    "\n",
    "| K De\u011feri | A\u00e7\u0131klama |\n",
    "|----------|----------|\n",
    "| **Top-5** | En az label ile baseline |\n",
    "| **Top-10** | Minimal label seti |\n",
    "| **Top-20** | K\u00fc\u00e7\u00fck label seti |\n",
    "| **Top-50** | Orta seviye |\n",
    "| **Top-100** | Geni\u015f label seti |\n",
    "\n",
    "\u23f1\ufe0f ~2-2.5 saat (5 model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c188f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83e\uddea TOP-K LABEL ANALYSIS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "from src.strategies import filter_top_k_labels\n",
    "\n",
    "# Test different K values\n",
    "k_values = [100, 50, 20, 10, 5]\n",
    "topk_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"\ud83d\udd2c Testing Top-{k} Labels\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Filter dataset to top-k labels\n",
    "    filtered_train_ds, filtered_label_list, label_mapping = filter_top_k_labels(\n",
    "        train_dataset, \n",
    "        label_names, \n",
    "        k=k\n",
    "    )\n",
    "    filtered_test_ds, _, _ = filter_top_k_labels(\n",
    "        test_dataset, \n",
    "        label_names, \n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    print(f\"\ud83d\udcca Dataset Statistics:\")\n",
    "    print(f\"   Top-{k} labels selected\")\n",
    "    print(f\"   Train samples: {len(filtered_train_ds)}\")\n",
    "    print(f\"   Test samples: {len(filtered_test_ds)}\")\n",
    "    print(f\"   Labels: {filtered_label_list[:5]}...\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    topk_train_loader = DataLoader(\n",
    "        filtered_train_ds,\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "    topk_test_loader = DataLoader(\n",
    "        filtered_test_ds,\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Load model for this K\n",
    "    print(f\"\\n\ud83d\udd27 Loading model for {k} labels...\")\n",
    "    topk_model = load_model(\n",
    "        model_name=BASE_CONFIG['model_name'],\n",
    "        num_labels=k,\n",
    "        device=BASE_CONFIG['device'],\n",
    "        use_focal_loss=False,\n",
    "        pos_weight=None\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\n\ud83d\ude80 Training on Top-{k}...\")\n",
    "    topk_history = train_model(\n",
    "        model=topk_model,\n",
    "        train_dataloader=topk_train_loader,\n",
    "        num_epochs=BASE_CONFIG['num_epochs'],\n",
    "        learning_rate=BASE_CONFIG['learning_rate'],\n",
    "        device=BASE_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(f\"\\n\ud83d\udcca Evaluating Top-{k}...\")\n",
    "    topk_test_results = evaluate_model(\n",
    "        model=topk_model,\n",
    "        test_dataloader=topk_test_loader,\n",
    "        label_names=filtered_label_list,\n",
    "        device=BASE_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    topk_results[f'top_{k}'] = {\n",
    "        'k': k,\n",
    "        'num_train': len(filtered_train_ds),\n",
    "        'num_test': len(filtered_test_ds),\n",
    "        'metrics': topk_test_results,\n",
    "        'labels': filtered_label_list\n",
    "    }\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n\u2705 Top-{k} Results:\")\n",
    "    for metric, value in topk_test_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   {metric}: {value:.4f}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\ud83d\udcca TOP-K COMPARISON TABLE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "topk_comparison = []\n",
    "for key, data in topk_results.items():\n",
    "    metrics = data['metrics']\n",
    "    topk_comparison.append({\n",
    "        'K': data['k'],\n",
    "        'Train Samples': data['num_train'],\n",
    "        'Test Samples': data['num_test'],\n",
    "        'Micro F1': metrics.get('micro_f1', 0),\n",
    "        'Hamming Loss': metrics.get('hamming_loss', 0),\n",
    "        'Micro Precision': metrics.get('micro_precision', 0),\n",
    "        'Micro Recall': metrics.get('micro_recall', 0),\n",
    "        'Recall@5': metrics.get('recall_at_5', 0),\n",
    "        'Precision@5': metrics.get('precision_at_5', 0)\n",
    "    })\n",
    "\n",
    "df_topk = pd.DataFrame(topk_comparison)\n",
    "df_topk = df_topk.sort_values('K', ascending=False)\n",
    "print(df_topk.to_string(index=False))\n",
    "\n",
    "# Save CSV\n",
    "import os\n",
    "topk_csv_path = 'outputs/topk_analysis.csv'\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "df_topk.to_csv(topk_csv_path, index=False)\n",
    "print(f\"\\n\u2705 CSV saved: {topk_csv_path}\")\n",
    "\n",
    "# Create output directory for plots\n",
    "topk_plots_dir = 'outputs/topk_analysis_plots'\n",
    "os.makedirs(topk_plots_dir, exist_ok=True)\n",
    "\n",
    "# Setup for line charts\n",
    "k_labels = [f'Top-{k}' for k in df_topk['K']]\n",
    "x_pos = np.arange(len(k_labels))\n",
    "\n",
    "print(\"\\n\ud83d\udcca Creating LINE CHART visualizations...\")\n",
    "\n",
    "# ========== MICRO F1 LINE CHART ==========\n",
    "micro_f1 = df_topk['Micro F1'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, micro_f1, marker='o', linewidth=2.5, markersize=10, \n",
    "        color='#2E86AB', label='Micro F1')\n",
    "ax.fill_between(x_pos, micro_f1, alpha=0.2, color='#2E86AB')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Micro F1 Score', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Micro F1 vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(micro_f1)*0.95, max(micro_f1)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(micro_f1):\n",
    "    ax.text(i, val - (max(micro_f1) - min(micro_f1))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/micro_f1_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  \u2713 Micro F1 line chart saved\")\n",
    "\n",
    "# ========== HAMMING LOSS LINE CHART ==========\n",
    "hamming_loss = df_topk['Hamming Loss'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, hamming_loss, marker='v', linewidth=2.5, markersize=10, \n",
    "        color='#E63946', label='Hamming Loss')\n",
    "ax.fill_between(x_pos, hamming_loss, alpha=0.2, color='#E63946')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Hamming Loss (lower is better)', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Hamming Loss vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(hamming_loss)*0.92, max(hamming_loss)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(hamming_loss):\n",
    "    ax.text(i, val + (max(hamming_loss) - min(hamming_loss))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/hamming_loss_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  \u2713 Hamming Loss line chart saved\")\n",
    "\n",
    "# ========== PRECISION@5 LINE CHART ==========\n",
    "precision_5 = df_topk['Precision@5'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, precision_5, marker='p', linewidth=2.5, markersize=10, \n",
    "        color='#F77F00', label='Precision@5')\n",
    "ax.fill_between(x_pos, precision_5, alpha=0.2, color='#F77F00')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Precision@5', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Precision@5 vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(precision_5)*0.95, max(precision_5)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(precision_5):\n",
    "    ax.text(i, val - (max(precision_5) - min(precision_5))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/precision_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  \u2713 Precision@5 line chart saved\")\n",
    "\n",
    "# ========== RECALL@5 LINE CHART ==========\n",
    "recall_5 = df_topk['Recall@5'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, recall_5, marker='D', linewidth=2.5, markersize=10, \n",
    "        color='#06A77D', label='Recall@5')\n",
    "ax.fill_between(x_pos, recall_5, alpha=0.2, color='#06A77D')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Recall@5', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Recall@5 vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(recall_5)*0.95, max(recall_5)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(recall_5):\n",
    "    ax.text(i, val - (max(recall_5) - min(recall_5))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/recall_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  \u2713 Recall@5 line chart saved\")\n",
    "\n",
    "# ========== MICRO PRECISION LINE CHART ==========\n",
    "micro_prec = df_topk['Micro Precision'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, micro_prec, marker='o', linewidth=2.5, markersize=10, \n",
    "        color='#F18F01', label='Micro Precision')\n",
    "ax.fill_between(x_pos, micro_prec, alpha=0.2, color='#F18F01')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Micro Precision', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Micro Precision vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(micro_prec)*0.95, max(micro_prec)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(micro_prec):\n",
    "    ax.text(i, val - (max(micro_prec) - min(micro_prec))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/micro_precision_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  \u2713 Micro Precision line chart saved\")\n",
    "\n",
    "# ========== MICRO RECALL LINE CHART ==========\n",
    "micro_rec = df_topk['Micro Recall'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, micro_rec, marker='s', linewidth=2.5, markersize=10, \n",
    "        color='#C1121F', label='Micro Recall')\n",
    "ax.fill_between(x_pos, micro_rec, alpha=0.2, color='#C1121F')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Micro Recall', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Micro Recall vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(micro_rec)*0.95, max(micro_rec)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(micro_rec):\n",
    "    ax.text(i, val - (max(micro_rec) - min(micro_rec))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/micro_recall_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  \u2713 Micro Recall line chart saved\")\n",
    "\n",
    "print(f\"\\n\u2705 All line charts saved to: {topk_plots_dir}/\")\n",
    "\n",
    "# Store in all_test_results for comparison\n",
    "for key, data in topk_results.items():\n",
    "    all_test_results[key] = {\n",
    "        'config': f\"Top-{data['k']} Labels\",\n",
    "        'description': f\"Baseline BCE with {data['k']} most frequent labels\",\n",
    "        'results': data['metrics']\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83d\udcc1 EXPORTED FILES:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  \u2022 CSV: {topk_csv_path}\")\n",
    "print(f\"  \u2022 Line Charts: {topk_plots_dir}/\")\n",
    "print(\"    - micro_f1_comparison.png\")\n",
    "print(\"    - hamming_loss_comparison.png\")\n",
    "print(\"    - precision_5_comparison.png\")\n",
    "print(\"    - recall_5_comparison.png\")\n",
    "print(\"    - micro_precision_comparison.png\")\n",
    "print(\"    - micro_recall_comparison.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\u2705 TOP-K ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4409327",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udd17 PART C: HYBRID STRATEGIES (Loss \u00d7 Classification)\n",
    "\n",
    "> **Hedef:** En iyi loss fonksiyonlar\u0131n\u0131 farkl\u0131 classification y\u00f6ntemleriyle kombinleyerek optimal stratejiyi bul.\n",
    "\n",
    "**Formula:** 2 Loss \u00d7 5 Methods = **10 Strateji**\n",
    "\n",
    "---\n",
    "\n",
    "### \u26a1 Loss Functions (Part B'den se\u00e7ildi)\n",
    "\n",
    "| Loss | A\u00e7\u0131klama |\n",
    "|------|----------|\n",
    "| **Weighted BCE** | Frekans bazl\u0131 a\u011f\u0131rl\u0131klar - En ba\u015far\u0131l\u0131 baseline |\n",
    "| **Focal Loss \u03b3=5** | Strong hard example focusing |\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfaf Classification Methods\n",
    "\n",
    "| Method | A\u00e7\u0131klama | Kaynak |\n",
    "|--------|----------|--------|\n",
    "| **ClassifierChain** | Sequential label dependencies | scikit-learn |\n",
    "| **ExtraTreesClassifier** | Extremely randomized trees - H\u0131zl\u0131 | scikit-learn |\n",
    "| **RandomForestClassifier** | Ensemble decision trees | scikit-learn |\n",
    "| **AttentionXML** | Multi-label attention mechanism | NeurIPS 2019 |\n",
    "| **LightXML** | Dynamic negative sampling + label embeddings | AAAI 2021 |\n",
    "\n",
    "---\n",
    "\n",
    "\u23f1\ufe0f **Toplam S\u00fcre:** ~7.5-10 saat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"\ud83d\udd04 HYBRID STRATEGIES: LOSS FUNCTIONS \u00d7 CLASSIFICATION METHODS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "from src.classifier_chain import train_classifier_chain, evaluate_classifier_chain\n",
    "from src.classifier_chain import train_multi_output_classifier, evaluate_multi_output_classifier\n",
    "\n",
    "# Define loss configurations (2 most promising from PART B experiments)\n",
    "# Format: (name, use_focal_loss, pos_weight_config, focal_alpha, focal_gamma)\n",
    "loss_configs = []\n",
    "\n",
    "# 1. Weighted BCE (best baseline)\n",
    "strategy_config_weighted = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=train_dataset,\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "loss_configs.append({\n",
    "    'name': 'weighted',\n",
    "    'display_name': 'Weighted BCE',\n",
    "    'use_focal_loss': False,\n",
    "    'pos_weight': strategy_config_weighted['pos_weight'],\n",
    "    'focal_alpha': None,\n",
    "    'focal_gamma': None\n",
    "})\n",
    "\n",
    "# 2. Focal Loss \u03b3=5 (strongest focal)\n",
    "loss_configs.append({\n",
    "    'name': 'focal_gamma5',\n",
    "    'display_name': 'Focal Loss (\u03b3=5)',\n",
    "    'use_focal_loss': True,\n",
    "    'pos_weight': None,\n",
    "    'focal_alpha': 0.25,\n",
    "    'focal_gamma': 5.0\n",
    "})\n",
    "\n",
    "# Define classification methods (5 methods: 3 traditional + 2 XMC)\n",
    "classification_methods = [\n",
    "    {\n",
    "        'name': 'classifier_chain',\n",
    "        'display_name': 'ClassifierChain',\n",
    "        'base_estimator': 'logistic',\n",
    "        'train_func': train_classifier_chain,\n",
    "        'eval_func': evaluate_classifier_chain\n",
    "    },\n",
    "    {\n",
    "        'name': 'extra_trees',\n",
    "        'display_name': 'ExtraTreesClassifier',\n",
    "        'base_estimator': 'extra_trees',\n",
    "        'train_func': train_multi_output_classifier,\n",
    "        'eval_func': evaluate_multi_output_classifier\n",
    "    },\n",
    "    {\n",
    "        'name': 'random_forest',\n",
    "        'display_name': 'RandomForestClassifier',\n",
    "        'base_estimator': 'random_forest',\n",
    "        'train_func': train_multi_output_classifier,\n",
    "        'eval_func': evaluate_multi_output_classifier\n",
    "    },\n",
    "    {\n",
    "        'name': 'attentionxml',\n",
    "        'display_name': 'AttentionXML',\n",
    "        'train_func': 'attention_xml',\n",
    "        'eval_func': 'attention_xml'\n",
    "    },\n",
    "    {\n",
    "        'name': 'lightxml',\n",
    "        'display_name': 'LightXML',\n",
    "        'train_func': 'light_xml',\n",
    "        'eval_func': 'light_xml'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Counter for strategy numbering (starting from 1 for Part C)\n",
    "strategy_counter = 1\n",
    "\n",
    "# Test all combinations\n",
    "print(f\"\ud83e\uddea Testing {len(loss_configs)} loss functions \u00d7 {len(classification_methods)} classification methods\")\n",
    "print(f\"   Total combinations: {len(loss_configs) * len(classification_methods)}\")\n",
    "print(f\"   Estimated time: ~{len(loss_configs) * len(classification_methods) * 50} minutes\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "for loss_config in loss_configs:\n",
    "    for clf_method in classification_methods:\n",
    "        \n",
    "        strategy_name = f\"hybrid_{loss_config['name']}_{clf_method['name']}\"\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"\ud83e\uddea PART C STRATEGY {strategy_counter}: {loss_config['display_name']} + {clf_method['display_name']}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Start timing\n",
    "        strategy_start_time = time.time()\n",
    "        \n",
    "        # STEP 1: Configuration\n",
    "        print(f\"\ud83d\udccb Configuration:\")\n",
    "        print(f\"   Loss Function: {loss_config['display_name']}\")\n",
    "        print(f\"   Classification Method: {clf_method['display_name']}\")\n",
    "        print(f\"   Use Focal Loss: {loss_config['use_focal_loss']}\")\n",
    "        if loss_config['pos_weight'] is not None:\n",
    "            print(f\"   Pos Weight: min={loss_config['pos_weight'].min():.2f}, max={loss_config['pos_weight'].max():.2f}\")\n",
    "        if loss_config['use_focal_loss']:\n",
    "            print(f\"   Focal Alpha: {loss_config['focal_alpha']}\")\n",
    "            print(f\"   Focal Gamma: {loss_config['focal_gamma']}\")\n",
    "        \n",
    "        # Check if this is AttentionXML or LightXML (end-to-end training)\n",
    "        if clf_method['name'] in ['attentionxml', 'lightxml']:\n",
    "            # Import XML utilities\n",
    "            from src.xml_utils import train_attention_xml, evaluate_attention_xml\n",
    "            from src.xml_utils import train_light_xml, evaluate_light_xml\n",
    "            \n",
    "            if clf_method['name'] == 'attentionxml':\n",
    "                from src.attention_xml import load_attention_xml_model\n",
    "                \n",
    "                print(f\"\\n\ud83d\udd27 Training {clf_method['display_name']} (end-to-end with {loss_config['display_name']})...\")\n",
    "                model = load_attention_xml_model(\n",
    "                    model_name=BASE_CONFIG['model_name'],\n",
    "                    num_labels=num_labels,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    dropout=0.1\n",
    "                )\n",
    "                \n",
    "                training_history = train_attention_xml(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "                    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    use_focal_loss=loss_config['use_focal_loss'],\n",
    "                    pos_weight=loss_config['pos_weight'],\n",
    "                    focal_alpha=loss_config['focal_alpha'],\n",
    "                    focal_gamma=loss_config['focal_gamma']\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n\ud83d\udcca Evaluating...\")\n",
    "                test_results = evaluate_attention_xml(\n",
    "                    model=model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    label_names=label_names\n",
    "                )\n",
    "                \n",
    "            else:  # lightxml\n",
    "                from src.light_xml import load_light_xml_model\n",
    "                \n",
    "                print(f\"\\n\ud83d\udd27 Training {clf_method['display_name']} (end-to-end with {loss_config['display_name']})...\")\n",
    "                model = load_light_xml_model(\n",
    "                    model_name=BASE_CONFIG['model_name'],\n",
    "                    num_labels=num_labels,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    num_label_groups=50,\n",
    "                    label_emb_dim=128,\n",
    "                    dropout=0.1\n",
    "                )\n",
    "                \n",
    "                training_history = train_light_xml(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "                    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    use_focal_loss=loss_config['use_focal_loss'],\n",
    "                    pos_weight=loss_config['pos_weight'],\n",
    "                    focal_alpha=loss_config['focal_alpha'],\n",
    "                    focal_gamma=loss_config['focal_gamma']\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n\ud83d\udcca Evaluating...\")\n",
    "                test_results = evaluate_light_xml(\n",
    "                    model=model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    label_names=label_names\n",
    "                )\n",
    "        \n",
    "        else:\n",
    "            # Traditional two-stage approach: BERT + Classification\n",
    "            # STEP 1: Train BERT with specific loss function\n",
    "            print(f\"\\n\ud83d\udd27 Step 1/3: Training BERT with {loss_config['display_name']}...\")\n",
    "            bert_model = load_model(\n",
    "                model_name=BASE_CONFIG['model_name'],\n",
    "                num_labels=num_labels,\n",
    "                device=BASE_CONFIG['device'],\n",
    "                use_focal_loss=loss_config['use_focal_loss'],\n",
    "                focal_alpha=loss_config['focal_alpha'],\n",
    "                focal_gamma=loss_config['focal_gamma'],\n",
    "                pos_weight=loss_config['pos_weight']\n",
    "            )\n",
    "            \n",
    "            training_history = train_model(\n",
    "                model=bert_model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                num_epochs=BASE_CONFIG['num_epochs'],\n",
    "                learning_rate=BASE_CONFIG['learning_rate'],\n",
    "                device=BASE_CONFIG['device']\n",
    "            )\n",
    "            \n",
    "            # STEP 2: Train classifier on top of BERT embeddings\n",
    "            print(f\"\\n\ud83d\udd27 Step 2/3: Training {clf_method['display_name']}...\")\n",
    "            \n",
    "            if clf_method['name'] == 'classifier_chain':\n",
    "                # ClassifierChain: Sequential label modeling\n",
    "                chain_model = train_classifier_chain(\n",
    "                    bert_model=bert_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    base_estimator=clf_method['base_estimator'],\n",
    "                    order='random',\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n\ud83d\udcca Step 3/3: Evaluating...\")\n",
    "                test_results = evaluate_classifier_chain(\n",
    "                    model=chain_model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    label_names=label_names\n",
    "                )\n",
    "            \n",
    "            else:  # MultiOutputClassifier (RandomForest or ExtraTrees)\n",
    "                # Multi-output: Independent binary classifiers\n",
    "                multi_output_model = train_multi_output_classifier(\n",
    "                    bert_model=bert_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    base_estimator=clf_method['base_estimator'],\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n\ud83d\udcca Step 3/3: Evaluating...\")\n",
    "                test_results = evaluate_multi_output_classifier(\n",
    "                    model=multi_output_model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    label_names=label_names\n",
    "                )\n",
    "        \n",
    "        # Calculate training time\n",
    "        training_time_min = (time.time() - strategy_start_time) / 60\n",
    "        \n",
    "        # Store results\n",
    "        all_test_results[strategy_name] = {\n",
    "            'config': f\"{loss_config['display_name']} + {clf_method['display_name']}\",\n",
    "            'description': f\"Hybrid strategy: {loss_config['display_name']} loss with {clf_method['display_name']}\",\n",
    "            'training_time_min': training_time_min,\n",
    "            'results': test_results\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"\u2705 PART C STRATEGY {strategy_counter} COMPLETE: {strategy_name}\")\n",
    "        print(f\"\u23f1\ufe0f  Training Time: {training_time_min:.2f} minutes\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\n\ud83d\udcc8 Results:\")\n",
    "        for metric, value in test_results.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"   {metric}: {value:.4f}\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\\n\")\n",
    "        \n",
    "        # Increment counter\n",
    "        strategy_counter += 1\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"\u2705 ALL HYBRID STRATEGIES COMPLETE\")\n",
    "print(f\"   Total strategies tested: {len(loss_configs) * len(classification_methods)}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3c589",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcca Part C Results: Hybrid Strategies Comparison\n",
    "> T\u00fcm hybrid stratejileri kar\u015f\u0131la\u015ft\u0131r ve optimal kombinasyonu belirle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8301b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all strategies\n",
    "if len(all_test_results) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \ud83d\udcca H\u0130BR\u0130T STRATEJ\u0130 KAR\u015eILA\u015eTIRMASI (S\u0131ral\u0131 - Uygulama S\u0131ras\u0131na G\u00f6re)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Define the desired order of hybrid strategies (implementation order)\n",
    "    ordered_hybrid_strategies = [\n",
    "        'hybrid_weighted_classifier_chain',\n",
    "        'hybrid_weighted_extra_trees',\n",
    "        'hybrid_weighted_random_forest',\n",
    "        'hybrid_weighted_attentionxml',\n",
    "        'hybrid_weighted_lightxml',\n",
    "        'hybrid_focal_gamma5_classifier_chain',\n",
    "        'hybrid_focal_gamma5_extra_trees',\n",
    "        'hybrid_focal_gamma5_random_forest',\n",
    "        'hybrid_focal_gamma5_attentionxml',\n",
    "        'hybrid_focal_gamma5_lightxml'\n",
    "    ]\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    # First add hybrid strategies in order\n",
    "    for strategy_name in ordered_hybrid_strategies:\n",
    "        if strategy_name in all_test_results:\n",
    "            result_dict = all_test_results[strategy_name]\n",
    "            results = result_dict['results']\n",
    "            comparison_data.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Training_Time_min': result_dict.get('training_time_min', 0),\n",
    "                'Micro F1': results.get('micro_f1', 0),\n",
    "                'mAP': results.get('mean_average_precision', 0),\n",
    "                'Hamming Loss': results.get('hamming_loss', 0),\n",
    "                'Example-based Accuracy': results.get('example_based_accuracy', 0),\n",
    "                'Micro Precision': results.get('micro_precision', 0),\n",
    "                'Micro Recall': results.get('micro_recall', 0),\n",
    "                'Precision@5': results.get('precision_at_5', 0),\n",
    "                'Recall@5': results.get('recall_at_5', 0),\n",
    "                'Precision@10': results.get('precision_at_10', 0),\n",
    "                'Recall@10': results.get('recall_at_10', 0)\n",
    "            })\n",
    "    \n",
    "    # Then add any remaining strategies not in the ordered list\n",
    "    for strategy_name, result_dict in all_test_results.items():\n",
    "        if strategy_name not in ordered_hybrid_strategies:\n",
    "            results = result_dict['results']\n",
    "            comparison_data.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Training_Time_min': result_dict.get('training_time_min', 0),\n",
    "                'Micro F1': results.get('micro_f1', 0),\n",
    "                'mAP': results.get('mean_average_precision', 0),\n",
    "                'Hamming Loss': results.get('hamming_loss', 0),\n",
    "                'Example-based Accuracy': results.get('example_based_accuracy', 0),\n",
    "                'Micro Precision': results.get('micro_precision', 0),\n",
    "                'Micro Recall': results.get('micro_recall', 0),\n",
    "                'Precision@5': results.get('precision_at_5', 0),\n",
    "                'Recall@5': results.get('recall_at_5', 0),\n",
    "                'Precision@10': results.get('precision_at_10', 0),\n",
    "                'Recall@10': results.get('recall_at_10', 0)\n",
    "            })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(df_comparison.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Find best strategy\n",
    "    best_idx = df_comparison['mAP'].idxmax()\n",
    "    best_strategy = df_comparison.iloc[best_idx]['Strategy']\n",
    "    best_map = df_comparison.iloc[best_idx]['mAP']\n",
    "    best_f1 = df_comparison.iloc[best_idx]['Micro F1']\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfc6 EN \u0130Y\u0130 STRATEJ\u0130: {best_strategy}\")\n",
    "    print(f\"   mAP (Ranking Quality): {best_map:.4f}\")\n",
    "    print(f\"   Micro F1 Score: {best_f1:.4f}\")\n",
    "    print(f\"   Micro Precision: {df_comparison.iloc[best_idx]['Micro Precision']:.4f}\")\n",
    "    print(f\"   Micro Recall: {df_comparison.iloc[best_idx]['Micro Recall']:.4f}\")\n",
    "    \n",
    "    # Compare to baseline if exists\n",
    "    if 'baseline' in all_test_results:\n",
    "        baseline_map = all_test_results['baseline']['results'].get('mean_average_precision', 0)\n",
    "        improvement = ((best_map - baseline_map) / baseline_map * 100) if baseline_map > 0 else 0\n",
    "        print(f\"   Baseline'a g\u00f6re mAP iyile\u015ftirme: {improvement:+.2f}%\")\n",
    "    \n",
    "    # Save comparison to CSV\n",
    "    csv_path = 'outputs/hybrid_strategies_comparison.csv'\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    df_comparison.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n\ud83d\udcbe CSV saved: {csv_path}\")\n",
    "    \n",
    "    # Plot comparison - individual line charts\n",
    "    if len(all_test_results) > 1:\n",
    "        plots_dir = 'outputs/hybrid_strategies_plots'\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "        \n",
    "        strategies = df_comparison['Strategy'].tolist()\n",
    "        x = np.arange(len(strategies))\n",
    "        \n",
    "        # 1. Micro F1 Score\n",
    "        fig1, ax1 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Micro F1'].tolist()\n",
    "        ax1.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#2E86AB', label='Micro F1')\n",
    "        ax1.fill_between(x, values, alpha=0.3, color='#2E86AB')\n",
    "        ax1.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Micro F1 Score', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Hybrid Strategies: Micro F1 Score Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax1.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax1.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/micro_f1.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. mAP (Mean Average Precision)\n",
    "        fig2, ax2 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['mAP'].tolist()\n",
    "        ax2.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#06A77D', label='mAP')\n",
    "        ax2.fill_between(x, values, alpha=0.3, color='#06A77D')\n",
    "        ax2.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Mean Average Precision (mAP)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Hybrid Strategies: mAP Comparison (Ranking Quality)', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax2.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax2.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/map.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Micro Precision\n",
    "        fig3, ax3 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Micro Precision'].tolist()\n",
    "        ax3.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#5DADE2', label='Micro Precision')\n",
    "        ax3.fill_between(x, values, alpha=0.3, color='#5DADE2')\n",
    "        ax3.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax3.set_ylabel('Micro Precision', fontsize=13, fontweight='bold')\n",
    "        ax3.set_title('Hybrid Strategies: Micro Precision Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax3.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax3.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/micro_precision.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 4. Micro Recall\n",
    "        fig4, ax4 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Micro Recall'].tolist()\n",
    "        ax4.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#EC7063', label='Micro Recall')\n",
    "        ax4.fill_between(x, values, alpha=0.3, color='#EC7063')\n",
    "        ax4.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax4.set_ylabel('Micro Recall', fontsize=13, fontweight='bold')\n",
    "        ax4.set_title('Hybrid Strategies: Micro Recall Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax4.set_xticks(x)\n",
    "        ax4.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax4.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax4.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/micro_recall.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 5. Recall@5\n",
    "        fig5, ax5 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Recall@5'].tolist()\n",
    "        ax5.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#F39C12', label='Recall@5')\n",
    "        ax5.fill_between(x, values, alpha=0.3, color='#F39C12')\n",
    "        ax5.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax5.set_ylabel('Recall@5', fontsize=13, fontweight='bold')\n",
    "        ax5.set_title('Hybrid Strategies: Recall@5 Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax5.set_xticks(x)\n",
    "        ax5.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax5.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax5.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax5.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/recall_at_5.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 6. Precision@5\n",
    "        fig6, ax6 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Precision@5'].tolist()\n",
    "        ax6.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#17A589', label='Precision@5')\n",
    "        ax6.fill_between(x, values, alpha=0.3, color='#17A589')\n",
    "        ax6.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax6.set_ylabel('Precision@5', fontsize=13, fontweight='bold')\n",
    "        ax6.set_title('Hybrid Strategies: Precision@5 Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax6.set_xticks(x)\n",
    "        ax6.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax6.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax6.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax6.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/precision_at_5.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 7. Hamming Loss (Lower is Better)\n",
    "        fig7, ax7 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Hamming Loss'].tolist()\n",
    "        ax7.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#FF6F61', label='Hamming Loss')\n",
    "        ax7.fill_between(x, values, alpha=0.3, color='#FF6F61')\n",
    "        ax7.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax7.set_ylabel('Hamming Loss', fontsize=13, fontweight='bold')\n",
    "        ax7.set_title('Hybrid Strategies: Hamming Loss Comparison (Lower is Better)', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax7.set_xticks(x)\n",
    "        ax7.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax7.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax7.set_ylim([min(values) * 0.85, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax7.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/hamming_loss.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 8. Example-based Accuracy\n",
    "        fig8, ax8 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Example-based Accuracy'].tolist()\n",
    "        ax8.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#9B59B6', label='Example-based Accuracy')\n",
    "        ax8.fill_between(x, values, alpha=0.3, color='#9B59B6')\n",
    "        ax8.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax8.set_ylabel('Example-based Accuracy', fontsize=13, fontweight='bold')\n",
    "        ax8.set_title('Hybrid Strategies: Example-based Accuracy Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax8.set_xticks(x)\n",
    "        ax8.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax8.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax8.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax8.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/example_based_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Combined plot (4x2 grid for 8 metrics)\n",
    "        fig, axes = plt.subplots(4, 2, figsize=(18, 24))\n",
    "        \n",
    "        # Panel 1: Micro F1\n",
    "        values = df_comparison['Micro F1'].tolist()\n",
    "        axes[0, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#2E86AB')\n",
    "        axes[0, 0].fill_between(x, values, alpha=0.3, color='#2E86AB')\n",
    "        axes[0, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[0, 0].set_ylabel('Micro F1', fontsize=10)\n",
    "        axes[0, 0].set_title('Micro F1 Score', fontsize=11, fontweight='bold')\n",
    "        axes[0, 0].set_xticks(x)\n",
    "        axes[0, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 2: mAP\n",
    "        values = df_comparison['mAP'].tolist()\n",
    "        axes[0, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#06A77D')\n",
    "        axes[0, 1].fill_between(x, values, alpha=0.3, color='#06A77D')\n",
    "        axes[0, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[0, 1].set_ylabel('mAP', fontsize=10)\n",
    "        axes[0, 1].set_title('Mean Average Precision', fontsize=11, fontweight='bold')\n",
    "        axes[0, 1].set_xticks(x)\n",
    "        axes[0, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 3: Micro Precision\n",
    "        values = df_comparison['Micro Precision'].tolist()\n",
    "        axes[1, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#5DADE2')\n",
    "        axes[1, 0].fill_between(x, values, alpha=0.3, color='#5DADE2')\n",
    "        axes[1, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[1, 0].set_ylabel('Micro Precision', fontsize=10)\n",
    "        axes[1, 0].set_title('Micro Precision', fontsize=11, fontweight='bold')\n",
    "        axes[1, 0].set_xticks(x)\n",
    "        axes[1, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 4: Micro Recall\n",
    "        values = df_comparison['Micro Recall'].tolist()\n",
    "        axes[1, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#EC7063')\n",
    "        axes[1, 1].fill_between(x, values, alpha=0.3, color='#EC7063')\n",
    "        axes[1, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[1, 1].set_ylabel('Micro Recall', fontsize=10)\n",
    "        axes[1, 1].set_title('Micro Recall', fontsize=11, fontweight='bold')\n",
    "        axes[1, 1].set_xticks(x)\n",
    "        axes[1, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 5: Recall@5\n",
    "        values = df_comparison['Recall@5'].tolist()\n",
    "        axes[2, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#F39C12')\n",
    "        axes[2, 0].fill_between(x, values, alpha=0.3, color='#F39C12')\n",
    "        axes[2, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[2, 0].set_ylabel('Recall@5', fontsize=10)\n",
    "        axes[2, 0].set_title('Recall@5', fontsize=11, fontweight='bold')\n",
    "        axes[2, 0].set_xticks(x)\n",
    "        axes[2, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 6: Precision@5\n",
    "        values = df_comparison['Precision@5'].tolist()\n",
    "        axes[2, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#17A589')\n",
    "        axes[2, 1].fill_between(x, values, alpha=0.3, color='#17A589')\n",
    "        axes[2, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[2, 1].set_ylabel('Precision@5', fontsize=10)\n",
    "        axes[2, 1].set_title('Precision@5', fontsize=11, fontweight='bold')\n",
    "        axes[2, 1].set_xticks(x)\n",
    "        axes[2, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[2, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 7: Hamming Loss\n",
    "        values = df_comparison['Hamming Loss'].tolist()\n",
    "        axes[3, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#FF6F61')\n",
    "        axes[3, 0].fill_between(x, values, alpha=0.3, color='#FF6F61')\n",
    "        axes[3, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[3, 0].set_ylabel('Hamming Loss', fontsize=10)\n",
    "        axes[3, 0].set_title('Hamming Loss (Lower is Better)', fontsize=11, fontweight='bold')\n",
    "        axes[3, 0].set_xticks(x)\n",
    "        axes[3, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[3, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 8: Example-based Accuracy\n",
    "        values = df_comparison['Example-based Accuracy'].tolist()\n",
    "        axes[3, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#9B59B6')\n",
    "        axes[3, 1].fill_between(x, values, alpha=0.3, color='#9B59B6')\n",
    "        axes[3, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[3, 1].set_ylabel('Example-based Accuracy', fontsize=10)\n",
    "        axes[3, 1].set_title('Example-based Accuracy', fontsize=11, fontweight='bold')\n",
    "        axes[3, 1].set_xticks(x)\n",
    "        axes[3, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[3, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        combined_plot_path = f'{plots_dir}/hybrid_strategies_comparison_all.png'\n",
    "        plt.savefig(combined_plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n\ud83d\udcca Plots saved:\")\n",
    "        print(f\"    - {plots_dir}/hybrid_strategies_comparison_all.png (combined 8-panel)\")\n",
    "        print(f\"    - {plots_dir}/micro_f1.png\")\n",
    "        print(f\"    - {plots_dir}/map.png\")\n",
    "        print(f\"    - {plots_dir}/micro_precision.png\")\n",
    "        print(f\"    - {plots_dir}/micro_recall.png\")\n",
    "        print(f\"    - {plots_dir}/recall_at_5.png\")\n",
    "        print(f\"    - {plots_dir}/precision_at_5.png\")\n",
    "        print(f\"    - {plots_dir}/hamming_loss.png\")\n",
    "        print(f\"    - {plots_dir}/example_based_accuracy.png\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93aeaaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcdd NOTLAR VE REFERANSLAR\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcc8 Ba\u015far\u0131 Kriterleri (SOC Analyst Perspektifi)\n",
    "\n",
    "| Metrik | Hedef | A\u00e7\u0131klama | \u00d6ncelik |\n",
    "|--------|-------|----------|---------|\n",
    "| **mAP** | > 0.20 | S\u0131ralama kalitesi - do\u011fru TTP'leri listenin tepesine koyma | \u2b50\u2b50\u2b50 |\n",
    "| **Recall@5** | > 0.30 | Top-5 tahmin i\u00e7inde do\u011fru TTP'lerin oran\u0131 | \u2b50\u2b50\u2b50 |\n",
    "| **Micro F1** | > 0.15 | Genel performans (threshold-based) | \u2b50\u2b50 |\n",
    "| **Hamming Loss** | < 0.10 | Yanl\u0131\u015f tahmin oran\u0131 (d\u00fc\u015f\u00fck = iyi) | \u2b50\u2b50 |\n",
    "\n",
    "---\n",
    "\n",
    "## \u26a0\ufe0f \u00d6nemli Hat\u0131rlatmalar\n",
    "\n",
    "- \u2705 Her strateji h\u00fccresi **ba\u011f\u0131ms\u0131z** \u00e7al\u0131\u015ft\u0131r\u0131labilir\n",
    "- \u2705 Sonu\u00e7lar `all_test_results` dictionary'sinde saklan\u0131r\n",
    "- \u2705 Comparison h\u00fccresini diledi\u011finiz zaman \u00e7al\u0131\u015ft\u0131r\u0131p ara sonu\u00e7lara bakabilirsiniz\n",
    "- \u23f1\ufe0f CTI-BERT ilk indirilirken cache'lenir (~500MB)\n",
    "- \ud83d\udcca T\u00fcm grafikler `outputs/` klas\u00f6r\u00fcne kaydedilir\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda Referanslar\n",
    "\n",
    "| Kaynak | A\u00e7\u0131klama |\n",
    "|--------|----------|\n",
    "| [CTI-BERT](https://huggingface.co/ibm-research/CTI-BERT) | IBM Research - Cyber Threat Intelligence BERT |\n",
    "| [Security-TTP-Mapping](https://huggingface.co/datasets/tumeteor/Security-TTP-Mapping) | MITRE ATT&CK etiketli CTI dataset |\n",
    "| [MITRE ATT&CK](https://attack.mitre.org/) | Adversarial Tactics, Techniques & Common Knowledge |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}