{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe9927e",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è CTI - MITRE ATT&CK TTP MAPPING PROJECT\n",
    "\n",
    "> **Ama√ß:** Siber tehdit istihbaratƒ± (CTI) metinlerini otomatik olarak MITRE ATT&CK tekniklerine e≈üle≈ütirmek i√ßin derin √∂ƒürenme tabanlƒ± multi-label sƒ±nƒ±flandƒ±rma sistemi.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Model: CTI-BERT (IBM Research)\n",
    "\n",
    "| √ñzellik | Deƒüer |\n",
    "|---------|-------|\n",
    "| **Model** | `ibm-research/CTI-BERT` |\n",
    "| **Tip** | Domain-specific BERT |\n",
    "| **Avantaj** | G√ºvenlik ve CTI metinlerinde genel BERT'ten daha iyi performans |\n",
    "| **Embedding** | 768-dimensional |\n",
    "\n",
    "üìé [Hugging Face Model Card](https://huggingface.co/ibm-research/CTI-BERT)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dataset: Security-TTP-Mapping\n",
    "\n",
    "| √ñzellik | Deƒüer |\n",
    "|---------|-------|\n",
    "| **Kaynak** | `tumeteor/Security-TTP-Mapping` |\n",
    "| **Train** | 14.9k √∂rnek |\n",
    "| **Test** | 2.6k √∂rnek |\n",
    "| **Labels** | 499 MITRE ATT&CK tekniƒüi |\n",
    "\n",
    "üìé [Hugging Face Dataset](https://huggingface.co/datasets/tumeteor/Security-TTP-Mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6204197",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß SETUP \n",
    "> Colab ortamƒ±nda proje kurulumu ve baƒüƒ±mlƒ±lƒ±klarƒ±n y√ºklenmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4016e0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: /content/Mitre_Attack_TTP_Mapping\n",
      "\n",
      "‚ö° OPTIMIZATION APPLIED:\n",
      "   - ExtraTreesClassifier: 50 trees (was 100)\n",
      "   - RandomForestClassifier: 50 trees (was 100)\n",
      "   - max_features='sqrt' (~28 features per split instead of 768)\n",
      "   - min_samples_split=20 (faster splits)\n",
      "   - Expected speedup: ~4x faster training!\n",
      "\n",
      "   If training was stuck, Runtime > Interrupt execution, then re-run from Strategy cell\n",
      "\n",
      "‚ÑπÔ∏è  Yerel ortamda √ßalƒ±≈üƒ±yorsunuz\n"
     ]
    }
   ],
   "source": [
    "# Update repository to latest version (get optimized tree classifiers)\n",
    "!cd /content/Mitre_Attack_TTP_Mapping && git pull origin main\n",
    "\n",
    "print(\"\\n‚ö° OPTIMIZATION APPLIED:\")\n",
    "print(\"   - ExtraTreesClassifier: 50 trees (was 100)\")\n",
    "print(\"   - RandomForestClassifier: 50 trees (was 100)\")\n",
    "print(\"   - max_features='sqrt' (~28 features per split instead of 768)\")\n",
    "print(\"   - min_samples_split=20 (faster splits)\")\n",
    "print(\"   - Expected speedup: ~4x faster training!\")\n",
    "print(\"\\n   If training was stuck, Runtime > Interrupt execution, then re-run from Strategy cell\\n\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"‚úÖ Google Colab ortamƒ± tespit edildi\")\n",
    "    \n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GPU bulunamadƒ±! Runtime > Change runtime type > GPU se√ßin\")\n",
    "    \n",
    "    print(\"\\nüì• Proje indiriliyor...\")\n",
    "    !rm -rf Mitre_Attack_TTP_Mapping\n",
    "    !git clone https://github.com/Aliekinozcetin/Mitre_Attack_TTP_Mapping.git\n",
    "    os.chdir('Mitre_Attack_TTP_Mapping')\n",
    "    print(f\"‚úÖ √áalƒ±≈üma dizini: {os.getcwd()}\")\n",
    "    \n",
    "    print(\"\\nüì¶ Paketler y√ºkleniyor...\")\n",
    "    !pip install -q torch transformers datasets scikit-learn pandas tqdm matplotlib seaborn\n",
    "    print(\"‚úÖ T√ºm paketler y√ºklendi\")\n",
    "    \n",
    "    # HuggingFace baƒülantƒ± optimizasyonu\n",
    "    print(\"\\nüîß HuggingFace cache ayarlarƒ±...\")\n",
    "    \n",
    "    # Create cache directory\n",
    "    cache_dir = '/content/hf_cache'\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    # Set environment variables\n",
    "    os.environ['HF_HOME'] = cache_dir\n",
    "    os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "    os.environ['HF_DATASETS_CACHE'] = cache_dir\n",
    "    os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '600'  # 10 minutes\n",
    "    os.environ['CURL_CA_BUNDLE'] = ''\n",
    "    os.environ['HF_ENDPOINT'] = 'https://huggingface.co'\n",
    "    os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'  # Faster downloads\n",
    "    \n",
    "    print(f\"‚úÖ Cache dizini olu≈üturuldu: {cache_dir}\")\n",
    "    print(f\"   Timeout: 10 dakika\")\n",
    "    \n",
    "    # Test HuggingFace connection\n",
    "    try:\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        print(\"\\nüì° HuggingFace baƒülantƒ± testi...\")\n",
    "        info = api.model_info(\"ibm-research/CTI-BERT\", timeout=30)\n",
    "        print(f\"‚úÖ Model eri≈üilebilir: {info.modelId}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Baƒülantƒ± uyarƒ±sƒ±: {str(e)[:100]}\")\n",
    "        print(\"   Model indirme denemeye devam edilecek...\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Yerel ortamda √ßalƒ±≈üƒ±yorsunuz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044287e",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Import Modules\n",
    "> Gerekli k√ºt√ºphaneleri ve proje mod√ºllerini y√ºkle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4696cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc.strategies\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc.strategies\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import project modules\n",
    "from src.data_loader import prepare_data, load_datasets_and_prepare_dataloaders\n",
    "from src.model import load_model\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model\n",
    "from src.strategies import get_strategy_config\n",
    "from src.augmentation import replace_iocs, back_translate, augment_tail_samples\n",
    "\n",
    "print(\"‚úÖ Mod√ºller y√ºklendi\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82a7c4",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è Configuration\n",
    "> Eƒüitim parametrelerini ve √ßƒ±ktƒ± dizinini ayarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aaecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base training configuration\n",
    "BASE_CONFIG = {\n",
    "    'model_name': 'ibm-research/CTI-BERT',  # CTI domain-specific BERT\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_epochs': 5,\n",
    "    'max_length': 128,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Store results from all strategies\n",
    "all_test_results = {}\n",
    "\n",
    "print(\"‚úÖ Konfig√ºrasyon ayarlandƒ±\")\n",
    "print(f\"Model: {BASE_CONFIG['model_name']}\")\n",
    "print(f\"Device: {BASE_CONFIG['device']}\")\n",
    "print(f\"Output: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c082e5",
   "metadata": {},
   "source": [
    "---\n",
    "## üì• Data Loading\n",
    "> Dataset'i y√ºkle ve DataLoader'larƒ± olu≈ütur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì• Veri y√ºkleniyor...\")\n",
    "print(\"üì¶ Dataset: tumeteor/Security-TTP-Mapping (Single Source)\")\n",
    "print(f\"ü§ñ Model: {BASE_CONFIG['model_name']}\")\n",
    "print(\"\")\n",
    "\n",
    "# Use single dataset: tumeteor only\n",
    "train_dataloader, val_dataloader, test_dataset, label_names = load_datasets_and_prepare_dataloaders(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    max_length=BASE_CONFIG['max_length'],\n",
    "    dataset_name=\"tumeteor/Security-TTP-Mapping\"\n",
    ")\n",
    "\n",
    "# Get train_dataset from dataloader for strategies\n",
    "train_dataset = train_dataloader.dataset\n",
    "\n",
    "# Create test dataloader\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_labels = len(label_names)\n",
    "\n",
    "# Create data dict for backward compatibility\n",
    "data = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'test_dataset': test_dataset,\n",
    "    'label_list': label_names,\n",
    "    'num_labels': num_labels\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Veri y√ºklendi\")\n",
    "print(f\"   Train batches: {len(train_dataloader)}\")\n",
    "print(f\"   Test batches: {len(test_dataloader)}\")\n",
    "print(f\"   Toplam label sayƒ±sƒ±: {num_labels}\")\n",
    "print(f\"   ƒ∞lk 5 label: {label_names[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de26a69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä EXPERIMENT STRUCTURE\n",
    "\n",
    "> √ú√ß a≈üamalƒ± deneysel √ßalƒ±≈üma ile optimal TTP mapping stratejisini bulma.\n",
    "\n",
    "| B√∂l√ºm | A√ßƒ±klama | Strateji Sayƒ±sƒ± | Tahmini S√ºre |\n",
    "|-------|----------|-----------------|--------------|\n",
    "| **PART A** | Data Augmentation | 5 strateji | ~4-5 saat |\n",
    "| **PART B** | Loss Functions + Capacity | 4 + 5 strateji | ~5-6 saat |\n",
    "| **PART C** | Hybrid (Loss √ó Classification) | 10 strateji | ~7.5-10 saat |\n",
    "\n",
    "### üéØ √ñnerilen √áalƒ±≈ütƒ±rma Sƒ±rasƒ±:\n",
    "1. **PART A** ‚Üí En iyi augmentation y√∂ntemini bul\n",
    "2. **PART B** ‚Üí En iyi loss function'ƒ± belirle  \n",
    "3. **PART C** ‚Üí Optimal kombinasyonu ke≈üfet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7ad4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîÑ PART A: DATA AUGMENTATION EXPERIMENTS\n",
    "\n",
    "> **Hedef:** Tail TTP'lerin (az g√∂r√ºlen teknikler) performansƒ±nƒ± artƒ±rmak i√ßin veri augmentation stratejilerini test et.\n",
    "\n",
    "‚ö†Ô∏è **√ñncelik:** Bu b√∂l√ºm√º PART B ve C'den √ñNCE √ßalƒ±≈ütƒ±rƒ±n!\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Augmentation Y√∂ntemleri\n",
    "\n",
    "| Y√∂ntem | A√ßƒ±klama | Etki |\n",
    "|--------|----------|------|\n",
    "| **IoC Replacement** | IP, domain, hash, file path deƒüi≈ütirme | Overfitting'i √∂nler |\n",
    "| **Back-translation** | EN ‚Üí DE ‚Üí EN paraphrasing | Semantic √ße≈üitlilik |\n",
    "| **Tail Oversampling** | Rare TTP'leri 3x-10x √ßoƒüaltma | Class balance |\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Test Stratejileri\n",
    "\n",
    "| Strateji | A√ßƒ±klama | S√ºre |\n",
    "|----------|----------|------|\n",
    "| **AUG-1** | Baseline (No Augmentation) | ~30-40 dk |\n",
    "| **AUG-2** | IoC Replacement Only | ~30-40 dk |\n",
    "| **AUG-3** | Back-translation Only | ~40-50 dk |\n",
    "| **AUG-4** | Oversampling Only | ~30-40 dk |\n",
    "| **AUG-5** | Combined (All 3 methods) | ~50-60 dk |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f4abc",
   "metadata": {},
   "source": [
    "### üîπ AUG-1: Baseline (No Augmentation)\n",
    "> Referans performans i√ßin augmentation olmadan Weighted BCE.  \n",
    "> ‚è±Ô∏è ~30-40 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26356171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Fixed-N setup for objective augmentation comparison\n",
    "FIXED_N_SEED = 42\n",
    "TARGET_TRAIN_SIZE = len(data['train_dataset'])  # Baseline size (~14,936)\n",
    "TARGET_AUG_SIZE = 30000  # Target size for AUG-2/3/4/5 (all augmented strategies train with same N)\n",
    "\n",
    "def apply_fixed_n(texts, labels, target_size, seed=FIXED_N_SEED):\n",
    "    if len(texts) != len(labels):\n",
    "        raise ValueError(f\"texts/labels length mismatch: {len(texts)} vs {len(labels)}\")\n",
    "\n",
    "    n = len(texts)\n",
    "    if n == target_size:\n",
    "        return texts, labels\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    if n > target_size:\n",
    "        indices = rng.sample(range(n), target_size)\n",
    "    else:\n",
    "        indices = list(range(n)) + rng.choices(range(n), k=target_size - n)\n",
    "        rng.shuffle(indices)\n",
    "\n",
    "    return [texts[i] for i in indices], [labels[i] for i in indices]\n",
    "\n",
    "print(f\"üéØ Baseline train size: {TARGET_TRAIN_SIZE}\")\n",
    "print(f\"üéØ Augmentation strategies target size: {TARGET_AUG_SIZE} (AUG-2/3/4/5 will train with equal data)\")\n",
    "\n",
    "strategy_name = \"aug_baseline\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ AUG-1: Baseline (No Augmentation)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "# Use weighted BCE (best performing strategy)\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "strategy_train_dataloader = DataLoader(\n",
    "    strategy_config['dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"üìã Konfig√ºrasyon:\")\n",
    "print(f\"   Strategy: Weighted BCE (Baseline for comparison)\")\n",
    "print(f\"   Augmentation: NONE\")\n",
    "print(f\"   Train size: {len(data['train_dataset'])} (natural baseline)\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "# Store results\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': 'Weighted BCE (No Augmentation)',\n",
    "    'description': 'Baseline for augmentation comparison',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ AUG-1 TAMAMLANDI: {strategy_name}\")\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca01e99",
   "metadata": {},
   "source": [
    "### üîπ AUG-2: IoC Replacement Only\n",
    "> IP, domain, hash, file path deƒüi≈ütirme ile overfitting'i √∂nle.  \n",
    "> ‚è±Ô∏è ~30-40 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_ioc_replacement\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ AUG-2: IoC Replacement\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "# Load raw dataset for text augmentation\n",
    "print(\"üîÑ Loading raw dataset for IoC replacement...\")\n",
    "from datasets import load_dataset\n",
    "import ast\n",
    "\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Find text column\n",
    "print(f\"Available columns: {train_df.columns.tolist()}\")\n",
    "possible_text_cols = ['text1', 'description', 'text', 'content', 'sentence']\n",
    "text_column = None\n",
    "for col in possible_text_cols:\n",
    "    if col in train_df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise ValueError(f\"No text column found! Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_column}\")\n",
    "\n",
    "# Apply IoC replacement to texts\n",
    "print(\"Replacing IoCs in training texts...\")\n",
    "augmented_train_texts = []\n",
    "for text in train_df[text_column].fillna('').tolist():\n",
    "    # Original + 2 IoC-replaced versions\n",
    "    augmented_train_texts.append(text)  # Original\n",
    "    augmented_train_texts.append(replace_iocs(text, seed=42))  # Aug 1\n",
    "    augmented_train_texts.append(replace_iocs(text, seed=123))  # Aug 2\n",
    "\n",
    "# Replicate labels accordingly\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "\n",
    "# Parse labels\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Expand labels to match augmented texts\n",
    "augmented_train_labels = []\n",
    "for labels in train_labels_raw:\n",
    "    augmented_train_labels.append(labels)  # Original\n",
    "    augmented_train_labels.append(labels)  # Aug 1\n",
    "    augmented_train_labels.append(labels)  # Aug 2\n",
    "\n",
    "print(f\"‚úÖ Original samples: {len(train_df)}\")\n",
    "print(f\"‚úÖ Augmented samples: {len(augmented_train_texts)} (3x augmentation)\")\n",
    "\n",
    "# FIXED-N: Match train size to common augmentation target for fair comparison\n",
    "_before_n = len(augmented_train_texts)\n",
    "augmented_train_texts, augmented_train_labels = apply_fixed_n(\n",
    "    augmented_train_texts,\n",
    "    augmented_train_labels,\n",
    "    target_size=TARGET_AUG_SIZE,\n",
    "    seed=FIXED_N_SEED,\n",
    ")\n",
    "print(f\"üéØ Fixed-N applied: {_before_n} -> {len(augmented_train_texts)} (target={TARGET_AUG_SIZE})\")\n",
    "\n",
    "# Prepare augmented data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create custom dataset\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_train_texts,\n",
    "    augmented_train_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "# Store results\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': f'Weighted BCE + IoC Replacement [N={TARGET_AUG_SIZE}]',\n",
    "    'description': f'Training data augmented with IoC replacement (normalized to {TARGET_AUG_SIZE} samples)',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ AUG-2 TAMAMLANDI: {strategy_name}\")\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e4284",
   "metadata": {},
   "source": [
    "### üîπ AUG-3: Back-translation Only\n",
    "> EN ‚Üí DE ‚Üí EN paraphrasing ile semantic √ße≈üitlilik.  \n",
    "> Tail TTP √∂rneklerinin %15'ine uygulanƒ±r.  \n",
    "> ‚è±Ô∏è ~40-50 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_back_translation\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ AUG-3: Back-translation\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "# Load raw data\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Parse labels\n",
    "import ast\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Calculate label frequencies\n",
    "from collections import Counter\n",
    "label_counter = Counter()\n",
    "for labels in train_labels_raw:\n",
    "    label_counter.update(labels)\n",
    "\n",
    "# Identify tail TTPs (frequency < 10)\n",
    "tail_threshold = 10\n",
    "tail_ttps = {label for label, count in label_counter.items() if count < tail_threshold}\n",
    "print(f\"üìä Tail TTPs detected: {len(tail_ttps)} (frequency < {tail_threshold})\")\n",
    "\n",
    "# Identify samples with tail TTPs\n",
    "tail_sample_indices = []\n",
    "for idx, labels in enumerate(train_labels_raw):\n",
    "    if any(label in tail_ttps for label in labels):\n",
    "        tail_sample_indices.append(idx)\n",
    "\n",
    "print(f\"üìä Samples with tail TTPs: {len(tail_sample_indices)} / {len(train_df)}\")\n",
    "\n",
    "# Apply back-translation to 15% of tail samples (faster)\n",
    "import random\n",
    "random.seed(42)\n",
    "num_to_augment = int(len(tail_sample_indices) * 0.15)\n",
    "samples_to_augment = random.sample(tail_sample_indices, num_to_augment)\n",
    "\n",
    "print(f\"üîÑ Applying back-translation to {num_to_augment} samples...\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_train_texts = train_df[text_column].fillna('').tolist()\n",
    "augmented_train_labels = train_labels_raw.copy()\n",
    "\n",
    "# Load translation models (lazy loading)\n",
    "back_translate_cached = {}\n",
    "\n",
    "for idx in samples_to_augment:\n",
    "    original_text = train_df.iloc[idx][text_column]\n",
    "    if pd.isna(original_text) or len(original_text.strip()) < 10:\n",
    "        continue\n",
    "    \n",
    "    # Back-translate\n",
    "    try:\n",
    "        bt_text = back_translate(original_text, pivot_lang='de')\n",
    "        if bt_text and bt_text != original_text:\n",
    "            # Add augmented sample\n",
    "            augmented_train_texts.append(bt_text)\n",
    "            augmented_train_labels.append(train_labels_raw[idx])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Back-translation failed for sample {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Original samples: {len(train_df)}\")\n",
    "print(f\"Augmented samples: {len(augmented_train_texts)} (+{len(augmented_train_texts) - len(train_df)} from back-translation)\")\n",
    "\n",
    "# FIXED-N: Match train size to common augmentation target for fair comparison\n",
    "_before_n = len(augmented_train_texts)\n",
    "augmented_train_texts, augmented_train_labels = apply_fixed_n(\n",
    "    augmented_train_texts,\n",
    "    augmented_train_labels,\n",
    "    target_size=TARGET_AUG_SIZE,\n",
    "    seed=FIXED_N_SEED,\n",
    ")\n",
    "print(f\"üéØ Fixed-N applied: {_before_n} -> {len(augmented_train_texts)} (target={TARGET_AUG_SIZE})\")\n",
    "\n",
    "# Create custom dataset\n",
    "from src.data_loader import prepare_data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_train_texts,\n",
    "    augmented_train_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "# Store results\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': f'Weighted BCE + Back-translation [N={TARGET_AUG_SIZE}]',\n",
    "    'description': f'Training data augmented with back-translation for tail TTPs (normalized to {TARGET_AUG_SIZE} samples)',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ AUG-3 TAMAMLANDI: {strategy_name}\")\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee08d69",
   "metadata": {},
   "source": [
    "### üîπ AUG-4: Oversampling Only\n",
    "> Tail TTP'leri 3x-10x √ßoƒüaltarak class balance saƒüla.  \n",
    "> En hƒ±zlƒ± augmentation y√∂ntemi.  \n",
    "> ‚è±Ô∏è ~30-40 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_oversampling\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ AUG-4: Oversampling Only\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Load raw data\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Find text column\n",
    "possible_text_cols = ['text1', 'description', 'text', 'content', 'sentence']\n",
    "text_column = None\n",
    "for col in possible_text_cols:\n",
    "    if col in train_df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise ValueError(f\"No text column found! Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_column}\")\n",
    "\n",
    "# Parse labels\n",
    "import ast\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Calculate label frequencies\n",
    "from collections import Counter\n",
    "label_counter = Counter()\n",
    "for labels in train_labels_raw:\n",
    "    label_counter.update(labels)\n",
    "\n",
    "# Identify tail TTPs (frequency < 10)\n",
    "tail_threshold = 10\n",
    "tail_ttps = {label for label, count in label_counter.items() if count < tail_threshold}\n",
    "print(f\"üìä Tail TTPs detected: {len(tail_ttps)} (frequency < {tail_threshold})\")\n",
    "\n",
    "# Get training texts\n",
    "train_texts = train_df[text_column].fillna('').tolist()\n",
    "\n",
    "# Apply oversampling only\n",
    "augmented_texts = train_texts.copy()\n",
    "augmented_labels = train_labels_raw.copy()\n",
    "\n",
    "print(f\"üîÑ Applying oversampling to tail TTPs...\")\n",
    "\n",
    "for idx, labels in enumerate(train_labels_raw):\n",
    "    # Check if sample has tail TTPs\n",
    "    if any(label in tail_ttps for label in labels):\n",
    "        # Calculate oversample factor based on min frequency\n",
    "        min_freq = min([label_counter[label] for label in labels if label in tail_ttps])\n",
    "        oversample_factor = max(3, min(10, 100 // min_freq))  # 3x-10x based on frequency\n",
    "        \n",
    "        # Oversample\n",
    "        for _ in range(oversample_factor - 1):  # -1 because original is already in list\n",
    "            augmented_texts.append(train_texts[idx])\n",
    "            augmented_labels.append(labels)\n",
    "\n",
    "print(f\"Original samples: {len(train_texts)}\")\n",
    "print(f\"Augmented samples: {len(augmented_texts)}\")\n",
    "print(f\"Augmentation ratio: {len(augmented_texts) / len(train_texts):.2f}x\")\n",
    "\n",
    "# FIXED-N: Match train size to common augmentation target for fair comparison\n",
    "_before_n = len(augmented_texts)\n",
    "augmented_texts, augmented_labels = apply_fixed_n(\n",
    "    augmented_texts,\n",
    "    augmented_labels,\n",
    "    target_size=TARGET_AUG_SIZE,\n",
    "    seed=FIXED_N_SEED,\n",
    ")\n",
    "print(f\"üéØ Fixed-N applied: {_before_n} -> {len(augmented_texts)} (target={TARGET_AUG_SIZE})\")\n",
    "\n",
    "# Create custom dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_texts,\n",
    "    augmented_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': f'Weighted BCE + Oversampling [N={TARGET_AUG_SIZE}]',\n",
    "    'description': f'Training data augmented with tail TTP oversampling (normalized to {TARGET_AUG_SIZE} samples)',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ AUG-4 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351506a",
   "metadata": {},
   "source": [
    "### üîπ AUG-5: Combined (IoC + Back-translation + Oversampling)\n",
    "> T√ºm augmentation y√∂ntemlerinin birlikte uygulandƒ±ƒüƒ± strateji.  \n",
    "> En kapsamlƒ± veri zenginle≈ütirme.  \n",
    "> ‚è±Ô∏è ~50-60 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"aug_combined\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ AUG-5: Combined Augmentation (All Methods)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Load raw data\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"tumeteor/Security-TTP-Mapping\")\n",
    "train_df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# Find text column\n",
    "possible_text_cols = ['text1', 'description', 'text', 'content', 'sentence']\n",
    "text_column = None\n",
    "for col in possible_text_cols:\n",
    "    if col in train_df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise ValueError(f\"No text column found! Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using text column: {text_column}\")\n",
    "\n",
    "# Parse labels\n",
    "import ast\n",
    "train_labels_raw = train_df['labels'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# Calculate label frequencies\n",
    "from collections import Counter\n",
    "label_counter = Counter()\n",
    "for labels in train_labels_raw:\n",
    "    label_counter.update(labels)\n",
    "\n",
    "# Identify tail TTPs (frequency < 10)\n",
    "tail_threshold = 10\n",
    "tail_ttps = {label for label, count in label_counter.items() if count < tail_threshold}\n",
    "print(f\"üìä Tail TTPs detected: {len(tail_ttps)} (frequency < {tail_threshold})\")\n",
    "\n",
    "# Get training texts\n",
    "train_texts = train_df[text_column].fillna('').tolist()\n",
    "\n",
    "print(f\"üîÑ Applying COMBINED augmentation...\")\n",
    "print(f\"   - IoC Replacement\")\n",
    "print(f\"   - Back-translation (15% probability)\")\n",
    "print(f\"   - Tail Oversampling (3x-10x)\")\n",
    "\n",
    "# Apply combined augmentation\n",
    "augmented_texts = train_texts.copy()\n",
    "augmented_labels = train_labels_raw.copy()\n",
    "\n",
    "rng = random.Random(FIXED_N_SEED)\n",
    "\n",
    "for idx, labels in enumerate(train_labels_raw):\n",
    "    # Check if sample has tail TTPs\n",
    "    if any(label in tail_ttps for label in labels):\n",
    "        # Calculate oversample factor based on min frequency\n",
    "        min_freq = min([label_counter[label] for label in labels if label in tail_ttps])\n",
    "        oversample_factor = max(3, min(10, 100 // min_freq))  # 3x-10x based on frequency\n",
    "        \n",
    "        # Oversample with augmentation\n",
    "        for _ in range(oversample_factor - 1):  # -1 because original is already in list\n",
    "            augmented_text = train_texts[idx]\n",
    "            \n",
    "            # Apply IoC replacement\n",
    "            augmented_text = replace_iocs(augmented_text)\n",
    "            \n",
    "            # Apply back-translation with 15% probability\n",
    "            if rng.random() < 0.15:\n",
    "                augmented_text = back_translate(augmented_text, device=BASE_CONFIG['device'])\n",
    "            \n",
    "            augmented_texts.append(augmented_text)\n",
    "            augmented_labels.append(labels)\n",
    "\n",
    "print(f\"\\nOriginal samples: {len(train_texts)}\")\n",
    "print(f\"Augmented samples: {len(augmented_texts)}\")\n",
    "print(f\"Augmentation ratio: {len(augmented_texts) / len(train_texts):.2f}x\")\n",
    "\n",
    "# FIXED-N: Match train size to common augmentation target for fair comparison\n",
    "_before_n = len(augmented_texts)\n",
    "augmented_texts, augmented_labels = apply_fixed_n(\n",
    "    augmented_texts,\n",
    "    augmented_labels,\n",
    "    target_size=TARGET_AUG_SIZE,\n",
    "    seed=FIXED_N_SEED,\n",
    ")\n",
    "print(f\"üéØ Fixed-N applied: {_before_n} -> {len(augmented_texts)} (target={TARGET_AUG_SIZE})\")\n",
    "\n",
    "# Create custom dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AugmentedCTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get unique labels\n",
    "        all_labels = set()\n",
    "        for label_list in labels:\n",
    "            all_labels.update(label_list)\n",
    "        self.label_list = sorted(list(all_labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.encoded_labels = []\n",
    "        for label_list in labels:\n",
    "            encoded = [0] * len(self.label_list)\n",
    "            for label in label_list:\n",
    "                if label in self.label_to_idx:\n",
    "                    encoded[self.label_to_idx[label]] = 1\n",
    "            self.encoded_labels.append(encoded)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create augmented dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG['model_name'])\n",
    "aug_train_dataset = AugmentedCTIDataset(\n",
    "    augmented_texts,\n",
    "    augmented_labels,\n",
    "    tokenizer,\n",
    "    BASE_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "aug_train_dataloader = DataLoader(\n",
    "    aug_train_dataset,\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Augmented dataset created!\")\n",
    "print(f\"   Num labels: {len(aug_train_dataset.label_list)}\")\n",
    "\n",
    "# Get strategy config for weighted BCE\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=len(aug_train_dataset.label_list),\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=False,\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=aug_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': f'Weighted BCE + Combined [N={TARGET_AUG_SIZE}]',\n",
    "    'description': f'Training data augmented with IoC, back-translation, and tail oversampling (normalized to {TARGET_AUG_SIZE} samples)',\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ AUG-5 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18e9a8",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Part A Results: Augmentation Comparison\n",
    "> T√ºm augmentation stratejilerini kar≈üƒ±la≈ütƒ±r ve en iyi performansƒ± belirle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract augmentation results for comparison\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä AUGMENTATION STRATEGIES COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Define the desired order of strategies for the x-axis (must match strategy_name in each cell)\n",
    "ordered_strategies = ['aug_baseline', 'aug_ioc_replacement', 'aug_back_translation', 'aug_oversampling', 'aug_combined']\n",
    "aug_comparison_data = []\n",
    "\n",
    "for strategy_name in ordered_strategies:\n",
    "    if strategy_name in all_test_results:\n",
    "        data = all_test_results[strategy_name]\n",
    "        results = data['results']\n",
    "        aug_comparison_data.append({\n",
    "            'Strategy': data['config'],\n",
    "            'Training_Time_min': data.get('training_time_min', 0),\n",
    "            'mAP': results.get('mean_average_precision', 0),\n",
    "            'Micro_F1': results.get('micro_f1', 0),\n",
    "            'Recall@5': results.get('recall_at_5', 0),\n",
    "            'Precision@5': results.get('precision_at_5', 0),\n",
    "            'Recall@10': results.get('recall_at_10', 0),\n",
    "            'Precision@10': results.get('precision_at_10', 0),\n",
    "            'Hamming_Loss': results.get('hamming_loss', 0),\n",
    "            'Micro_Precision': results.get('micro_precision', 0),\n",
    "            'Micro_Recall': results.get('micro_recall', 0)\n",
    "        })\n",
    "\n",
    "if len(aug_comparison_data) > 0:\n",
    "    df_aug_comparison = pd.DataFrame(aug_comparison_data)\n",
    "    \n",
    "    # Ensure the DataFrame is in the desired order\n",
    "    df_aug_comparison['Strategy'] = pd.Categorical(df_aug_comparison['Strategy'], categories=[all_test_results[s]['config'] for s in ordered_strategies if s in all_test_results], ordered=True)\n",
    "    df_aug_comparison = df_aug_comparison.sort_values('Strategy')\n",
    "    \n",
    "    # Export CSV (includes all metrics including @10)\n",
    "    import os\n",
    "    aug_csv_path = 'outputs/augmentation_comparison.csv'\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    df_aug_comparison.to_csv(aug_csv_path, index=False)\n",
    "    print(f\"‚úÖ CSV exported to: {aug_csv_path}\\n\")\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(\"\\nüìã Augmentation Performance Comparison (Ordered by Implementation):\")\n",
    "    print(df_aug_comparison.to_string(index=False))\n",
    "    \n",
    "    # Find best strategies\n",
    "    print(\"\\nüèÜ Best Performers:\")\n",
    "    print(f\"   Best mAP: {df_aug_comparison.loc[df_aug_comparison['mAP'].idxmax(), 'Strategy']} ({df_aug_comparison['mAP'].max():.4f})\")\n",
    "    print(f\"   Best Micro F1: {df_aug_comparison.loc[df_aug_comparison['Micro_F1'].idxmax(), 'Strategy']} ({df_aug_comparison['Micro_F1'].max():.4f})\")\n",
    "    print(f\"   Best Recall@5: {df_aug_comparison.loc[df_aug_comparison['Recall@5'].idxmax(), 'Strategy']} ({df_aug_comparison['Recall@5'].max():.4f})\")\n",
    "    print(f\"   Best Precision@5: {df_aug_comparison.loc[df_aug_comparison['Precision@5'].idxmax(), 'Strategy']} ({df_aug_comparison['Precision@5'].max():.4f})\")\n",
    "    print(f\"   Lowest Hamming Loss: {df_aug_comparison.loc[df_aug_comparison['Hamming_Loss'].idxmin(), 'Strategy']} ({df_aug_comparison['Hamming_Loss'].min():.4f})\")\n",
    "    \n",
    "    # Create output directory for plots\n",
    "    aug_plots_dir = 'outputs/augmentation_plots'\n",
    "    os.makedirs(aug_plots_dir, exist_ok=True)\n",
    "    \n",
    "    strategies = df_aug_comparison['Strategy'].tolist()\n",
    "    x_pos = np.arange(len(strategies))\n",
    "    \n",
    "    print(\"\\nüìä Creating LINE CHART visualizations...\")\n",
    "\n",
    "    # ========== 1. mAP LINE CHART ==========\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['mAP'].tolist()\n",
    "    ax1.plot(x_pos, values, marker='o', linewidth=2.5, markersize=10, color='#06A77D', label='mAP')\n",
    "    ax1.fill_between(x_pos, values, alpha=0.2, color='#06A77D')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Mean Average Precision (mAP)', fontsize=12)\n",
    "    ax1.set_title('Augmentation Strategies: mAP Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax1.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax1.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/map_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì mAP line chart saved\")\n",
    "    \n",
    "    # ========== 2. RECALL@5 LINE CHART ==========\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Recall@5'].tolist()\n",
    "    ax2.plot(x_pos, values, marker='s', linewidth=2.5, markersize=10, color='#F39C12', label='Recall@5')\n",
    "    ax2.fill_between(x_pos, values, alpha=0.2, color='#F39C12')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Recall@5', fontsize=12)\n",
    "    ax2.set_title('Augmentation Strategies: Recall@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax2.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax2.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/recall_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Recall@5 line chart saved\")\n",
    "    \n",
    "    # ========== 3. PRECISION@5 LINE CHART ==========\n",
    "    fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Precision@5'].tolist()\n",
    "    ax3.plot(x_pos, values, marker='D', linewidth=2.5, markersize=10, color='#17A589', label='Precision@5')\n",
    "    ax3.fill_between(x_pos, values, alpha=0.2, color='#17A589')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Precision@5', fontsize=12)\n",
    "    ax3.set_title('Augmentation Strategies: Precision@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax3.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax3.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/precision_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Precision@5 line chart saved\")\n",
    "    \n",
    "    # ========== 4. MICRO F1 LINE CHART ==========\n",
    "    fig4, ax4 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Micro_F1'].tolist()\n",
    "    ax4.plot(x_pos, values, marker='p', linewidth=2.5, markersize=10, color='#8E44AD', label='Micro F1')\n",
    "    ax4.fill_between(x_pos, values, alpha=0.2, color='#8E44AD')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax4.set_ylabel('Micro F1 Score', fontsize=12)\n",
    "    ax4.set_title('Augmentation Strategies: Micro F1 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax4.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax4.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/micro_f1_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Micro F1 line chart saved\")\n",
    "    \n",
    "    # ========== 5. HAMMING LOSS LINE CHART ==========\n",
    "    fig5, ax5 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Hamming_Loss'].tolist()\n",
    "    ax5.plot(x_pos, values, marker='^', linewidth=2.5, markersize=10, color='#E74C3C', label='Hamming Loss')\n",
    "    ax5.fill_between(x_pos, values, alpha=0.2, color='#E74C3C')\n",
    "    ax5.set_xticks(x_pos)\n",
    "    ax5.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax5.set_ylabel('Hamming Loss', fontsize=12)\n",
    "    ax5.set_title('Augmentation Strategies: Hamming Loss Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax5.set_ylim([min(values)*0.9, max(values)*1.1])\n",
    "    for i, val in enumerate(values):\n",
    "        ax5.text(i, val + (max(values) - min(values))*0.02, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/hamming_loss_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Hamming Loss line chart saved\")\n",
    "    \n",
    "    # ========== 6. TRAINING TIME LINE CHART ==========\n",
    "    fig6, ax6 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_aug_comparison['Training_Time_min'].tolist()\n",
    "    ax6.plot(x_pos, values, marker='h', linewidth=2.5, markersize=10, color='#34495E', label='Training Time (min)')\n",
    "    ax6.fill_between(x_pos, values, alpha=0.2, color='#34495E')\n",
    "    ax6.set_xticks(x_pos)\n",
    "    ax6.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax6.set_ylabel('Training Time (minutes)', fontsize=12)\n",
    "    ax6.set_title('Augmentation Strategies: Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "    ax6.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax6.set_ylim([0, max(values)*1.15])\n",
    "    for i, val in enumerate(values):\n",
    "        ax6.text(i, val + 5, f'{val:.1f}', ha='center', fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aug_plots_dir}/training_time_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Training Time line chart saved\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All line charts saved to: {aug_plots_dir}/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìÅ EXPORTED FILES:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  ‚Ä¢ CSV: {aug_csv_path} (includes @10 metrics)\")\n",
    "    print(f\"  ‚Ä¢ Line Charts: {aug_plots_dir}/\")\n",
    "    print(\"    - map_comparison.png\")\n",
    "    print(\"    - recall_5_comparison.png\")\n",
    "    print(\"    - precision_5_comparison.png\")\n",
    "    print(\"    - micro_f1_comparison.png\")\n",
    "    print(\"    - hamming_loss_comparison.png\")\n",
    "    print(\"    - training_time_comparison.png\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No augmentation results found. Please run strategies A-1 to A-4 first.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f52529",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîÑ PART B: LOSS FUNCTION STRATEGIES\n",
    "\n",
    "> **Hedef:** Farklƒ± loss fonksiyonlarƒ±nƒ±n multi-label sƒ±nƒ±flandƒ±rma performansƒ±na etkisini test et.\n",
    "\n",
    "üí° **Not:** Bu stratejileri PART A'dan sonra, en iyi augmentation y√∂ntemi ile √ßalƒ±≈ütƒ±rƒ±n.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Test Stratejileri\n",
    "\n",
    "| Strateji | Loss Function | √ñzellik | S√ºre |\n",
    "|----------|---------------|---------|------|\n",
    "| **B-1** | Baseline BCE | Standart loss, referans | ~30-45 dk |\n",
    "| **B-2** | Weighted BCE | Frekans bazlƒ± aƒüƒ±rlƒ±klar | ~30-45 dk |\n",
    "| **B-3** | Focal Loss (Œ≥=2) | Moderate hard example focusing | ~30-45 dk |\n",
    "| **B-4** | Focal Loss (Œ≥=5) | Strong hard example focusing | ~30-45 dk |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c7ec3",
   "metadata": {},
   "source": [
    "### üîπ B-1: Baseline (Standard BCE Loss)\n",
    "> Standart Binary Cross-Entropy loss. Referans performans i√ßin baseline.  \n",
    "> ‚è±Ô∏è ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"baseline\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ STRATEGY 1: Baseline BCE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"üìã Konfig√ºrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['pos_weight'] is not None:\n",
    "    print(f\"   Pos weight: min={strategy_config['pos_weight'].min():.2f}, max={strategy_config['pos_weight'].max():.2f}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ STRATEGY 1 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd655b",
   "metadata": {},
   "source": [
    "### üîπ B-2: Weighted BCE Loss\n",
    "> Frekans bazlƒ± aƒüƒ±rlƒ±klar (pos_weight) ile class imbalance'ƒ± √ß√∂z.  \n",
    "> En etkili baseline y√∂ntem.  \n",
    "> ‚è±Ô∏è ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a054e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"weighted\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ STRATEGY 2: Weighted BCE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"üìã Konfig√ºrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['pos_weight'] is not None:\n",
    "    print(f\"   Pos weight: min={strategy_config['pos_weight'].min():.2f}, max={strategy_config['pos_weight'].max():.2f}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ STRATEGY 2 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028aa98",
   "metadata": {},
   "source": [
    "### üîπ B-3: Focal Loss (Œ≥=2)\n",
    "> Moderate hard example focusing. Yanlƒ±≈ü sƒ±nƒ±flandƒ±rƒ±lan √∂rneklere odaklan.  \n",
    "> ‚è±Ô∏è ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"focal_weak\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ STRATEGY 3: Focal Loss (Œ≥=2)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"üìã Konfig√ºrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['use_focal_loss']:\n",
    "    print(f\"   Focal alpha: {strategy_config.get('focal_alpha')}\")\n",
    "    print(f\"   Focal gamma: {strategy_config.get('focal_gamma')}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ STRATEGY 3 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b7263",
   "metadata": {},
   "source": [
    "### üîπ B-4: Focal Loss (Œ≥=5)\n",
    "> Strong hard example focusing. Tail TTP'ler i√ßin potansiyel iyile≈ütirme.  \n",
    "> ‚è±Ô∏è ~30-45 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"focal_strong\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ STRATEGY 4: Focal Loss (Œ≥=5)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start timing\n",
    "strategy_start_time = time.time()\n",
    "\n",
    "\n",
    "# Get strategy configuration\n",
    "strategy_config = get_strategy_config(\n",
    "    strategy_name=strategy_name,\n",
    "    train_dataset=data['train_dataset'],\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "if strategy_config['custom_dataloader'] is not None:\n",
    "    strategy_train_dataloader = strategy_config['custom_dataloader'](BASE_CONFIG['batch_size'])\n",
    "else:\n",
    "    strategy_train_dataloader = DataLoader(\n",
    "        strategy_config['dataset'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "print(\"üìã Konfig√ºrasyon:\")\n",
    "print(f\"   Strategy: {strategy_config['name']}\")\n",
    "print(f\"   Description: {strategy_config['description']}\")\n",
    "print(f\"   Num labels: {strategy_config['num_labels']}\")\n",
    "print(f\"   Focal loss: {strategy_config['use_focal_loss']}\")\n",
    "if strategy_config['use_focal_loss']:\n",
    "    print(f\"   Focal alpha: {strategy_config.get('focal_alpha')}\")\n",
    "    print(f\"   Focal gamma: {strategy_config.get('focal_gamma')}\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\nüîß Model y√ºkleniyor...\")\n",
    "model = load_model(\n",
    "    model_name=BASE_CONFIG['model_name'],\n",
    "    num_labels=strategy_config['num_labels'],\n",
    "    device=BASE_CONFIG['device'],\n",
    "    use_focal_loss=strategy_config['use_focal_loss'],\n",
    "    focal_alpha=strategy_config.get('focal_alpha', 0.25),\n",
    "    focal_gamma=strategy_config.get('focal_gamma', 2.0),\n",
    "    pos_weight=strategy_config['pos_weight']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor...\")\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=strategy_train_dataloader,\n",
    "    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nüìä Test seti deƒüerlendiriliyor...\")\n",
    "test_results = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=data['test_dataset'],\n",
    "    batch_size=BASE_CONFIG['batch_size'],\n",
    "    device=BASE_CONFIG['device']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "# Calculate training time\n",
    "training_time_min = (time.time() - strategy_start_time) / 60\n",
    "\n",
    "all_test_results[strategy_name] = {\n",
    "    'config': strategy_config['name'],\n",
    "    'description': strategy_config['description'],\n",
    "    'training_time_min': training_time_min,\n",
    "    'results': test_results\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ STRATEGY 4 TAMAMLANDI: {strategy_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24503a",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Part B-1 Results: Loss Function Comparison\n",
    "> 4 loss function stratejisini (B-1 ‚Üí B-4) kar≈üƒ±la≈ütƒ±r ve en iyi performansƒ± belirle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss function results for comparison\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä LOSS FUNCTION STRATEGIES COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Define the desired order of strategies for the x-axis\n",
    "ordered_loss_strategies = ['baseline', 'weighted', 'focal_weak', 'focal_strong']\n",
    "loss_comparison_data = []\n",
    "\n",
    "for strategy_name in ordered_loss_strategies:\n",
    "    if strategy_name in all_test_results:\n",
    "        data = all_test_results[strategy_name]\n",
    "        results = data['results']\n",
    "        loss_comparison_data.append({\n",
    "            'Strategy': data['config'],\n",
    "            'Training_Time_min': data.get('training_time_min', 0),\n",
    "            'mAP': results.get('mean_average_precision', 0),\n",
    "            'Micro_F1': results.get('micro_f1', 0),\n",
    "            'Recall@5': results.get('recall_at_5', 0),\n",
    "            'Precision@5': results.get('precision_at_5', 0),\n",
    "            'Recall@10': results.get('recall_at_10', 0),\n",
    "            'Precision@10': results.get('precision_at_10', 0),\n",
    "            'Hamming_Loss': results.get('hamming_loss', 0),\n",
    "            'Micro_Precision': results.get('micro_precision', 0),\n",
    "            'Micro_Recall': results.get('micro_recall', 0)\n",
    "        })\n",
    "\n",
    "if len(loss_comparison_data) > 0:\n",
    "    df_loss_comparison = pd.DataFrame(loss_comparison_data)\n",
    "    \n",
    "    # Export CSV\n",
    "    import os\n",
    "    loss_csv_path = 'outputs/loss_function_comparison.csv'\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    df_loss_comparison.to_csv(loss_csv_path, index=False)\n",
    "    print(f\"‚úÖ CSV exported to: {loss_csv_path}\\n\")\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(\"\\nüìã Loss Function Performance Comparison:\")\n",
    "    print(df_loss_comparison.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüìä Creating LINE CHART visualizations...\")\n",
    "    \n",
    "    # Create output directory for plots\n",
    "    loss_plots_dir = 'outputs/loss_function_plots'\n",
    "    os.makedirs(loss_plots_dir, exist_ok=True)\n",
    "    \n",
    "    strategies = df_loss_comparison['Strategy'].tolist()\n",
    "    x_pos = np.arange(len(strategies))\n",
    "    \n",
    "    # ========== 1. mAP LINE CHART ==========\n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['mAP'].tolist()\n",
    "    ax1.plot(x_pos, values, marker='o', linewidth=2.5, markersize=10, color='#06A77D', label='mAP')\n",
    "    ax1.fill_between(x_pos, values, alpha=0.2, color='#06A77D')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Mean Average Precision (mAP)', fontsize=12)\n",
    "    ax1.set_title('Loss Functions: mAP Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax1.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax1.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/map_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì mAP line chart saved\")\n",
    "    \n",
    "    # ========== 2. RECALL@5 LINE CHART ==========\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['Recall@5'].tolist()\n",
    "    ax2.plot(x_pos, values, marker='s', linewidth=2.5, markersize=10, color='#F39C12', label='Recall@5')\n",
    "    ax2.fill_between(x_pos, values, alpha=0.2, color='#F39C12')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Recall@5', fontsize=12)\n",
    "    ax2.set_title('Loss Functions: Recall@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax2.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax2.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/recall_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Recall@5 line chart saved\")\n",
    "    \n",
    "    # ========== 3. PRECISION@5 LINE CHART ==========\n",
    "    fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['Precision@5'].tolist()\n",
    "    ax3.plot(x_pos, values, marker='D', linewidth=2.5, markersize=10, color='#17A589', label='Precision@5')\n",
    "    ax3.fill_between(x_pos, values, alpha=0.2, color='#17A589')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Precision@5', fontsize=12)\n",
    "    ax3.set_title('Loss Functions: Precision@5 Comparison', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax3.set_ylim([min(values)*0.95, max(values)*1.08])\n",
    "    for i, val in enumerate(values):\n",
    "        ax3.text(i, val - (max(values) - min(values))*0.04, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/precision_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Precision@5 line chart saved\")\n",
    "    \n",
    "    # ========== 4. HAMMING LOSS LINE CHART ==========\n",
    "    fig4, ax4 = plt.subplots(figsize=(10, 6))\n",
    "    values = df_loss_comparison['Hamming_Loss'].tolist()\n",
    "    ax4.plot(x_pos, values, marker='^', linewidth=2.5, markersize=10, color='#E74C3C', label='Hamming Loss')\n",
    "    ax4.fill_between(x_pos, values, alpha=0.2, color='#E74C3C')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax4.set_ylabel('Hamming Loss', fontsize=12)\n",
    "    ax4.set_title('Loss Functions: Hamming Loss Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax4.set_ylim([min(values)*0.9, max(values)*1.1])\n",
    "    for i, val in enumerate(values):\n",
    "        ax4.text(i, val + (max(values) - min(values))*0.02, f'{val:.4f}', \n",
    "                ha='center', fontsize=9, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{loss_plots_dir}/hamming_loss_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì Hamming Loss line chart saved\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All line charts saved to: {loss_plots_dir}/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìÅ EXPORTED FILES:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  ‚Ä¢ CSV: {loss_csv_path} (includes @10 metrics)\")\n",
    "    print(f\"  ‚Ä¢ Line Charts: {loss_plots_dir}/\")\n",
    "    print(\"    - map_comparison.png\")\n",
    "    print(\"    - recall_5_comparison.png\")\n",
    "    print(\"    - precision_5_comparison.png\")\n",
    "    print(\"    - hamming_loss_comparison.png\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No loss function results found. Please run strategies B-1 to B-4 first.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40a253",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ PART B Section 2: Capacity Testing (Top-K Analysis)\n",
    "\n",
    "> **Hedef:** Farklƒ± label subset boyutlarƒ±yla model kapasitesini test et ve √∂ƒürenme davranƒ±≈üƒ±nƒ± anla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af275ab",
   "metadata": {},
   "source": [
    "### üîπ Strategy B-5: Top-K Label Analysis\n",
    "\n",
    "> Model'in farklƒ± label sayƒ±larƒ±ndaki performansƒ±nƒ± test et.\n",
    "\n",
    "| K Deƒüeri | A√ßƒ±klama |\n",
    "|----------|----------|\n",
    "| **Top-5** | En az label ile baseline |\n",
    "| **Top-10** | Minimal label seti |\n",
    "| **Top-20** | K√º√ß√ºk label seti |\n",
    "| **Top-50** | Orta seviye |\n",
    "| **Top-100** | Geni≈ü label seti |\n",
    "\n",
    "‚è±Ô∏è ~2-2.5 saat (5 model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c188f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üß™ TOP-K LABEL ANALYSIS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "from src.strategies import filter_top_k_labels\n",
    "\n",
    "# Test different K values\n",
    "k_values = [100, 50, 20, 10, 5]\n",
    "topk_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üî¨ Testing Top-{k} Labels\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Filter dataset to top-k labels\n",
    "    filtered_train_ds, filtered_label_list, label_mapping = filter_top_k_labels(\n",
    "        train_dataset, \n",
    "        label_names, \n",
    "        k=k\n",
    "    )\n",
    "    filtered_test_ds, _, _ = filter_top_k_labels(\n",
    "        test_dataset, \n",
    "        label_names, \n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Dataset Statistics:\")\n",
    "    print(f\"   Top-{k} labels selected\")\n",
    "    print(f\"   Train samples: {len(filtered_train_ds)}\")\n",
    "    print(f\"   Test samples: {len(filtered_test_ds)}\")\n",
    "    print(f\"   Labels: {filtered_label_list[:5]}...\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    topk_train_loader = DataLoader(\n",
    "        filtered_train_ds,\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "    topk_test_loader = DataLoader(\n",
    "        filtered_test_ds,\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Load model for this K\n",
    "    print(f\"\\nüîß Loading model for {k} labels...\")\n",
    "    topk_model = load_model(\n",
    "        model_name=BASE_CONFIG['model_name'],\n",
    "        num_labels=k,\n",
    "        device=BASE_CONFIG['device'],\n",
    "        use_focal_loss=False,\n",
    "        pos_weight=None\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nüöÄ Training on Top-{k}...\")\n",
    "    topk_history = train_model(\n",
    "        model=topk_model,\n",
    "        train_dataloader=topk_train_loader,\n",
    "        num_epochs=BASE_CONFIG['num_epochs'],\n",
    "        learning_rate=BASE_CONFIG['learning_rate'],\n",
    "        device=BASE_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(f\"\\nüìä Evaluating Top-{k}...\")\n",
    "    topk_test_results = evaluate_model(\n",
    "        model=topk_model,\n",
    "        test_dataloader=topk_test_loader,\n",
    "        label_names=filtered_label_list,\n",
    "        device=BASE_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    topk_results[f'top_{k}'] = {\n",
    "        'k': k,\n",
    "        'num_train': len(filtered_train_ds),\n",
    "        'num_test': len(filtered_test_ds),\n",
    "        'metrics': topk_test_results,\n",
    "        'labels': filtered_label_list\n",
    "    }\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n‚úÖ Top-{k} Results:\")\n",
    "    for metric, value in topk_test_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   {metric}: {value:.4f}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üìä TOP-K COMPARISON TABLE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "topk_comparison = []\n",
    "for key, data in topk_results.items():\n",
    "    metrics = data['metrics']\n",
    "    topk_comparison.append({\n",
    "        'K': data['k'],\n",
    "        'Train Samples': data['num_train'],\n",
    "        'Test Samples': data['num_test'],\n",
    "        'Micro F1': metrics.get('micro_f1', 0),\n",
    "        'Hamming Loss': metrics.get('hamming_loss', 0),\n",
    "        'Micro Precision': metrics.get('micro_precision', 0),\n",
    "        'Micro Recall': metrics.get('micro_recall', 0),\n",
    "        'Recall@5': metrics.get('recall_at_5', 0),\n",
    "        'Precision@5': metrics.get('precision_at_5', 0)\n",
    "    })\n",
    "\n",
    "df_topk = pd.DataFrame(topk_comparison)\n",
    "df_topk = df_topk.sort_values('K', ascending=False)\n",
    "print(df_topk.to_string(index=False))\n",
    "\n",
    "# Save CSV\n",
    "import os\n",
    "topk_csv_path = 'outputs/topk_analysis.csv'\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "df_topk.to_csv(topk_csv_path, index=False)\n",
    "print(f\"\\n‚úÖ CSV saved: {topk_csv_path}\")\n",
    "\n",
    "# Create output directory for plots\n",
    "topk_plots_dir = 'outputs/topk_analysis_plots'\n",
    "os.makedirs(topk_plots_dir, exist_ok=True)\n",
    "\n",
    "# Setup for line charts\n",
    "k_labels = [f'Top-{k}' for k in df_topk['K']]\n",
    "x_pos = np.arange(len(k_labels))\n",
    "\n",
    "print(\"\\nüìä Creating LINE CHART visualizations...\")\n",
    "\n",
    "# ========== MICRO F1 LINE CHART ==========\n",
    "micro_f1 = df_topk['Micro F1'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, micro_f1, marker='o', linewidth=2.5, markersize=10, \n",
    "        color='#2E86AB', label='Micro F1')\n",
    "ax.fill_between(x_pos, micro_f1, alpha=0.2, color='#2E86AB')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Micro F1 Score', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Micro F1 vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(micro_f1)*0.95, max(micro_f1)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(micro_f1):\n",
    "    ax.text(i, val - (max(micro_f1) - min(micro_f1))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/micro_f1_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  ‚úì Micro F1 line chart saved\")\n",
    "\n",
    "# ========== HAMMING LOSS LINE CHART ==========\n",
    "hamming_loss = df_topk['Hamming Loss'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, hamming_loss, marker='v', linewidth=2.5, markersize=10, \n",
    "        color='#E63946', label='Hamming Loss')\n",
    "ax.fill_between(x_pos, hamming_loss, alpha=0.2, color='#E63946')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Hamming Loss (lower is better)', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Hamming Loss vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(hamming_loss)*0.92, max(hamming_loss)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(hamming_loss):\n",
    "    ax.text(i, val + (max(hamming_loss) - min(hamming_loss))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/hamming_loss_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  ‚úì Hamming Loss line chart saved\")\n",
    "\n",
    "# ========== PRECISION@5 LINE CHART ==========\n",
    "precision_5 = df_topk['Precision@5'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, precision_5, marker='p', linewidth=2.5, markersize=10, \n",
    "        color='#F77F00', label='Precision@5')\n",
    "ax.fill_between(x_pos, precision_5, alpha=0.2, color='#F77F00')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Precision@5', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Precision@5 vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(precision_5)*0.95, max(precision_5)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(precision_5):\n",
    "    ax.text(i, val - (max(precision_5) - min(precision_5))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/precision_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  ‚úì Precision@5 line chart saved\")\n",
    "\n",
    "# ========== RECALL@5 LINE CHART ==========\n",
    "recall_5 = df_topk['Recall@5'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, recall_5, marker='D', linewidth=2.5, markersize=10, \n",
    "        color='#06A77D', label='Recall@5')\n",
    "ax.fill_between(x_pos, recall_5, alpha=0.2, color='#06A77D')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Recall@5', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Recall@5 vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(recall_5)*0.95, max(recall_5)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(recall_5):\n",
    "    ax.text(i, val - (max(recall_5) - min(recall_5))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/recall_5_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  ‚úì Recall@5 line chart saved\")\n",
    "\n",
    "# ========== MICRO PRECISION LINE CHART ==========\n",
    "micro_prec = df_topk['Micro Precision'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, micro_prec, marker='o', linewidth=2.5, markersize=10, \n",
    "        color='#F18F01', label='Micro Precision')\n",
    "ax.fill_between(x_pos, micro_prec, alpha=0.2, color='#F18F01')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Micro Precision', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Micro Precision vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(micro_prec)*0.95, max(micro_prec)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(micro_prec):\n",
    "    ax.text(i, val - (max(micro_prec) - min(micro_prec))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/micro_precision_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  ‚úì Micro Precision line chart saved\")\n",
    "\n",
    "# ========== MICRO RECALL LINE CHART ==========\n",
    "micro_rec = df_topk['Micro Recall'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x_pos, micro_rec, marker='s', linewidth=2.5, markersize=10, \n",
    "        color='#C1121F', label='Micro Recall')\n",
    "ax.fill_between(x_pos, micro_rec, alpha=0.2, color='#C1121F')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(k_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Micro Recall', fontsize=12)\n",
    "ax.set_title('Top-K Analysis: Micro Recall vs Label Count', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([min(micro_rec)*0.95, max(micro_rec)*1.08])\n",
    "ax.legend(loc='upper right')\n",
    "for i, val in enumerate(micro_rec):\n",
    "    ax.text(i, val - (max(micro_rec) - min(micro_rec))*0.04, f'{val:.4f}', \n",
    "            ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{topk_plots_dir}/micro_recall_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"  ‚úì Micro Recall line chart saved\")\n",
    "\n",
    "print(f\"\\n‚úÖ All line charts saved to: {topk_plots_dir}/\")\n",
    "\n",
    "# Store in all_test_results for comparison\n",
    "for key, data in topk_results.items():\n",
    "    all_test_results[key] = {\n",
    "        'config': f\"Top-{data['k']} Labels\",\n",
    "        'description': f\"Baseline BCE with {data['k']} most frequent labels\",\n",
    "        'results': data['metrics']\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÅ EXPORTED FILES:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  ‚Ä¢ CSV: {topk_csv_path}\")\n",
    "print(f\"  ‚Ä¢ Line Charts: {topk_plots_dir}/\")\n",
    "print(\"    - micro_f1_comparison.png\")\n",
    "print(\"    - hamming_loss_comparison.png\")\n",
    "print(\"    - precision_5_comparison.png\")\n",
    "print(\"    - recall_5_comparison.png\")\n",
    "print(\"    - micro_precision_comparison.png\")\n",
    "print(\"    - micro_recall_comparison.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ TOP-K ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4409327",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîó PART C: HYBRID STRATEGIES (Loss √ó Classification)\n",
    "\n",
    "> **Hedef:** En iyi loss fonksiyonlarƒ±nƒ± farklƒ± classification y√∂ntemleriyle kombinleyerek optimal stratejiyi bul.\n",
    "\n",
    "**Formula:** 2 Loss √ó 5 Methods = **10 Strateji**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° Loss Functions (Part B'den se√ßildi)\n",
    "\n",
    "| Loss | A√ßƒ±klama |\n",
    "|------|----------|\n",
    "| **Weighted BCE** | Frekans bazlƒ± aƒüƒ±rlƒ±klar - En ba≈üarƒ±lƒ± baseline |\n",
    "| **Focal Loss Œ≥=5** | Strong hard example focusing |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Classification Methods\n",
    "\n",
    "| Method | A√ßƒ±klama | Kaynak |\n",
    "|--------|----------|--------|\n",
    "| **ClassifierChain** | Sequential label dependencies | scikit-learn |\n",
    "| **ExtraTreesClassifier** | Extremely randomized trees - Hƒ±zlƒ± | scikit-learn |\n",
    "| **RandomForestClassifier** | Ensemble decision trees | scikit-learn |\n",
    "| **AttentionXML** | Multi-label attention mechanism | NeurIPS 2019 |\n",
    "| **LightXML** | Dynamic negative sampling + label embeddings | AAAI 2021 |\n",
    "\n",
    "---\n",
    "\n",
    "‚è±Ô∏è **Toplam S√ºre:** ~7.5-10 saat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üîÑ HYBRID STRATEGIES: LOSS FUNCTIONS √ó CLASSIFICATION METHODS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "from src.classifier_chain import train_classifier_chain, evaluate_classifier_chain\n",
    "from src.classifier_chain import train_multi_output_classifier, evaluate_multi_output_classifier\n",
    "\n",
    "# Define loss configurations (2 most promising from PART B experiments)\n",
    "# Format: (name, use_focal_loss, pos_weight_config, focal_alpha, focal_gamma)\n",
    "loss_configs = []\n",
    "\n",
    "# 1. Weighted BCE (best baseline)\n",
    "strategy_config_weighted = get_strategy_config(\n",
    "    strategy_name='weighted',\n",
    "    train_dataset=train_dataset,\n",
    "    num_labels=num_labels,\n",
    "    label_list=label_names\n",
    ")\n",
    "loss_configs.append({\n",
    "    'name': 'weighted',\n",
    "    'display_name': 'Weighted BCE',\n",
    "    'use_focal_loss': False,\n",
    "    'pos_weight': strategy_config_weighted['pos_weight'],\n",
    "    'focal_alpha': None,\n",
    "    'focal_gamma': None\n",
    "})\n",
    "\n",
    "# 2. Focal Loss Œ≥=5 (strongest focal)\n",
    "loss_configs.append({\n",
    "    'name': 'focal_gamma5',\n",
    "    'display_name': 'Focal Loss (Œ≥=5)',\n",
    "    'use_focal_loss': True,\n",
    "    'pos_weight': None,\n",
    "    'focal_alpha': 0.25,\n",
    "    'focal_gamma': 5.0\n",
    "})\n",
    "\n",
    "# Define classification methods (5 methods: 3 traditional + 2 XMC)\n",
    "classification_methods = [\n",
    "    {\n",
    "        'name': 'classifier_chain',\n",
    "        'display_name': 'ClassifierChain',\n",
    "        'base_estimator': 'logistic',\n",
    "        'train_func': train_classifier_chain,\n",
    "        'eval_func': evaluate_classifier_chain\n",
    "    },\n",
    "    {\n",
    "        'name': 'extra_trees',\n",
    "        'display_name': 'ExtraTreesClassifier',\n",
    "        'base_estimator': 'extra_trees',\n",
    "        'train_func': train_multi_output_classifier,\n",
    "        'eval_func': evaluate_multi_output_classifier\n",
    "    },\n",
    "    {\n",
    "        'name': 'random_forest',\n",
    "        'display_name': 'RandomForestClassifier',\n",
    "        'base_estimator': 'random_forest',\n",
    "        'train_func': train_multi_output_classifier,\n",
    "        'eval_func': evaluate_multi_output_classifier\n",
    "    },\n",
    "    {\n",
    "        'name': 'attentionxml',\n",
    "        'display_name': 'AttentionXML',\n",
    "        'train_func': 'attention_xml',\n",
    "        'eval_func': 'attention_xml'\n",
    "    },\n",
    "    {\n",
    "        'name': 'lightxml',\n",
    "        'display_name': 'LightXML',\n",
    "        'train_func': 'light_xml',\n",
    "        'eval_func': 'light_xml'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Counter for strategy numbering (starting from 1 for Part C)\n",
    "strategy_counter = 1\n",
    "\n",
    "# Test all combinations\n",
    "print(f\"üß™ Testing {len(loss_configs)} loss functions √ó {len(classification_methods)} classification methods\")\n",
    "print(f\"   Total combinations: {len(loss_configs) * len(classification_methods)}\")\n",
    "print(f\"   Estimated time: ~{len(loss_configs) * len(classification_methods) * 50} minutes\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "for loss_config in loss_configs:\n",
    "    for clf_method in classification_methods:\n",
    "        \n",
    "        strategy_name = f\"hybrid_{loss_config['name']}_{clf_method['name']}\"\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üß™ PART C STRATEGY {strategy_counter}: {loss_config['display_name']} + {clf_method['display_name']}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Start timing\n",
    "        strategy_start_time = time.time()\n",
    "        \n",
    "        # STEP 1: Configuration\n",
    "        print(f\"üìã Configuration:\")\n",
    "        print(f\"   Loss Function: {loss_config['display_name']}\")\n",
    "        print(f\"   Classification Method: {clf_method['display_name']}\")\n",
    "        print(f\"   Use Focal Loss: {loss_config['use_focal_loss']}\")\n",
    "        if loss_config['pos_weight'] is not None:\n",
    "            print(f\"   Pos Weight: min={loss_config['pos_weight'].min():.2f}, max={loss_config['pos_weight'].max():.2f}\")\n",
    "        if loss_config['use_focal_loss']:\n",
    "            print(f\"   Focal Alpha: {loss_config['focal_alpha']}\")\n",
    "            print(f\"   Focal Gamma: {loss_config['focal_gamma']}\")\n",
    "        \n",
    "        # Check if this is AttentionXML or LightXML (end-to-end training)\n",
    "        if clf_method['name'] in ['attentionxml', 'lightxml']:\n",
    "            # Import XML utilities\n",
    "            from src.xml_utils import train_attention_xml, evaluate_attention_xml\n",
    "            from src.xml_utils import train_light_xml, evaluate_light_xml\n",
    "            \n",
    "            if clf_method['name'] == 'attentionxml':\n",
    "                from src.attention_xml import load_attention_xml_model\n",
    "                \n",
    "                print(f\"\\nüîß Training {clf_method['display_name']} (end-to-end with {loss_config['display_name']})...\")\n",
    "                model = load_attention_xml_model(\n",
    "                    model_name=BASE_CONFIG['model_name'],\n",
    "                    num_labels=num_labels,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    dropout=0.1\n",
    "                )\n",
    "                \n",
    "                training_history = train_attention_xml(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "                    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    use_focal_loss=loss_config['use_focal_loss'],\n",
    "                    pos_weight=loss_config['pos_weight'],\n",
    "                    focal_alpha=loss_config['focal_alpha'],\n",
    "                    focal_gamma=loss_config['focal_gamma']\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nüìä Evaluating...\")\n",
    "                test_results = evaluate_attention_xml(\n",
    "                    model=model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    label_names=label_names\n",
    "                )\n",
    "                \n",
    "            else:  # lightxml\n",
    "                from src.light_xml import load_light_xml_model\n",
    "                \n",
    "                print(f\"\\nüîß Training {clf_method['display_name']} (end-to-end with {loss_config['display_name']})...\")\n",
    "                model = load_light_xml_model(\n",
    "                    model_name=BASE_CONFIG['model_name'],\n",
    "                    num_labels=num_labels,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    num_label_groups=50,\n",
    "                    label_emb_dim=128,\n",
    "                    dropout=0.1\n",
    "                )\n",
    "                \n",
    "                training_history = train_light_xml(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    num_epochs=BASE_CONFIG['num_epochs'],\n",
    "                    learning_rate=BASE_CONFIG['learning_rate'],\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    use_focal_loss=loss_config['use_focal_loss'],\n",
    "                    pos_weight=loss_config['pos_weight'],\n",
    "                    focal_alpha=loss_config['focal_alpha'],\n",
    "                    focal_gamma=loss_config['focal_gamma']\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nüìä Evaluating...\")\n",
    "                test_results = evaluate_light_xml(\n",
    "                    model=model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    label_names=label_names\n",
    "                )\n",
    "        \n",
    "        else:\n",
    "            # Traditional two-stage approach: BERT + Classification\n",
    "            # STEP 1: Train BERT with specific loss function\n",
    "            print(f\"\\nüîß Step 1/3: Training BERT with {loss_config['display_name']}...\")\n",
    "            bert_model = load_model(\n",
    "                model_name=BASE_CONFIG['model_name'],\n",
    "                num_labels=num_labels,\n",
    "                device=BASE_CONFIG['device'],\n",
    "                use_focal_loss=loss_config['use_focal_loss'],\n",
    "                focal_alpha=loss_config['focal_alpha'],\n",
    "                focal_gamma=loss_config['focal_gamma'],\n",
    "                pos_weight=loss_config['pos_weight']\n",
    "            )\n",
    "            \n",
    "            training_history = train_model(\n",
    "                model=bert_model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                num_epochs=BASE_CONFIG['num_epochs'],\n",
    "                learning_rate=BASE_CONFIG['learning_rate'],\n",
    "                device=BASE_CONFIG['device']\n",
    "            )\n",
    "            \n",
    "            # STEP 2: Train classifier on top of BERT embeddings\n",
    "            print(f\"\\nüîß Step 2/3: Training {clf_method['display_name']}...\")\n",
    "            \n",
    "            if clf_method['name'] == 'classifier_chain':\n",
    "                # ClassifierChain: Sequential label modeling\n",
    "                chain_model = train_classifier_chain(\n",
    "                    bert_model=bert_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    base_estimator=clf_method['base_estimator'],\n",
    "                    order='random',\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nüìä Step 3/3: Evaluating...\")\n",
    "                test_results = evaluate_classifier_chain(\n",
    "                    model=chain_model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    label_names=label_names\n",
    "                )\n",
    "            \n",
    "            else:  # MultiOutputClassifier (RandomForest or ExtraTrees)\n",
    "                # Multi-output: Independent binary classifiers\n",
    "                multi_output_model = train_multi_output_classifier(\n",
    "                    bert_model=bert_model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    device=BASE_CONFIG['device'],\n",
    "                    base_estimator=clf_method['base_estimator'],\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nüìä Step 3/3: Evaluating...\")\n",
    "                test_results = evaluate_multi_output_classifier(\n",
    "                    model=multi_output_model,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    label_names=label_names\n",
    "                )\n",
    "        \n",
    "        # Calculate training time\n",
    "        training_time_min = (time.time() - strategy_start_time) / 60\n",
    "        \n",
    "        # Store results\n",
    "        all_test_results[strategy_name] = {\n",
    "            'config': f\"{loss_config['display_name']} + {clf_method['display_name']}\",\n",
    "            'description': f\"Hybrid strategy: {loss_config['display_name']} loss with {clf_method['display_name']}\",\n",
    "            'training_time_min': training_time_min,\n",
    "            'results': test_results\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"‚úÖ PART C STRATEGY {strategy_counter} COMPLETE: {strategy_name}\")\n",
    "        print(f\"‚è±Ô∏è  Training Time: {training_time_min:.2f} minutes\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\nüìà Results:\")\n",
    "        for metric, value in test_results.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"   {metric}: {value:.4f}\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\\n\")\n",
    "        \n",
    "        # Increment counter\n",
    "        strategy_counter += 1\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ ALL HYBRID STRATEGIES COMPLETE\")\n",
    "print(f\"   Total strategies tested: {len(loss_configs) * len(classification_methods)}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3c589",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Part C Results: Hybrid Strategies Comparison\n",
    "> T√ºm hybrid stratejileri kar≈üƒ±la≈ütƒ±r ve optimal kombinasyonu belirle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8301b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all strategies\n",
    "if len(all_test_results) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" üìä Hƒ∞BRƒ∞T STRATEJƒ∞ KAR≈ûILA≈ûTIRMASI (Sƒ±ralƒ± - Uygulama Sƒ±rasƒ±na G√∂re)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Define the desired order of hybrid strategies (implementation order)\n",
    "    ordered_hybrid_strategies = [\n",
    "        'hybrid_weighted_classifier_chain',\n",
    "        'hybrid_weighted_extra_trees',\n",
    "        'hybrid_weighted_random_forest',\n",
    "        'hybrid_weighted_attentionxml',\n",
    "        'hybrid_weighted_lightxml',\n",
    "        'hybrid_focal_gamma5_classifier_chain',\n",
    "        'hybrid_focal_gamma5_extra_trees',\n",
    "        'hybrid_focal_gamma5_random_forest',\n",
    "        'hybrid_focal_gamma5_attentionxml',\n",
    "        'hybrid_focal_gamma5_lightxml'\n",
    "    ]\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    # First add hybrid strategies in order\n",
    "    for strategy_name in ordered_hybrid_strategies:\n",
    "        if strategy_name in all_test_results:\n",
    "            result_dict = all_test_results[strategy_name]\n",
    "            results = result_dict['results']\n",
    "            comparison_data.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Training_Time_min': result_dict.get('training_time_min', 0),\n",
    "                'Micro F1': results.get('micro_f1', 0),\n",
    "                'mAP': results.get('mean_average_precision', 0),\n",
    "                'Hamming Loss': results.get('hamming_loss', 0),\n",
    "                'Example-based Accuracy': results.get('example_based_accuracy', 0),\n",
    "                'Micro Precision': results.get('micro_precision', 0),\n",
    "                'Micro Recall': results.get('micro_recall', 0),\n",
    "                'Precision@5': results.get('precision_at_5', 0),\n",
    "                'Recall@5': results.get('recall_at_5', 0),\n",
    "                'Precision@10': results.get('precision_at_10', 0),\n",
    "                'Recall@10': results.get('recall_at_10', 0)\n",
    "            })\n",
    "    \n",
    "    # Then add any remaining strategies not in the ordered list\n",
    "    for strategy_name, result_dict in all_test_results.items():\n",
    "        if strategy_name not in ordered_hybrid_strategies:\n",
    "            results = result_dict['results']\n",
    "            comparison_data.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Training_Time_min': result_dict.get('training_time_min', 0),\n",
    "                'Micro F1': results.get('micro_f1', 0),\n",
    "                'mAP': results.get('mean_average_precision', 0),\n",
    "                'Hamming Loss': results.get('hamming_loss', 0),\n",
    "                'Example-based Accuracy': results.get('example_based_accuracy', 0),\n",
    "                'Micro Precision': results.get('micro_precision', 0),\n",
    "                'Micro Recall': results.get('micro_recall', 0),\n",
    "                'Precision@5': results.get('precision_at_5', 0),\n",
    "                'Recall@5': results.get('recall_at_5', 0),\n",
    "                'Precision@10': results.get('precision_at_10', 0),\n",
    "                'Recall@10': results.get('recall_at_10', 0)\n",
    "            })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(df_comparison.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Find best strategy\n",
    "    best_idx = df_comparison['mAP'].idxmax()\n",
    "    best_strategy = df_comparison.iloc[best_idx]['Strategy']\n",
    "    best_map = df_comparison.iloc[best_idx]['mAP']\n",
    "    best_f1 = df_comparison.iloc[best_idx]['Micro F1']\n",
    "    \n",
    "    print(f\"\\nüèÜ EN ƒ∞Yƒ∞ STRATEJƒ∞: {best_strategy}\")\n",
    "    print(f\"   mAP (Ranking Quality): {best_map:.4f}\")\n",
    "    print(f\"   Micro F1 Score: {best_f1:.4f}\")\n",
    "    print(f\"   Micro Precision: {df_comparison.iloc[best_idx]['Micro Precision']:.4f}\")\n",
    "    print(f\"   Micro Recall: {df_comparison.iloc[best_idx]['Micro Recall']:.4f}\")\n",
    "    \n",
    "    # Compare to baseline if exists\n",
    "    if 'baseline' in all_test_results:\n",
    "        baseline_map = all_test_results['baseline']['results'].get('mean_average_precision', 0)\n",
    "        improvement = ((best_map - baseline_map) / baseline_map * 100) if baseline_map > 0 else 0\n",
    "        print(f\"   Baseline'a g√∂re mAP iyile≈ütirme: {improvement:+.2f}%\")\n",
    "    \n",
    "    # Save comparison to CSV\n",
    "    csv_path = 'outputs/hybrid_strategies_comparison.csv'\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    df_comparison.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nüíæ CSV saved: {csv_path}\")\n",
    "    \n",
    "    # Plot comparison - individual line charts\n",
    "    if len(all_test_results) > 1:\n",
    "        plots_dir = 'outputs/hybrid_strategies_plots'\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "        \n",
    "        strategies = df_comparison['Strategy'].tolist()\n",
    "        x = np.arange(len(strategies))\n",
    "        \n",
    "        # 1. Micro F1 Score\n",
    "        fig1, ax1 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Micro F1'].tolist()\n",
    "        ax1.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#2E86AB', label='Micro F1')\n",
    "        ax1.fill_between(x, values, alpha=0.3, color='#2E86AB')\n",
    "        ax1.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Micro F1 Score', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Hybrid Strategies: Micro F1 Score Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax1.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax1.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/micro_f1.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. mAP (Mean Average Precision)\n",
    "        fig2, ax2 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['mAP'].tolist()\n",
    "        ax2.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#06A77D', label='mAP')\n",
    "        ax2.fill_between(x, values, alpha=0.3, color='#06A77D')\n",
    "        ax2.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Mean Average Precision (mAP)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Hybrid Strategies: mAP Comparison (Ranking Quality)', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax2.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax2.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/map.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Micro Precision\n",
    "        fig3, ax3 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Micro Precision'].tolist()\n",
    "        ax3.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#5DADE2', label='Micro Precision')\n",
    "        ax3.fill_between(x, values, alpha=0.3, color='#5DADE2')\n",
    "        ax3.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax3.set_ylabel('Micro Precision', fontsize=13, fontweight='bold')\n",
    "        ax3.set_title('Hybrid Strategies: Micro Precision Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax3.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax3.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/micro_precision.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 4. Micro Recall\n",
    "        fig4, ax4 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Micro Recall'].tolist()\n",
    "        ax4.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#EC7063', label='Micro Recall')\n",
    "        ax4.fill_between(x, values, alpha=0.3, color='#EC7063')\n",
    "        ax4.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax4.set_ylabel('Micro Recall', fontsize=13, fontweight='bold')\n",
    "        ax4.set_title('Hybrid Strategies: Micro Recall Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax4.set_xticks(x)\n",
    "        ax4.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax4.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax4.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/micro_recall.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 5. Recall@5\n",
    "        fig5, ax5 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Recall@5'].tolist()\n",
    "        ax5.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#F39C12', label='Recall@5')\n",
    "        ax5.fill_between(x, values, alpha=0.3, color='#F39C12')\n",
    "        ax5.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax5.set_ylabel('Recall@5', fontsize=13, fontweight='bold')\n",
    "        ax5.set_title('Hybrid Strategies: Recall@5 Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax5.set_xticks(x)\n",
    "        ax5.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax5.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax5.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax5.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/recall_at_5.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 6. Precision@5\n",
    "        fig6, ax6 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Precision@5'].tolist()\n",
    "        ax6.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#17A589', label='Precision@5')\n",
    "        ax6.fill_between(x, values, alpha=0.3, color='#17A589')\n",
    "        ax6.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax6.set_ylabel('Precision@5', fontsize=13, fontweight='bold')\n",
    "        ax6.set_title('Hybrid Strategies: Precision@5 Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax6.set_xticks(x)\n",
    "        ax6.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax6.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax6.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax6.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/precision_at_5.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 7. Hamming Loss (Lower is Better)\n",
    "        fig7, ax7 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Hamming Loss'].tolist()\n",
    "        ax7.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#FF6F61', label='Hamming Loss')\n",
    "        ax7.fill_between(x, values, alpha=0.3, color='#FF6F61')\n",
    "        ax7.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax7.set_ylabel('Hamming Loss', fontsize=13, fontweight='bold')\n",
    "        ax7.set_title('Hybrid Strategies: Hamming Loss Comparison (Lower is Better)', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax7.set_xticks(x)\n",
    "        ax7.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax7.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax7.set_ylim([min(values) * 0.85, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax7.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/hamming_loss.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 8. Example-based Accuracy\n",
    "        fig8, ax8 = plt.subplots(figsize=(12, 7))\n",
    "        values = df_comparison['Example-based Accuracy'].tolist()\n",
    "        ax8.plot(x, values, marker='o', linewidth=2.5, markersize=8, color='#9B59B6', label='Example-based Accuracy')\n",
    "        ax8.fill_between(x, values, alpha=0.3, color='#9B59B6')\n",
    "        ax8.set_xlabel('Strategy', fontsize=13, fontweight='bold')\n",
    "        ax8.set_ylabel('Example-based Accuracy', fontsize=13, fontweight='bold')\n",
    "        ax8.set_title('Hybrid Strategies: Example-based Accuracy Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "        ax8.set_xticks(x)\n",
    "        ax8.set_xticklabels(strategies, rotation=45, ha='right', fontsize=10)\n",
    "        ax8.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax8.set_ylim([min(values) * 0.95, max(values) * 1.1])\n",
    "        for i, v in enumerate(values):\n",
    "            ax8.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{plots_dir}/example_based_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Combined plot (4x2 grid for 8 metrics)\n",
    "        fig, axes = plt.subplots(4, 2, figsize=(18, 24))\n",
    "        \n",
    "        # Panel 1: Micro F1\n",
    "        values = df_comparison['Micro F1'].tolist()\n",
    "        axes[0, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#2E86AB')\n",
    "        axes[0, 0].fill_between(x, values, alpha=0.3, color='#2E86AB')\n",
    "        axes[0, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[0, 0].set_ylabel('Micro F1', fontsize=10)\n",
    "        axes[0, 0].set_title('Micro F1 Score', fontsize=11, fontweight='bold')\n",
    "        axes[0, 0].set_xticks(x)\n",
    "        axes[0, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 2: mAP\n",
    "        values = df_comparison['mAP'].tolist()\n",
    "        axes[0, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#06A77D')\n",
    "        axes[0, 1].fill_between(x, values, alpha=0.3, color='#06A77D')\n",
    "        axes[0, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[0, 1].set_ylabel('mAP', fontsize=10)\n",
    "        axes[0, 1].set_title('Mean Average Precision', fontsize=11, fontweight='bold')\n",
    "        axes[0, 1].set_xticks(x)\n",
    "        axes[0, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 3: Micro Precision\n",
    "        values = df_comparison['Micro Precision'].tolist()\n",
    "        axes[1, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#5DADE2')\n",
    "        axes[1, 0].fill_between(x, values, alpha=0.3, color='#5DADE2')\n",
    "        axes[1, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[1, 0].set_ylabel('Micro Precision', fontsize=10)\n",
    "        axes[1, 0].set_title('Micro Precision', fontsize=11, fontweight='bold')\n",
    "        axes[1, 0].set_xticks(x)\n",
    "        axes[1, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 4: Micro Recall\n",
    "        values = df_comparison['Micro Recall'].tolist()\n",
    "        axes[1, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#EC7063')\n",
    "        axes[1, 1].fill_between(x, values, alpha=0.3, color='#EC7063')\n",
    "        axes[1, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[1, 1].set_ylabel('Micro Recall', fontsize=10)\n",
    "        axes[1, 1].set_title('Micro Recall', fontsize=11, fontweight='bold')\n",
    "        axes[1, 1].set_xticks(x)\n",
    "        axes[1, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 5: Recall@5\n",
    "        values = df_comparison['Recall@5'].tolist()\n",
    "        axes[2, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#F39C12')\n",
    "        axes[2, 0].fill_between(x, values, alpha=0.3, color='#F39C12')\n",
    "        axes[2, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[2, 0].set_ylabel('Recall@5', fontsize=10)\n",
    "        axes[2, 0].set_title('Recall@5', fontsize=11, fontweight='bold')\n",
    "        axes[2, 0].set_xticks(x)\n",
    "        axes[2, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 6: Precision@5\n",
    "        values = df_comparison['Precision@5'].tolist()\n",
    "        axes[2, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#17A589')\n",
    "        axes[2, 1].fill_between(x, values, alpha=0.3, color='#17A589')\n",
    "        axes[2, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[2, 1].set_ylabel('Precision@5', fontsize=10)\n",
    "        axes[2, 1].set_title('Precision@5', fontsize=11, fontweight='bold')\n",
    "        axes[2, 1].set_xticks(x)\n",
    "        axes[2, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[2, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 7: Hamming Loss\n",
    "        values = df_comparison['Hamming Loss'].tolist()\n",
    "        axes[3, 0].plot(x, values, marker='o', linewidth=2, markersize=6, color='#FF6F61')\n",
    "        axes[3, 0].fill_between(x, values, alpha=0.3, color='#FF6F61')\n",
    "        axes[3, 0].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[3, 0].set_ylabel('Hamming Loss', fontsize=10)\n",
    "        axes[3, 0].set_title('Hamming Loss (Lower is Better)', fontsize=11, fontweight='bold')\n",
    "        axes[3, 0].set_xticks(x)\n",
    "        axes[3, 0].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[3, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Panel 8: Example-based Accuracy\n",
    "        values = df_comparison['Example-based Accuracy'].tolist()\n",
    "        axes[3, 1].plot(x, values, marker='o', linewidth=2, markersize=6, color='#9B59B6')\n",
    "        axes[3, 1].fill_between(x, values, alpha=0.3, color='#9B59B6')\n",
    "        axes[3, 1].set_xlabel('Strategy', fontsize=10)\n",
    "        axes[3, 1].set_ylabel('Example-based Accuracy', fontsize=10)\n",
    "        axes[3, 1].set_title('Example-based Accuracy', fontsize=11, fontweight='bold')\n",
    "        axes[3, 1].set_xticks(x)\n",
    "        axes[3, 1].set_xticklabels(strategies, rotation=45, ha='right', fontsize=7)\n",
    "        axes[3, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        combined_plot_path = f'{plots_dir}/hybrid_strategies_comparison_all.png'\n",
    "        plt.savefig(combined_plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüìä Plots saved:\")\n",
    "        print(f\"    - {plots_dir}/hybrid_strategies_comparison_all.png (combined 8-panel)\")\n",
    "        print(f\"    - {plots_dir}/micro_f1.png\")\n",
    "        print(f\"    - {plots_dir}/map.png\")\n",
    "        print(f\"    - {plots_dir}/micro_precision.png\")\n",
    "        print(f\"    - {plots_dir}/micro_recall.png\")\n",
    "        print(f\"    - {plots_dir}/recall_at_5.png\")\n",
    "        print(f\"    - {plots_dir}/precision_at_5.png\")\n",
    "        print(f\"    - {plots_dir}/hamming_loss.png\")\n",
    "        print(f\"    - {plots_dir}/example_based_accuracy.png\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93aeaaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìù NOTLAR VE REFERANSLAR\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Ba≈üarƒ± Kriterleri (SOC Analyst Perspektifi)\n",
    "\n",
    "| Metrik | Hedef | A√ßƒ±klama | √ñncelik |\n",
    "|--------|-------|----------|---------|\n",
    "| **mAP** | > 0.20 | Sƒ±ralama kalitesi - doƒüru TTP'leri listenin tepesine koyma | ‚≠ê‚≠ê‚≠ê |\n",
    "| **Recall@5** | > 0.30 | Top-5 tahmin i√ßinde doƒüru TTP'lerin oranƒ± | ‚≠ê‚≠ê‚≠ê |\n",
    "| **Micro F1** | > 0.15 | Genel performans (threshold-based) | ‚≠ê‚≠ê |\n",
    "| **Hamming Loss** | < 0.10 | Yanlƒ±≈ü tahmin oranƒ± (d√º≈ü√ºk = iyi) | ‚≠ê‚≠ê |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è √ñnemli Hatƒ±rlatmalar\n",
    "\n",
    "- ‚úÖ Her strateji h√ºcresi **baƒüƒ±msƒ±z** √ßalƒ±≈ütƒ±rƒ±labilir\n",
    "- ‚úÖ Sonu√ßlar `all_test_results` dictionary'sinde saklanƒ±r\n",
    "- ‚úÖ Comparison h√ºcresini dilediƒüiniz zaman √ßalƒ±≈ütƒ±rƒ±p ara sonu√ßlara bakabilirsiniz\n",
    "- ‚è±Ô∏è CTI-BERT ilk indirilirken cache'lenir (~500MB)\n",
    "- üìä T√ºm grafikler `outputs/` klas√∂r√ºne kaydedilir\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Referanslar\n",
    "\n",
    "| Kaynak | A√ßƒ±klama |\n",
    "|--------|----------|\n",
    "| [CTI-BERT](https://huggingface.co/ibm-research/CTI-BERT) | IBM Research - Cyber Threat Intelligence BERT |\n",
    "| [Security-TTP-Mapping](https://huggingface.co/datasets/tumeteor/Security-TTP-Mapping) | MITRE ATT&CK etiketli CTI dataset |\n",
    "| [MITRE ATT&CK](https://attack.mitre.org/) | Adversarial Tactics, Techniques & Common Knowledge |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
