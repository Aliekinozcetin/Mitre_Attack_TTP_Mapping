{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810ed58e",
   "metadata": {},
   "source": [
    "## 1. Setup - Colab Kontrol√º ve Proje Kurulumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Colab kontrol√º\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"‚úÖ Google Colab ortamƒ± tespit edildi\")\n",
    "\n",
    "    # GPU kontrol√º\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GPU bulunamadƒ±! Runtime > Change runtime type > GPU se√ßin\")\n",
    "\n",
    "    # GitHub'dan projeyi klonla\n",
    "    print(\"\\nüì• Proje indiriliyor...\")\n",
    "    !git clone https://github.com/Aliekinozcetin/Mitre_Attack_TTP_Mapping.git\n",
    "\n",
    "    # Proje dizinine ge√ß\n",
    "    os.chdir('Mitre_Attack_TTP_Mapping')\n",
    "    print(f\"‚úÖ √áalƒ±≈üma dizini: {os.getcwd()}\")\n",
    "\n",
    "    # Gerekli paketleri y√ºkle (sadece temel ML paketleri, Jupyter paketleri hari√ß)\n",
    "    print(\"\\nüì¶ Paketler y√ºkleniyor...\")\n",
    "    !pip install -q torch transformers datasets scikit-learn pandas tqdm wandb matplotlib seaborn\n",
    "    print(\"‚úÖ T√ºm paketler y√ºklendi\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Yerel ortamda √ßalƒ±≈üƒ±yorsunuz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c051a6d",
   "metadata": {},
   "source": [
    "## 2. Import Mod√ºller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from src.data_loader import prepare_data\n",
    "from src.model import load_model\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model\n",
    "\n",
    "print(\"‚úÖ Mod√ºller y√ºklendi\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad159860",
   "metadata": {},
   "source": [
    "## 3. Konfig√ºrasyon - Focal Loss Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092480ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parametreleri - FOCAL LOSS VERSION\n",
    "CONFIG = {\n",
    "    'model_name': 'bert-base-uncased',\n",
    "    'max_length': 512,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_epochs': 3,\n",
    "    'warmup_steps': 500,\n",
    "    'threshold': 0.5,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'output_dir': './outputs',\n",
    "    \n",
    "    # üéØ FOCAL LOSS PARAMETERS\n",
    "    'use_focal_loss': True,\n",
    "    'focal_alpha': 0.25,  # Weight for positive class (0.25 = focus on positives)\n",
    "    'focal_gamma': 2.0,   # Focusing parameter (2.0 = standard, higher = more aggressive)\n",
    "}\n",
    "\n",
    "# Konfig√ºrasyonu yazdƒ±r\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ FOCAL LOSS TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "for key, value in CONFIG.items():\n",
    "    marker = \"üéØ\" if 'focal' in key else \"  \"\n",
    "    print(f\"{marker} {key:20s}: {value}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° Focal Loss formula: FL(p_t) = -Œ±(1-p_t)^Œ≥ * log(p_t)\")\n",
    "print(f\"   Œ± (alpha) = {CONFIG['focal_alpha']} : Balances positive/negative class importance\")\n",
    "print(f\"   Œ≥ (gamma) = {CONFIG['focal_gamma']} : Down-weights easy examples (higher = more focus on hard examples)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13732dea",
   "metadata": {},
   "source": [
    "## 4. Veri Y√ºkleme ve Hazƒ±rlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: DATA PREPARATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "data = prepare_data(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "\n",
    "train_dataset = data['train_dataset']\n",
    "test_dataset = data['test_dataset']\n",
    "label_list = data['label_list']\n",
    "num_labels = data['num_labels']\n",
    "\n",
    "print(f\"\\n‚úÖ Veri hazƒ±rlama tamamlandƒ±!\")\n",
    "print(f\"   Train samples: {len(train_dataset)}\")\n",
    "print(f\"   Test samples: {len(test_dataset)}\")\n",
    "print(f\"   Number of labels: {num_labels}\")\n",
    "\n",
    "# Class imbalance analizi\n",
    "all_train_labels = torch.stack([train_dataset[i]['labels'] for i in range(len(train_dataset))])\n",
    "positive_ratio = all_train_labels.float().mean().item()\n",
    "print(f\"\\n‚ö†Ô∏è  Class Imbalance:\")\n",
    "print(f\"   Positive label ratio: {positive_ratio:.4f} ({positive_ratio*100:.2f}%)\")\n",
    "print(f\"   Imbalance ratio: 1:{int(1/positive_ratio)}\")\n",
    "print(f\"   This is why we need Focal Loss!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd1f39",
   "metadata": {},
   "source": [
    "## 5. Model Y√ºkleme - With Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a287a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: MODEL INITIALIZATION WITH FOCAL LOSS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "model = load_model(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    num_labels=num_labels,\n",
    "    device=CONFIG['device'],\n",
    "    use_focal_loss=CONFIG['use_focal_loss'],\n",
    "    focal_alpha=CONFIG['focal_alpha'],\n",
    "    focal_gamma=CONFIG['focal_gamma']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model y√ºklendi ve {CONFIG['device']} cihazƒ±na ta≈üƒ±ndƒ±!\")\n",
    "print(f\"üéØ Loss function: Focal Loss (Œ±={CONFIG['focal_alpha']}, Œ≥={CONFIG['focal_gamma']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cf2eb",
   "metadata": {},
   "source": [
    "## 6. Model Eƒüitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b32d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: MODEL TRAINING WITH FOCAL LOSS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Output dizini olu≈ütur\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_name = f\"{CONFIG['model_name'].replace('/', '_')}_focal_loss_{timestamp}\"\n",
    "output_dir = os.path.join(CONFIG['output_dir'], run_name)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Label listesini kaydet\n",
    "label_file = os.path.join(output_dir, \"labels.json\")\n",
    "with open(label_file, 'w') as f:\n",
    "    json.dump(label_list, f, indent=2)\n",
    "\n",
    "# Config'i kaydet\n",
    "config_file = os.path.join(output_dir, \"config.json\")\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "# Eƒüitimi ba≈ülat\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    output_dir=output_dir,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "# Training ge√ßmi≈üini kaydet\n",
    "history_file = os.path.join(output_dir, \"training_history.json\")\n",
    "with open(history_file, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Eƒüitim tamamlandƒ±!\")\n",
    "print(f\"   Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "if 'val_loss' in history:\n",
    "    print(f\"   Final val loss: {history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "# Loss grafiƒüi\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss (Focal)', linewidth=2)\n",
    "if 'val_loss' in history:\n",
    "    plt.plot(history['val_loss'], label='Val Loss (Focal)', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Focal Loss')\n",
    "plt.title('Training History - Focal Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(output_dir, 'training_loss.png'))\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Loss grafiƒüi kaydedildi: training_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663448b",
   "metadata": {},
   "source": [
    "## 7. Model Deƒüerlendirme - Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: MODEL EVALUATION - FOCAL LOSS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Model √ßƒ±ktƒ±larƒ±nƒ± kontrol et - Focal Loss ile iyile≈üme bekleniyor\n",
    "print(\"üîç Focal Loss ile model √ßƒ±ktƒ±larƒ±nƒ± kontrol ediyorum...\")\n",
    "model.eval()\n",
    "sample_batch = next(iter(torch.utils.data.DataLoader(test_dataset, batch_size=16)))\n",
    "with torch.no_grad():\n",
    "    sample_out = model(\n",
    "        input_ids=sample_batch['input_ids'].to(CONFIG['device']),\n",
    "        attention_mask=sample_batch['attention_mask'].to(CONFIG['device'])\n",
    "    )\n",
    "    sample_probs = torch.sigmoid(sample_out['logits'])\n",
    "\n",
    "print(f\"\\nSample sigmoid outputs (Focal Loss):\")\n",
    "print(f\"  Min: {sample_probs.min().item():.6f}\")\n",
    "print(f\"  Max: {sample_probs.max().item():.6f}\")\n",
    "print(f\"  Mean: {sample_probs.mean().item():.6f}\")\n",
    "print(f\"  Median: {sample_probs.median().item():.6f}\")\n",
    "print(f\"  Std: {sample_probs.std().item():.6f}\")\n",
    "\n",
    "print(f\"\\nüí° Expected improvement over BCE:\")\n",
    "print(f\"   - Higher max values (more confident predictions)\")\n",
    "print(f\"   - Higher variance (not all predictions near 0)\")\n",
    "print(f\"   - Better calibration for rare labels\")\n",
    "\n",
    "# Otomatik threshold belirleme\n",
    "optimal_threshold = float(sample_probs.median().item())\n",
    "print(f\"\\nüí° √ñnerilen threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Farklƒ± threshold deƒüerleri ile deƒüerlendir\n",
    "thresholds_to_test = [0.1, 0.2, 0.3, optimal_threshold, 0.5]\n",
    "print(f\"\\nüìä Farklƒ± threshold deƒüerleri test ediliyor...\")\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5\n",
    "best_metrics = None\n",
    "\n",
    "for thresh in thresholds_to_test:\n",
    "    metrics = evaluate_model(\n",
    "        model=model,\n",
    "        test_dataset=test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        device=CONFIG['device'],\n",
    "        threshold=thresh,\n",
    "        label_list=label_list\n",
    "    )\n",
    "\n",
    "    if metrics['micro_f1'] > best_f1:\n",
    "        best_f1 = metrics['micro_f1']\n",
    "        best_threshold = thresh\n",
    "        best_metrics = metrics\n",
    "\n",
    "print(f\"\\nüèÜ En iyi threshold: {best_threshold:.4f}\")\n",
    "print(f\"   Micro F1: {best_f1:.4f}\")\n",
    "\n",
    "# En iyi metrikleri kaydet\n",
    "metrics_to_save = {k: float(v) if isinstance(v, (float, int)) else v\n",
    "                   for k, v in best_metrics.items()\n",
    "                   if k not in ['predictions', 'labels']}\n",
    "metrics_to_save['best_threshold'] = best_threshold\n",
    "metrics_to_save['loss_type'] = 'focal_loss'\n",
    "metrics_to_save['focal_alpha'] = CONFIG['focal_alpha']\n",
    "metrics_to_save['focal_gamma'] = CONFIG['focal_gamma']\n",
    "\n",
    "metrics_file = os.path.join(output_dir, \"evaluation_metrics.json\")\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics_to_save, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Deƒüerlendirme tamamlandƒ±!\")\n",
    "print(f\"\\nFinal Metrics (Focal Loss, threshold={best_threshold:.4f}):\")\n",
    "print(f\"  Micro F1:    {best_metrics['micro_f1']:.4f}\")\n",
    "print(f\"  Macro F1:    {best_metrics['macro_f1']:.4f}\")\n",
    "print(f\"  Samples F1:  {best_metrics['samples_f1']:.4f}\")\n",
    "print(f\"  Precision:   {best_metrics['micro_precision']:.4f}\")\n",
    "print(f\"  Recall:      {best_metrics['micro_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62512c1",
   "metadata": {},
   "source": [
    "## 8. üî¨ Top-K Strategy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885104ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üî¨ TOP-K EVALUATION WITH FOCAL LOSS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Calculate average number of true labels per sample\n",
    "true_labels_sum = torch.stack([test_dataset[i]['labels'] for i in range(len(test_dataset))]).sum(dim=1)\n",
    "avg_k = int(true_labels_sum.float().mean().item())\n",
    "print(f\"Average true labels per sample: {avg_k:.1f}\")\n",
    "\n",
    "# Test different K values\n",
    "k_values = [1, 3, 5, avg_k, 10, 15, 20]\n",
    "topk_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nTesting Top-K with k={k}...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'].to(CONFIG['device']),\n",
    "                attention_mask=batch['attention_mask'].to(CONFIG['device'])\n",
    "            )\n",
    "            probs = torch.sigmoid(outputs['logits'])\n",
    "            \n",
    "            # Select top-k\n",
    "            batch_preds = torch.zeros_like(probs)\n",
    "            topk_values, topk_indices = torch.topk(probs, k=min(k, probs.size(1)), dim=1)\n",
    "            batch_preds.scatter_(1, topk_indices, 1.0)\n",
    "            \n",
    "            all_predictions.append(batch_preds.cpu().numpy())\n",
    "            all_labels.append(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    predictions = np.vstack(all_predictions)\n",
    "    labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Compute metrics\n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "    \n",
    "    micro_f1 = f1_score(labels, predictions, average='micro', zero_division=0)\n",
    "    macro_f1 = f1_score(labels, predictions, average='macro', zero_division=0)\n",
    "    samples_f1 = f1_score(labels, predictions, average='samples', zero_division=0)\n",
    "    precision = precision_score(labels, predictions, average='micro', zero_division=0)\n",
    "    recall = recall_score(labels, predictions, average='micro', zero_division=0)\n",
    "    \n",
    "    topk_results.append({\n",
    "        'k': k,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'samples_f1': samples_f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "    \n",
    "    print(f\"  Micro F1: {micro_f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "# Display results table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üéØ FOCAL LOSS - TOP-K STRATEGY RESULTS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"{'K':>5} {'Micro F1':>10} {'Macro F1':>10} {'Samples F1':>12} {'Precision':>11} {'Recall':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for result in topk_results:\n",
    "    print(f\"{result['k']:>5} {result['micro_f1']:>10.4f} {result['macro_f1']:>10.4f} \"\n",
    "          f\"{result['samples_f1']:>12.4f} {result['precision']:>11.4f} {result['recall']:>10.4f}\")\n",
    "\n",
    "# Find best K\n",
    "best_result = max(topk_results, key=lambda x: x['micro_f1'])\n",
    "print(f\"\\nüèÜ Best K: {best_result['k']} with Micro F1: {best_result['micro_f1']:.4f}\")\n",
    "\n",
    "# Save Top-K results\n",
    "topk_file = os.path.join(output_dir, \"topk_results.json\")\n",
    "with open(topk_file, 'w') as f:\n",
    "    json.dump(topk_results, f, indent=2)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot F1 scores\n",
    "k_vals = [r['k'] for r in topk_results]\n",
    "axes[0].plot(k_vals, [r['micro_f1'] for r in topk_results], marker='o', label='Micro F1', linewidth=2)\n",
    "axes[0].plot(k_vals, [r['macro_f1'] for r in topk_results], marker='s', label='Macro F1', linewidth=2)\n",
    "axes[0].plot(k_vals, [r['samples_f1'] for r in topk_results], marker='^', label='Samples F1', linewidth=2)\n",
    "axes[0].axvline(x=best_result['k'], color='r', linestyle='--', alpha=0.5, label=f'Best K={best_result[\"k\"]}')\n",
    "axes[0].set_xlabel('K')\n",
    "axes[0].set_ylabel('F1 Score')\n",
    "axes[0].set_title('Focal Loss: F1 Scores vs K')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot Precision-Recall\n",
    "axes[1].plot(k_vals, [r['precision'] for r in topk_results], marker='o', label='Precision', linewidth=2)\n",
    "axes[1].plot(k_vals, [r['recall'] for r in topk_results], marker='s', label='Recall', linewidth=2)\n",
    "axes[1].axvline(x=best_result['k'], color='r', linestyle='--', alpha=0.5, label=f'Best K={best_result[\"k\"]}')\n",
    "axes[1].set_xlabel('K')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Focal Loss: Precision & Recall vs K')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'topk_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Top-K analiz grafiƒüi kaydedildi: topk_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b256c8",
   "metadata": {},
   "source": [
    "## 9. üìä BCE vs Focal Loss Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7635a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FOCAL LOSS vs BCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# You can manually enter BCE results from previous run for comparison\n",
    "print(\"\\nüí° To compare with BCE results:\")\n",
    "print(\"   1. Check outputs/bert-base-uncased_YYYYMMDD_HHMMSS/evaluation_metrics.json\")\n",
    "print(\"   2. Compare Micro F1, Macro F1, and prediction statistics\")\n",
    "print(\"\\nüìã Focal Loss Results (this run):\")\n",
    "print(f\"   Best threshold: {best_threshold:.4f}\")\n",
    "print(f\"   Micro F1: {best_metrics['micro_f1']:.4f}\")\n",
    "print(f\"   Macro F1: {best_metrics['macro_f1']:.4f}\")\n",
    "print(f\"   Best Top-K: k={best_result['k']}, F1={best_result['micro_f1']:.4f}\")\n",
    "\n",
    "print(\"\\nüí° Expected improvements:\")\n",
    "print(\"   ‚úÖ Higher F1 scores (especially for rare labels)\")\n",
    "print(\"   ‚úÖ Better prediction calibration\")\n",
    "print(\"   ‚úÖ More variance in predictions\")\n",
    "print(\"   ‚úÖ Reduced false negatives for minority classes\")\n",
    "\n",
    "# Quick variance check\n",
    "all_test_probs = []\n",
    "model.eval()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'].to(CONFIG['device']),\n",
    "            attention_mask=batch['attention_mask'].to(CONFIG['device'])\n",
    "        )\n",
    "        probs = torch.sigmoid(outputs['logits'])\n",
    "        all_test_probs.append(probs.cpu())\n",
    "\n",
    "all_test_probs = torch.cat(all_test_probs, dim=0)\n",
    "variance_per_label = all_test_probs.var(dim=0)\n",
    "low_variance_count = (variance_per_label < 0.0001).sum().item()\n",
    "\n",
    "print(f\"\\nüîç Prediction Variance Analysis:\")\n",
    "print(f\"   Labels with very low variance (<0.0001): {low_variance_count}/{num_labels}\")\n",
    "print(f\"   ({(low_variance_count/num_labels)*100:.1f}% of labels)\")\n",
    "print(f\"\\n   BCE baseline had: 499/499 (100%) - all predictions identical!\")\n",
    "print(f\"   Focal Loss improvement: {499 - low_variance_count} labels now have variance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418cf16",
   "metadata": {},
   "source": [
    "## 10. Sonu√ßlarƒ± Kaydet ve ƒ∞ndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √ñzet dosyasƒ± olu≈ütur\n",
    "summary = {\n",
    "    'model': CONFIG['model_name'],\n",
    "    'timestamp': timestamp,\n",
    "    'loss_function': 'Focal Loss',\n",
    "    'focal_params': {\n",
    "        'alpha': CONFIG['focal_alpha'],\n",
    "        'gamma': CONFIG['focal_gamma']\n",
    "    },\n",
    "    'configuration': CONFIG,\n",
    "    'data': {\n",
    "        'num_labels': num_labels,\n",
    "        'train_samples': len(train_dataset),\n",
    "        'test_samples': len(test_dataset),\n",
    "        'class_imbalance_ratio': f\"1:{int(1/positive_ratio)}\"\n",
    "    },\n",
    "    'training': {\n",
    "        'final_loss': history['train_loss'][-1],\n",
    "        'epochs': CONFIG['num_epochs']\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'threshold_based': metrics_to_save,\n",
    "        'topk_based': {\n",
    "            'best_k': best_result['k'],\n",
    "            'best_micro_f1': best_result['micro_f1'],\n",
    "            'all_k_results': topk_results\n",
    "        },\n",
    "        'prediction_stats': {\n",
    "            'low_variance_labels': low_variance_count,\n",
    "            'total_labels': num_labels,\n",
    "            'variance_improvement': f\"{499 - low_variance_count} labels gained variance\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_file = os.path.join(output_dir, \"summary.json\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ FOCAL LOSS PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSonu√ßlar kaydedildi: {output_dir}\")\n",
    "print(\"\\nDosyalar:\")\n",
    "print(f\"  - config.json (Focal Loss parameters)\")\n",
    "print(f\"  - labels.json\")\n",
    "print(f\"  - training_history.json\")\n",
    "print(f\"  - evaluation_metrics.json\")\n",
    "print(f\"  - topk_results.json\")\n",
    "print(f\"  - summary.json\")\n",
    "print(f\"  - final_model.pt\")\n",
    "print(f\"  - checkpoint_epoch_*.pt\")\n",
    "print(f\"  - training_loss.png\")\n",
    "print(f\"  - topk_analysis.png\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b20fd",
   "metadata": {},
   "source": [
    "## 11. Colab'da Sonu√ßlarƒ± ƒ∞ndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "    from google.colab import files\n",
    "\n",
    "    # Sonu√ßlarƒ± ZIP'le\n",
    "    zip_name = f\"{run_name}.zip\"\n",
    "    shutil.make_archive(run_name, 'zip', output_dir)\n",
    "\n",
    "    print(f\"\\nüì¶ Sonu√ßlar sƒ±kƒ±≈ütƒ±rƒ±lƒ±yor: {zip_name}\")\n",
    "    print(f\"   Boyut: {os.path.getsize(zip_name) / (1024*1024):.2f} MB\")\n",
    "\n",
    "    # ƒ∞ndir\n",
    "    print(\"\\n‚¨áÔ∏è  ƒ∞ndirme ba≈ülatƒ±lƒ±yor...\")\n",
    "    files.download(zip_name)\n",
    "    print(\"‚úÖ ƒ∞ndirme tamamlandƒ±!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Yerel ortamdasƒ±nƒ±z, sonu√ßlar zaten bilgisayarƒ±nƒ±zda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c09fc7",
   "metadata": {},
   "source": [
    "## 12. (Opsiyonel) Focal Loss Parameters Tuning\n",
    "\n",
    "You can experiment with different Focal Loss parameters to find optimal settings for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6524e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different Focal Loss parameters:\n",
    "\n",
    "# More aggressive focusing (harder examples get more weight):\n",
    "# CONFIG['focal_gamma'] = 3.0  # or 4.0\n",
    "\n",
    "# More balanced class weighting:\n",
    "# CONFIG['focal_alpha'] = 0.5  # Equal weight to positive/negative\n",
    "\n",
    "# Focus more on positive class:\n",
    "# CONFIG['focal_alpha'] = 0.75  # More weight to positives\n",
    "\n",
    "# Less aggressive (closer to BCE):\n",
    "# CONFIG['focal_gamma'] = 1.0\n",
    "\n",
    "# Then re-run cells from \"5. Model Y√ºkleme\" onwards\n",
    "print(\"üí° Adjust CONFIG['focal_alpha'] and CONFIG['focal_gamma'] above\")\n",
    "print(\"   Then re-run from Cell 5 to experiment with different parameters\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
